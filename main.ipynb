{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    PIPELINE DE VEILLE KPMG                  â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                             â”‚\n",
    "â”‚  [Sources] â†’ [Loaders] â†’ [Chunking] â†’ [Embeddings]          â”‚\n",
    "â”‚                              â†“                              â”‚\n",
    "â”‚                     [Pinecone Namespaces]                   â”‚\n",
    "â”‚                              â†“                              â”‚\n",
    "â”‚              [Retriever] â†’ [LLM] â†’ [RÃ©ponse]                â”‚\n",
    "â”‚                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEF d'un namespace = un dossier dans une base\n",
    "\n",
    "index: veille-strategique\n",
    "\n",
    "â”œâ”€â”€ namespace: financial_reports\n",
    "â”‚   â”œâ”€â”€ vecteur_001 (10-K Apple)\n",
    "â”‚   â”œâ”€â”€ vecteur_002 (10-Q Microsoft)\n",
    "â”‚\n",
    "â”œâ”€â”€ namespace: news\n",
    "â”‚   â”œâ”€â”€ vecteur_101 (Google News - OpenAI)\n",
    "â”‚   â”œâ”€â”€ vecteur_102 (Reuters - Tesla)\n",
    "â”‚\n",
    "â”œâ”€â”€ namespace: startups\n",
    "â”‚   â”œâ”€â”€ vecteur_201 (Crunchbase - levÃ©e SÃ©rie A)\n",
    "â”‚\n",
    "â”œâ”€â”€ namespace: macro_data\n",
    "â”‚   â”œâ”€â”€ vecteur_301 (World Bank - inflation UE)\n",
    "â”‚\n",
    "â””â”€â”€ namespace: social_signals\n",
    "    â”œâ”€â”€ vecteur_401 (Reddit sentiment marchÃ©)\n",
    "\n",
    "BUT : Retrieval ciblÃ©, Ã‰viter le bruit, Prompting plus intelligent (Â« RÃ©ponds uniquement Ã  partir des donnÃ©es issues du namespace financial_reports et cite les sources Â»)Ã‡a rÃ©duit les hallucinations, ScalabilitÃ© propre :\n",
    "\n",
    "-Tu peux ajouter de nouvelles sources sans casser lâ€™existant\n",
    "\n",
    "-Tu peux purger un namespace sans toucher aux autres\n",
    "\n",
    "-Tu peux tester des sources expÃ©rimentales (social_signals) sans polluer le corpus principal\n",
    "\n",
    ",  \n",
    "\n",
    "1 index = 1 projet RAG\n",
    "N namespaces = N types de sources\n",
    "\n",
    "Je pourrais meme aller plus loin ; \n",
    "news/google\n",
    "news/press_release\n",
    "social/reddit\n",
    "social/twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom pinecone import Pinecone\\nimport os\\n\\npc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\\nINDEX_NAME = \"kpmg-veille\"\\n\\n# Supprimer TOUS les vecteurs de TOUS les namespaces\\nindex = pc.Index(INDEX_NAME)\\nstats = index.describe_index_stats()\\n\\nfor namespace in stats.namespaces.keys():\\n    print(f\"ðŸ—‘ï¸ Suppression du namespace \\'{namespace}\\'...\")\\n    index.delete(delete_all=True, namespace=namespace)\\n\\nprint(\"âœ… Index nettoyÃ©\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean l'index ( ATTENTION A NE PAS EXECUTER A CHAQUZ FOIS !!)\n",
    "\n",
    "'''\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "INDEX_NAME = \"kpmg-veille\"\n",
    "\n",
    "# Supprimer TOUS les vecteurs de TOUS les namespaces\n",
    "index = pc.Index(INDEX_NAME)\n",
    "stats = index.describe_index_stats()\n",
    "\n",
    "for namespace in stats.namespaces.keys():\n",
    "    print(f\"ðŸ—‘ï¸ Suppression du namespace '{namespace}'...\")\n",
    "    index.delete(delete_all=True, namespace=namespace)\n",
    "\n",
    "print(\"âœ… Index nettoyÃ©\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ AjoutÃ© au path : /Users/robincrifo/Documents/KPMG/kpmg/HACK-KPMG/src\n",
      " Variables d'environnement chargÃ©es\n",
      "Client Pinecone initialisÃ©\n",
      "ðŸ—‘ï¸  Index 'kpmg-veille' dÃ©tectÃ©. Suppression en cours...\n",
      "âœ… Index supprimÃ© avec succÃ¨s\n",
      "ðŸ”¨ CrÃ©ation de l'index 'kpmg-veille'...\n",
      "âœ… Index crÃ©Ã© et opÃ©rationnel\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š CONFIGURATION DE L'INDEX\n",
      "============================================================\n",
      "Nom : kpmg-veille\n",
      "Dimension : 1024 (Mistral-embed)\n",
      "MÃ©trique : cosine\n",
      "Vecteurs totaux : 0\n",
      "\n",
      "ðŸ“ Namespaces dÃ©finis :\n",
      "   - financial_reports\n",
      "   - news\n",
      "   - startups\n",
      "   - macro_data\n",
      "   - social_signals\n",
      "============================================================\n",
      "\n",
      "âœ… Index prÃªt pour l'ingestion de donnÃ©es\n",
      "\n",
      "âœ… CHECKLIST COMPLÃ‰TÃ‰E :\n",
      "   â˜‘ Index existant supprimÃ©\n",
      "   â˜‘ Nouvel index crÃ©Ã© avec dimension 1024\n",
      "   â˜‘ MÃ©trique cosine configurÃ©e\n",
      "   â˜‘ Serverless spec activÃ©\n",
      "   â˜‘ Namespaces documentÃ©s\n",
      "\n",
      "ðŸŽ¯ PrÃªt pour l'ingestion (Notebook 2)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK 1 : Configuration et Nettoyage Pinecone\n",
    "================================================\n",
    "\n",
    "OBJECTIF : RÃ©initialiser complÃ¨tement l'environnement vectoriel\n",
    "           et crÃ©er une architecture propre avec namespaces.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- Pinecone Docs : https://docs.pinecone.io/docs/python-client\n",
    "- LangChain Pinecone : https://python.langchain.com/docs/integrations/vectorstores/pinecone\n",
    "\n",
    "MÃ‰THODOLOGIE :\n",
    "1. Supprimer l'index existant (stratÃ©gie Option A validÃ©e)\n",
    "2. RecrÃ©er un index optimisÃ© pour Mistral embeddings (dimension 1024)\n",
    "3. Valider la structure des namespaces\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "# Ajoute le dossier courant + le dossier src au path\n",
    "current_dir = os.getcwd()\n",
    "src_dir = os.path.join(current_dir, \"src\")\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "print(f\"ðŸ”§ AjoutÃ© au path : {src_dir}\")\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 1 : CHARGEMENT DES VARIABLES D'ENVIRONNEMENT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "    #PINECONE_ENVIRONMENT = os.getenv(\"PINECONE_ENVIRONMENT\", \"us-east-1\")\n",
    "\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"âŒ PINECONE_API_KEY manquante dans .env\")\n",
    "\n",
    "print(\" Variables d'environnement chargÃ©es\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 2 : INITIALISATION CLIENT PINECONE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "JUSTIFICATION : \n",
    "Pinecone v3+ utilise une nouvelle API avec ServerlessSpec.\n",
    "Cela permet une scalabilitÃ© automatique sans gÃ©rer de pods.\n",
    "\n",
    "RÃ©fÃ©rence : https://docs.pinecone.io/docs/new-api\n",
    "\"\"\"\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "print(\"Client Pinecone initialisÃ©\")\n",
    "    #print(f\" Client Pinecone initialisÃ© (Environnement : {PINECONE_ENVIRONMENT})\")\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 3 : SUPPRESSION DE L'INDEX EXISTANT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "STRATÃ‰GIE VALIDÃ‰E : Option A - Suppression totale\n",
    "\n",
    "POURQUOI ?\n",
    "- Garantit un environnement propre sans donnÃ©es parasites\n",
    "- Ã‰vite les conflits de dimension d'embeddings\n",
    "- Permet de repartir sur des mÃ©tadonnÃ©es structurÃ©es\n",
    "\n",
    "ALTERNATIVE NON RETENUE :\n",
    "Option B (namespaces sans suppression) aurait conservÃ© les donnÃ©es \n",
    "de test (Wikipedia, thermodynamique) qui pollueraient la veille.\n",
    "\"\"\"\n",
    "\n",
    "INDEX_NAME = \"kpmg-veille\"\n",
    "def clean_pinecone_index():\n",
    "    \"\"\"Supprime l'index existant s'il existe\"\"\"\n",
    "    try:\n",
    "        existing_indexes = [idx.name for idx in pc.list_indexes()]\n",
    "        \n",
    "        if INDEX_NAME in existing_indexes:\n",
    "            print(f\"ðŸ—‘ï¸  Index '{INDEX_NAME}' dÃ©tectÃ©. Suppression en cours...\")\n",
    "            pc.delete_index(INDEX_NAME)\n",
    "            \n",
    "            # Attendre la suppression complÃ¨te (bonnes pratiques Pinecone)\n",
    "            while INDEX_NAME in [idx.name for idx in pc.list_indexes()]:\n",
    "                print(\"   â³ Attente de la suppression...\")\n",
    "                time.sleep(2)\n",
    "            \n",
    "            print(\"âœ… Index supprimÃ© avec succÃ¨s\")\n",
    "        else:\n",
    "            print(f\"â„¹ï¸  Aucun index '{INDEX_NAME}' trouvÃ© (normal si 1Ã¨re exÃ©cution)\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Erreur lors du nettoyage : {e}\")\n",
    "        raise\n",
    "\n",
    "clean_pinecone_index()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 4 : CRÃ‰ATION DU NOUVEL INDEX\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "CONFIGURATION OPTIMALE POUR MISTRAL EMBEDDINGS\n",
    "\n",
    "1. DIMENSION : 1024\n",
    "   - Mistral-embed gÃ©nÃ¨re des vecteurs de 1024 dimensions\n",
    "   - RÃ©fÃ©rence : https://docs.mistral.ai/capabilities/embeddings/\n",
    "\n",
    "2. MÃ‰TRIQUE : cosine\n",
    "   - Standard pour la similaritÃ© sÃ©mantique\n",
    "   - RecommandÃ©e par LangChain pour les embeddings textuels\n",
    "   - RÃ©fÃ©rence : https://python.langchain.com/docs/modules/data_connection/vectorstores/\n",
    "\n",
    "3. SERVERLESS SPEC :\n",
    "   - Cloud 'aws', RÃ©gion 'us-east-1'\n",
    "   - ScalabilitÃ© automatique (critique pour la veille en production)\n",
    "   - Pas de gestion de pods\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_optimized_index():\n",
    "    \"\"\"CrÃ©e un index Pinecone optimisÃ© pour la veille stratÃ©gique\"\"\"\n",
    "    try:\n",
    "        print(f\"ðŸ”¨ CrÃ©ation de l'index '{INDEX_NAME}'...\")\n",
    "        \n",
    "        pc.create_index(\n",
    "            name=INDEX_NAME,\n",
    "            dimension=1024,  # Dimension Mistral-embed\n",
    "            metric=\"cosine\",  # SimilaritÃ© sÃ©mantique\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\"  # Utiliser votre rÃ©gion Pinecone\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Attendre que l'index soit prÃªt\n",
    "        while not pc.describe_index(INDEX_NAME).status['ready']:\n",
    "            print(\"   â³ Initialisation de l'index...\")\n",
    "            time.sleep(2)\n",
    "        \n",
    "        print(\"âœ… Index crÃ©Ã© et opÃ©rationnel\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur lors de la crÃ©ation : {e}\")\n",
    "        raise\n",
    "\n",
    "create_optimized_index()\n",
    "\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 5 : VALIDATION DE LA STRUCTURE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "ARCHITECTURE DES NAMESPACES\n",
    "\n",
    "Chaque namespace correspond Ã  un type de source de donnÃ©es :\n",
    "- financial_reports : SEC EDGAR, rapports annuels\n",
    "- news : NewsAPI, communiquÃ©s de presse\n",
    "- startups : Crunchbase (futur)\n",
    "- macro_data : yfinance, donnÃ©es Ã©conomiques\n",
    "- social_signals : Reddit, Twitter (futur)\n",
    "\n",
    "AVANTAGES :\n",
    "âœ“ Isolation des sources pour des requÃªtes ciblÃ©es\n",
    "âœ“ PossibilitÃ© de filtrer par namespace lors du retrieval\n",
    "âœ“ Gestion indÃ©pendante du cycle de vie des donnÃ©es\n",
    "âœ“ Facilite le debugging et les audits\n",
    "\"\"\"\n",
    "\n",
    "NAMESPACES = [\n",
    "    \"financial_reports\",\n",
    "    \"news\",\n",
    "    \"startups\",\n",
    "    \"macro_data\",\n",
    "    \"social_signals\"\n",
    "]\n",
    "\n",
    "def validate_index_structure():\n",
    "    \"\"\"Affiche la configuration de l'index\"\"\"\n",
    "    try:\n",
    "        index_stats = pc.Index(INDEX_NAME).describe_index_stats()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ðŸ“Š CONFIGURATION DE L'INDEX\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Nom : {INDEX_NAME}\")\n",
    "        print(f\"Dimension : 1024 (Mistral-embed)\")\n",
    "        print(f\"MÃ©trique : cosine\")\n",
    "        print(f\"Vecteurs totaux : {index_stats.get('total_vector_count', 0)}\")\n",
    "        print(f\"\\nðŸ“ Namespaces dÃ©finis :\")\n",
    "        for ns in NAMESPACES:\n",
    "            print(f\"   - {ns}\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        print(\"âœ… Index prÃªt pour l'ingestion de donnÃ©es\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur de validation : {e}\")\n",
    "        raise\n",
    "\n",
    "validate_index_structure()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 6 : CHECKLIST DE VALIDATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nâœ… CHECKLIST COMPLÃ‰TÃ‰E :\")\n",
    "print(\"   â˜‘ Index existant supprimÃ©\")\n",
    "print(\"   â˜‘ Nouvel index crÃ©Ã© avec dimension 1024\")\n",
    "print(\"   â˜‘ MÃ©trique cosine configurÃ©e\")\n",
    "print(\"   â˜‘ Serverless spec activÃ©\")\n",
    "print(\"   â˜‘ Namespaces documentÃ©s\")\n",
    "print(\"\\nðŸŽ¯ PrÃªt pour l'ingestion (Notebook 2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration des sources initialisÃ©e\n",
      "\n",
      "============================================================\n",
      "ðŸš€ DÃ‰MARRAGE DE L'INGESTION MULTI-SOURCES\n",
      "============================================================\n",
      "\n",
      "\n",
      "ðŸ“° Chargement NewsAPI...\n",
      "[2026-01-27T08:47:08.003496] NEWSAPI - INFO : Recherche : 'technology finance'\n",
      "[2026-01-27T08:47:08.321106] NEWSAPI - SUCCESS : 97 articles rÃ©cupÃ©rÃ©s\n",
      "\n",
      "ðŸ“¢ Chargement communiquÃ©s de presse...\n",
      "[2026-01-27T08:47:08.325023] PRESS_RELEASE - INFO : Scraping https://www.apple.com/newsroom/\n",
      "[2026-01-27T08:47:09.548059] PRESS_RELEASE - SUCCESS : Document chargÃ© depuis https://www.apple.com/newsroom/\n",
      "\n",
      "ðŸ’¹ Chargement donnÃ©es financiÃ¨res...\n",
      "[2026-01-27T08:47:09.550103] YFINANCE - INFO : RÃ©cupÃ©ration donnÃ©es pour AAPL\n",
      "[2026-01-27T08:47:10.638128] YFINANCE - SUCCESS : DonnÃ©es rÃ©cupÃ©rÃ©es pour AAPL\n",
      "[2026-01-27T08:47:16.643413] YFINANCE - INFO : RÃ©cupÃ©ration donnÃ©es pour MSFT\n",
      "[2026-01-27T08:47:17.082179] YFINANCE - SUCCESS : DonnÃ©es rÃ©cupÃ©rÃ©es pour MSFT\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š RÃ‰SUMÃ‰ DE L'INGESTION\n",
      "============================================================\n",
      "   financial_reports: 0 documents\n",
      "   news: 98 documents\n",
      "   macro_data: 2 documents\n",
      "============================================================\n",
      "\n",
      "âœ… Documents sauvegardÃ©s dans 'ingested_documents.json'\n",
      "ðŸŽ¯ PrÃªt pour le chunking et les embeddings (Notebook 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK 2 : Ingestion Multi-Sources\n",
    "====================================\n",
    "\n",
    "OBJECTIF : CrÃ©er un pipeline robuste d'ingestion de donnÃ©es\n",
    "           depuis SEC EDGAR, NewsAPI, communiquÃ©s de presse et yfinance.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- LangChain Document Loaders : https://python.langchain.com/docs/modules/data_connection/document_loaders/\n",
    "- SEC EDGAR : https://www.sec.gov/edgar/sec-api-documentation\n",
    "- NewsAPI : https://newsapi.org/docs\n",
    "- yfinance : https://pypi.org/project/yfinance/\n",
    "\n",
    "ARCHITECTURE :\n",
    "1. Loaders modulaires par source\n",
    "2. MÃ©tadonnÃ©es riches (source, date, type)\n",
    "3. Gestion d'erreurs et retry\n",
    "4. Logging pour traÃ§abilitÃ©\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# APIs externes\n",
    "import yfinance as yf\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 1 : CONFIGURATION DES SOURCES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "BONNES PRATIQUES :\n",
    "- Centraliser les configurations\n",
    "- Utiliser des variables d'environnement pour les clÃ©s API\n",
    "- Documenter les limites de chaque source\n",
    "\"\"\"\n",
    "\n",
    "# NewsAPI (100 requÃªtes/jour gratuit)\n",
    "NEWSAPI_KEY = os.getenv(\"NEWSAPI_KEY\")\n",
    "NEWSAPI_ENDPOINT = \"https://newsapi.org/v2/everything\"\n",
    "\n",
    "# SEC EDGAR (gratuit, nÃ©cessite User-Agent)\n",
    "    #SEC_USER_AGENT = os.getenv(\"SEC_USER_AGENT\", \"VotreNom votre.email@example.com\")\n",
    "    #SEC_BASE_URL = \"https://data.sec.gov/submissions/\"\n",
    "\n",
    "# Configuration logging\n",
    "LOGS_DIR = \"ingestion_logs\"\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "\n",
    "def log_ingestion(source: str, status: str, details: str):\n",
    "    \"\"\"Log les opÃ©rations d'ingestion pour audit\"\"\"\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    log_entry = f\"[{timestamp}] {source} - {status} : {details}\\n\"\n",
    "    \n",
    "    with open(f\"{LOGS_DIR}/ingestion.log\", \"a\") as f:\n",
    "        f.write(log_entry)\n",
    "    \n",
    "    print(log_entry.strip())\n",
    "\n",
    "print(\"âœ… Configuration des sources initialisÃ©e\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 2 : SOURCE 1 - SEC EDGAR\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "SEC EDGAR : Base de donnÃ©es rÃ©glementaire de la SEC (US)\n",
    "\n",
    "JUSTIFICATION DU CHOIX :\n",
    "âœ“ DonnÃ©es structurÃ©es et fiables\n",
    "âœ“ Gratuit avec rate limiting raisonnable (10 req/sec)\n",
    "âœ“ Essentiel pour l'analyse d'entreprises US (contexte KPMG)\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://www.sec.gov/edgar/sec-api-documentation\n",
    "\n",
    "EXIGENCE CRITIQUE :\n",
    "La SEC bloque les requÃªtes sans User-Agent. \n",
    "Format requis : \"Nom email@example.com\"\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "def load_sec_edgar_filing(cik: str, filing_type: str = \"10-K\") -> List[Document]:\n",
    "    \"\"\"\n",
    "    Charge un dÃ©pÃ´t SEC pour une entreprise donnÃ©e\n",
    "    \n",
    "    Args:\n",
    "        cik: Central Index Key de l'entreprise (ex: \"0000320193\" pour Apple)\n",
    "        filing_type: Type de dÃ©pÃ´t (10-K, 10-Q, 8-K, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Liste de Documents LangChain avec mÃ©tadonnÃ©es\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\"User-Agent\": SEC_USER_AGENT}\n",
    "        url = f\"{SEC_BASE_URL}CIK{cik.zfill(10)}.json\"\n",
    "        \n",
    "        log_ingestion(\"SEC_EDGAR\", \"INFO\", f\"RequÃªte pour CIK {cik}\")\n",
    "        \n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        company_name = data.get(\"name\", \"Unknown\")\n",
    "        \n",
    "        # Filtrer les dÃ©pÃ´ts par type\n",
    "        filings = data.get(\"filings\", {}).get(\"recent\", {})\n",
    "        \n",
    "        documents = []\n",
    "        for i, form in enumerate(filings.get(\"form\", [])):\n",
    "            if form == filing_type:\n",
    "                filing_date = filings[\"filingDate\"][i]\n",
    "                accession = filings[\"accessionNumber\"][i]\n",
    "                primary_doc = filings[\"primaryDocument\"][i]\n",
    "                \n",
    "                # URL du document\n",
    "                acc_no_formatted = accession.replace(\"-\", \"\")\n",
    "                doc_url = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{acc_no_formatted}/{primary_doc}\"\n",
    "                \n",
    "                # CrÃ©ation du Document LangChain\n",
    "                doc = Document(\n",
    "                    page_content=f\"SEC Filing {filing_type} for {company_name} on {filing_date}\",\n",
    "                    metadata={\n",
    "                        \"source\": \"sec_edgar\",\n",
    "                        \"company\": company_name,\n",
    "                        \"cik\": cik,\n",
    "                        \"filing_type\": filing_type,\n",
    "                        \"filing_date\": filing_date,\n",
    "                        \"accession_number\": accession,\n",
    "                        \"url\": doc_url,\n",
    "                        \"namespace\": \"financial_reports\"\n",
    "                    }\n",
    "                )\n",
    "                documents.append(doc)\n",
    "        \n",
    "        log_ingestion(\"SEC_EDGAR\", \"SUCCESS\", f\"{len(documents)} documents trouvÃ©s pour {company_name}\")\n",
    "        return documents\n",
    "    \n",
    "    except Exception as e:\n",
    "        log_ingestion(\"SEC_EDGAR\", \"ERROR\", str(e))\n",
    "        return []\n",
    "'''\n",
    "\n",
    "# Exemple d'utilisation (commentÃ© pour Ã©viter rate limiting)\n",
    "# apple_docs = load_sec_edgar_filing(\"0000320193\", \"10-K\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 3 : SOURCE 2 - NEWSAPI\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "NEWSAPI : AgrÃ©gateur d'actualitÃ©s mondiales\n",
    "\n",
    "JUSTIFICATION :\n",
    "âœ“ Alternative gratuite Ã  Google News API (100 req/jour)\n",
    "âœ“ Couvre 150 000+ sources\n",
    "âœ“ Filtrage par mots-clÃ©s, langue, date\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://newsapi.org/docs/endpoints/everything\n",
    "\n",
    "LIMITE PLAN GRATUIT :\n",
    "- Articles limitÃ©s aux 30 derniers jours\n",
    "- Pas d'accÃ¨s aux articles complets (seulement titre + description)\n",
    "\"\"\"\n",
    "\n",
    "def load_newsapi_articles(query: str, language: str = \"en\", days_back: int = 7) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Charge des articles depuis NewsAPI\n",
    "    \n",
    "    Args:\n",
    "        query: Mot-clÃ© de recherche (ex: \"artificial intelligence finance\")\n",
    "        language: Code langue (en, fr, de, etc.)\n",
    "        days_back: Nombre de jours en arriÃ¨re (max 30 pour plan gratuit)\n",
    "    \n",
    "    Returns:\n",
    "        Liste de Documents avec mÃ©tadonnÃ©es structurÃ©es\n",
    "    \"\"\"\n",
    "    if not NEWSAPI_KEY:\n",
    "        log_ingestion(\"NEWSAPI\", \"ERROR\", \"ClÃ© API manquante\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        from_date = (datetime.now() - timedelta(days=days_back)).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"from\": from_date,\n",
    "            \"language\": language,\n",
    "            \"sortBy\": \"relevancy\",\n",
    "            \"apiKey\": NEWSAPI_KEY\n",
    "        }\n",
    "        \n",
    "        log_ingestion(\"NEWSAPI\", \"INFO\", f\"Recherche : '{query}'\")\n",
    "        \n",
    "        response = requests.get(NEWSAPI_ENDPOINT, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        articles = data.get(\"articles\", [])\n",
    "        \n",
    "        documents = []\n",
    "        for article in articles:\n",
    "            content = f\"{article.get('title', '')}. {article.get('description', '')}\"\n",
    "            \n",
    "            doc = Document(\n",
    "                page_content=content,\n",
    "                metadata={\n",
    "                    \"source\": \"newsapi\",\n",
    "                    \"title\": article.get(\"title\"),\n",
    "                    \"author\": article.get(\"author\"),\n",
    "                    \"published_at\": article.get(\"publishedAt\"),\n",
    "                    \"url\": article.get(\"url\"),\n",
    "                    \"source_name\": article.get(\"source\", {}).get(\"name\"),\n",
    "                    \"namespace\": \"news\"\n",
    "                }\n",
    "            )\n",
    "            documents.append(doc)\n",
    "        \n",
    "        log_ingestion(\"NEWSAPI\", \"SUCCESS\", f\"{len(documents)} articles rÃ©cupÃ©rÃ©s\")\n",
    "        return documents\n",
    "    \n",
    "    except Exception as e:\n",
    "        log_ingestion(\"NEWSAPI\", \"ERROR\", str(e))\n",
    "        return []\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# news_docs = load_newsapi_articles(\"fintech investment\", language=\"en\", days_back=7)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 4 : SOURCE 3 - COMMUNIQUÃ‰S DE PRESSE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "WEB SCRAPING : CommuniquÃ©s de presse d'entreprises\n",
    "\n",
    "JUSTIFICATION :\n",
    "âœ“ Source primaire (directement depuis les entreprises)\n",
    "âœ“ DonnÃ©es structurÃ©es et fiables\n",
    "âœ“ Gratuit (scraping Ã©thique avec respect du robots.txt)\n",
    "\n",
    "LOADER CHOISI : WebBaseLoader\n",
    "RÃ©fÃ©rence : https://python.langchain.com/docs/integrations/document_loaders/web_base\n",
    "\n",
    "BONNES PRATIQUES :\n",
    "- VÃ©rifier robots.txt avant de scraper\n",
    "- ImplÃ©menter des dÃ©lais entre requÃªtes (rate limiting)\n",
    "- GÃ©rer les erreurs (timeouts, 404, etc.)\n",
    "\"\"\"\n",
    "\n",
    "def load_press_releases(urls: List[str]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Charge des communiquÃ©s de presse depuis des URLs\n",
    "    \n",
    "    Args:\n",
    "        urls: Liste d'URLs de communiquÃ©s\n",
    "    \n",
    "    Returns:\n",
    "        Documents avec mÃ©tadonnÃ©es enrichies\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for url in urls:\n",
    "        try:\n",
    "            log_ingestion(\"PRESS_RELEASE\", \"INFO\", f\"Scraping {url}\")\n",
    "            \n",
    "            loader = WebBaseLoader(url)\n",
    "            docs = loader.load()\n",
    "            \n",
    "            # Enrichir les mÃ©tadonnÃ©es\n",
    "            for doc in docs:\n",
    "                doc.metadata.update({\n",
    "                    \"source\": \"press_release\",\n",
    "                    \"scrape_date\": datetime.now().isoformat(),\n",
    "                    \"namespace\": \"news\"\n",
    "                })\n",
    "                documents.append(doc)\n",
    "            \n",
    "            # Rate limiting Ã©thique\n",
    "            time.sleep(1)\n",
    "            \n",
    "            log_ingestion(\"PRESS_RELEASE\", \"SUCCESS\", f\"Document chargÃ© depuis {url}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            log_ingestion(\"PRESS_RELEASE\", \"ERROR\", f\"{url} - {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Exemple d'URLs (Ã  adapter selon vos besoins)\n",
    "# press_urls = [\n",
    "#     \"https://www.apple.com/newsroom/2024/01/apple-reports-first-quarter-results/\",\n",
    "#     \"https://investor.fb.com/investor-news/default.aspx\"\n",
    "# ]\n",
    "# press_docs = load_press_releases(press_urls)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 5 : SOURCE 4 - YFINANCE (DONNÃ‰ES FINANCIÃˆRES)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "YFINANCE : DonnÃ©es financiÃ¨res en temps rÃ©el\n",
    "\n",
    "JUSTIFICATION :\n",
    "âœ“ Gratuit et sans clÃ© API\n",
    "âœ“ DonnÃ©es Yahoo Finance (fiables)\n",
    "âœ“ IdÃ©al pour les KPIs financiers (prix, revenus, ratios)\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://pypi.org/project/yfinance/\n",
    "\n",
    "MÃ‰THODOLOGIE :\n",
    "On transforme les donnÃ©es structurÃ©es (JSON) en documents textuels\n",
    "pour les rendre compatibles avec le RAG.\n",
    "\"\"\"\n",
    "\n",
    "def load_yfinance_data(ticker: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Charge les donnÃ©es financiÃ¨res d'une entreprise via yfinance\n",
    "    \n",
    "    Args:\n",
    "        ticker: Symbole boursier (ex: \"AAPL\", \"MSFT\")\n",
    "    \n",
    "    Returns:\n",
    "        Documents avec mÃ©triques financiÃ¨res clÃ©s\n",
    "    \"\"\"\n",
    "    try:\n",
    "        log_ingestion(\"YFINANCE\", \"INFO\", f\"RÃ©cupÃ©ration donnÃ©es pour {ticker}\")\n",
    "        \n",
    "        stock = yf.Ticker(ticker)\n",
    "        info = stock.info\n",
    "        \n",
    "        # Extraire les mÃ©triques clÃ©s\n",
    "        metrics = {\n",
    "            \"market_cap\": info.get(\"marketCap\"),\n",
    "            \"revenue\": info.get(\"totalRevenue\"),\n",
    "            \"profit_margin\": info.get(\"profitMargins\"),\n",
    "            \"pe_ratio\": info.get(\"trailingPE\"),\n",
    "            \"current_price\": info.get(\"currentPrice\"),\n",
    "            \"52week_high\": info.get(\"fiftyTwoWeekHigh\"),\n",
    "            \"52week_low\": info.get(\"fiftyTwoWeekLow\")\n",
    "        }\n",
    "        \n",
    "        # CrÃ©er un texte descriptif\n",
    "        content = f\"\"\"\n",
    "        Financial Overview for {ticker}:\n",
    "        - Market Cap: ${metrics['market_cap']:,} (if available)\n",
    "        - Revenue: ${metrics['revenue']:,}\n",
    "        - Profit Margin: {metrics['profit_margin']:.2%}\n",
    "        - P/E Ratio: {metrics['pe_ratio']}\n",
    "        - Current Price: ${metrics['current_price']}\n",
    "        - 52-Week Range: ${metrics['52week_low']} - ${metrics['52week_high']}\n",
    "        \"\"\"\n",
    "        \n",
    "        doc = Document(\n",
    "            page_content=content,\n",
    "            metadata={\n",
    "                \"source\": \"yfinance\",\n",
    "                \"ticker\": ticker,\n",
    "                \"company_name\": info.get(\"longName\", ticker),\n",
    "                \"sector\": info.get(\"sector\"),\n",
    "                \"industry\": info.get(\"industry\"),\n",
    "                \"retrieval_date\": datetime.now().isoformat(),\n",
    "                \"namespace\": \"macro_data\",\n",
    "                **metrics  # Ajouter toutes les mÃ©triques aux mÃ©tadonnÃ©es\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        log_ingestion(\"YFINANCE\", \"SUCCESS\", f\"DonnÃ©es rÃ©cupÃ©rÃ©es pour {ticker}\")\n",
    "        return [doc]\n",
    "    \n",
    "    except Exception as e:\n",
    "        log_ingestion(\"YFINANCE\", \"ERROR\", f\"{ticker} - {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# apple_finance = load_yfinance_data(\"AAPL\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 6 : PIPELINE D'INGESTION UNIFIÃ‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "FONCTION MAÃŽTRE : Orchestration de toutes les sources\n",
    "\n",
    "Cette fonction permet de lancer l'ingestion de toutes les sources\n",
    "en une seule commande. Elle gÃ¨re les erreurs et retourne un rÃ©sumÃ©.\n",
    "\"\"\"\n",
    "\n",
    "def ingest_all_sources() -> Dict[str, List[Document]]:\n",
    "    \"\"\"\n",
    "    Lance l'ingestion de toutes les sources configurÃ©es\n",
    "    \n",
    "    Returns:\n",
    "        Dictionnaire {namespace: [documents]}\n",
    "    \"\"\"\n",
    "    all_documents = {\n",
    "        \"financial_reports\": [],\n",
    "        \"news\": [],\n",
    "        \"macro_data\": []\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸš€ DÃ‰MARRAGE DE L'INGESTION MULTI-SOURCES\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Source 1 : SEC EDGAR (exemple : Apple)\n",
    "    '''\n",
    "    print(\"ðŸ“Š Chargement SEC EDGAR...\")\n",
    "    sec_docs = load_sec_edgar_filing(\"0000320193\", \"10-K\")\n",
    "    all_documents[\"financial_reports\"].extend(sec_docs)\n",
    "    '''\n",
    "\n",
    "    # Source 2 : NewsAPI (si clÃ© disponible)\n",
    "    if NEWSAPI_KEY:\n",
    "        print(\"\\nðŸ“° Chargement NewsAPI...\")\n",
    "        news_docs = load_newsapi_articles(\"technology finance\", days_back=7)\n",
    "        all_documents[\"news\"].extend(news_docs)\n",
    "    \n",
    "    # Source 3 : CommuniquÃ©s de presse (exemple)\n",
    "    print(\"\\nðŸ“¢ Chargement communiquÃ©s de presse...\")\n",
    "    press_urls = [\n",
    "        \"https://www.apple.com/newsroom/\"\n",
    "    ]\n",
    "    press_docs = load_press_releases(press_urls)\n",
    "    all_documents[\"news\"].extend(press_docs)\n",
    "    \n",
    "    # Source 4 : yfinance (exemple : Apple, Microsoft)\n",
    "    print(\"\\nðŸ’¹ Chargement donnÃ©es financiÃ¨res...\")\n",
    "    for ticker in [\"AAPL\", \"MSFT\"]:\n",
    "        finance_docs = load_yfinance_data(ticker)\n",
    "        all_documents[\"macro_data\"].extend(finance_docs)\n",
    "        time.sleep(6)  # Attendre 6 secondes entre chaque ticker\n",
    "\n",
    "    ''' \n",
    "    âœ… Solution long terme : Mettre en cache les donnÃ©es yfinance dans un fichier JSON.\n",
    "    '''\n",
    "    \n",
    "    # RÃ©sumÃ©\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“Š RÃ‰SUMÃ‰ DE L'INGESTION\")\n",
    "    print(\"=\"*60)\n",
    "    for namespace, docs in all_documents.items():\n",
    "        print(f\"   {namespace}: {len(docs)} documents\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    return all_documents\n",
    "\n",
    "# ExÃ©cution du pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    documents_by_namespace = ingest_all_sources()\n",
    "    \n",
    "    # Sauvegarder les documents pour le Notebook 3\n",
    "    with open(\"ingested_documents.json\", \"w\") as f:\n",
    "        # Conversion en format sÃ©rialisable\n",
    "        serializable = {}\n",
    "        for ns, docs in documents_by_namespace.items():\n",
    "            serializable[ns] = [\n",
    "                {\n",
    "                    \"page_content\": doc.page_content,\n",
    "                    \"metadata\": doc.metadata\n",
    "                }\n",
    "                for doc in docs\n",
    "            ]\n",
    "        json.dump(serializable, f, indent=2)\n",
    "    \n",
    "    print(\"âœ… Documents sauvegardÃ©s dans 'ingested_documents.json'\")\n",
    "    print(\"ðŸŽ¯ PrÃªt pour le chunking et les embeddings (Notebook 3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chunker adaptatif initialisÃ©\n",
      "âœ… 100 documents chargÃ©s\n",
      "\n",
      "============================================================\n",
      "ðŸ”ª PHASE DE CHUNKING ADAPTATIF\n",
      "============================================================\n",
      "\n",
      "ðŸ”ª Chunking pour namespace 'news'...\n",
      "   âœ… 98 docs â†’ 107 chunks\n",
      "\n",
      "ðŸ”ª Chunking pour namespace 'macro_data'...\n",
      "   âœ… 2 docs â†’ 2 chunks\n",
      "\n",
      "ðŸ“Š RÃ©sumÃ© du chunking :\n",
      "   news: 107 chunks\n",
      "   macro_data: 2 chunks\n",
      "\n",
      "âœ… ModÃ¨le Mistral-embed initialisÃ©\n",
      "\n",
      "âœ… Ã‰tape 1 : Chunking terminÃ©\n",
      "\n",
      "============================================================\n",
      "ðŸ§® Ã‰TAPE 2 : GÃ‰NÃ‰RATION DES EMBEDDINGS\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Traitement namespace 'news'...\n",
      "\n",
      "ðŸ§® GÃ©nÃ©ration de 107 embeddings...\n",
      "   âœ… Batch 1/3 traitÃ©\n",
      "   âœ… Batch 2/3 traitÃ©\n",
      "   âœ… Batch 3/3 traitÃ©\n",
      "\n",
      "ðŸ“ Traitement namespace 'macro_data'...\n",
      "\n",
      "ðŸ§® GÃ©nÃ©ration de 2 embeddings...\n",
      "   âœ… Batch 1/1 traitÃ©\n",
      "\n",
      "============================================================\n",
      "âœ… VALIDATION DE LA QUALITÃ‰\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Namespace: news\n",
      "   âœ… 107 chunks validÃ©s\n",
      "\n",
      "ðŸ“ Namespace: macro_data\n",
      "   âœ… 2 chunks validÃ©s\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š Chunks avec embeddings : 109/109\n",
      "âœ… Toutes les dimensions sont correctes (1024)\n",
      "============================================================\n",
      "\n",
      "ðŸ’¾ Sauvegarde des documents pour indexation...\n",
      "âœ… Documents sauvegardÃ©s dans 'embedded_documents.json'\n",
      "\n",
      "ðŸŽ¯ PrÃªt pour l'indexation Pinecone (Notebook 4)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK 3 : Chunking Adaptatif & Embeddings Mistral\n",
    "====================================================\n",
    "\n",
    "OBJECTIF : DÃ©couper les documents de maniÃ¨re intelligente\n",
    "           et gÃ©nÃ©rer des embeddings optimisÃ©s pour Pinecone.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- LangChain Text Splitters : https://python.langchain.com/docs/modules/data_connection/document_transformers/\n",
    "- Mistral Embeddings : https://docs.mistral.ai/capabilities/embeddings/\n",
    "- Chunking Best Practices : https://www.pinecone.io/learn/chunking-strategies/\n",
    "\n",
    "MÃ‰THODOLOGIE :\n",
    "1. Chunking adaptatif selon le type de document\n",
    "2. Enrichissement des mÃ©tadonnÃ©es\n",
    "3. GÃ©nÃ©ration d'embeddings par batch (optimisation)\n",
    "4. Validation de la qualitÃ©\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    HTMLHeaderTextSplitter\n",
    ")\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 1 : STRATÃ‰GIES DE CHUNKING PAR TYPE DE DOCUMENT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "JUSTIFICATION DES CHOIX DE CHUNKING\n",
    "\n",
    "D'aprÃ¨s vos notes (KPMG v2.pdf), le chunking est l'Ã©tape la plus sous-estimÃ©e\n",
    "mais dÃ©terminante pour la qualitÃ© du RAG.\n",
    "\n",
    "PRINCIPES :\n",
    "1. GranularitÃ© adaptÃ©e au contenu\n",
    "   - Petits chunks (500 chars) : KPIs, chiffres prÃ©cis\n",
    "   - Gros chunks (1000+ chars) : analyses, raisonnements\n",
    "\n",
    "2. Overlap significatif (15-20%)\n",
    "   - Ã‰vite de couper les informations critiques\n",
    "   - Maintient la cohÃ©rence contextuelle\n",
    "\n",
    "3. SÃ©parateurs intelligents\n",
    "   - Paragraphes > Phrases > Mots\n",
    "   - PrÃ©serve la structure sÃ©mantique\n",
    "\"\"\"\n",
    "\n",
    "class AdaptiveChunker:\n",
    "    \"\"\"DÃ©coupe intelligente selon le type de document\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Splitter pour rapports financiers (SEC, yfinance)\n",
    "        self.financial_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=800,      # Balance entre dÃ©tail et contexte\n",
    "            chunk_overlap=150,   # ~19% overlap\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "            add_start_index=True  # TraÃ§abilitÃ© dans le document source\n",
    "        )\n",
    "        \n",
    "        # Splitter pour actualitÃ©s (courtes, denses)\n",
    "        self.news_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,      # Articles courts\n",
    "            chunk_overlap=100,   # 20% overlap\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "            add_start_index=True\n",
    "        )\n",
    "        \n",
    "        # Splitter HTML (communiquÃ©s de presse structurÃ©s)\n",
    "        self.html_splitter = HTMLHeaderTextSplitter(\n",
    "            headers_to_split_on=[\n",
    "                (\"h1\", \"Header 1\"),\n",
    "                (\"h2\", \"Header 2\"),\n",
    "                (\"h3\", \"Header 3\"),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def chunk_documents(self, documents: List[Document], namespace: str) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Applique la stratÃ©gie de chunking appropriÃ©e\n",
    "        \n",
    "        Args:\n",
    "            documents: Documents Ã  dÃ©couper\n",
    "            namespace: Type de document (dÃ©termine la stratÃ©gie)\n",
    "        \n",
    "        Returns:\n",
    "            Documents dÃ©coupÃ©s avec mÃ©tadonnÃ©es enrichies\n",
    "        \"\"\"\n",
    "        print(f\"\\nðŸ”ª Chunking pour namespace '{namespace}'...\")\n",
    "        \n",
    "        # SÃ©lection du splitter\n",
    "        if namespace == \"financial_reports\":\n",
    "            splitter = self.financial_splitter\n",
    "        elif namespace == \"news\":\n",
    "            splitter = self.news_splitter\n",
    "        elif namespace == \"macro_data\":\n",
    "            splitter = self.financial_splitter\n",
    "        else:\n",
    "            splitter = self.news_splitter  # DÃ©faut\n",
    "        \n",
    "        # DÃ©coupage\n",
    "        chunked_docs = []\n",
    "        for doc in documents:\n",
    "            chunks = splitter.split_documents([doc])\n",
    "            \n",
    "            # Enrichir chaque chunk avec info de position\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                chunk.metadata.update({\n",
    "                    \"chunk_index\": i,\n",
    "                    \"total_chunks\": len(chunks),\n",
    "                    \"chunking_strategy\": splitter.__class__.__name__\n",
    "                })\n",
    "                chunked_docs.append(chunk)\n",
    "        \n",
    "        print(f\"   âœ… {len(documents)} docs â†’ {len(chunked_docs)} chunks\")\n",
    "        return chunked_docs\n",
    "\n",
    "chunker = AdaptiveChunker()\n",
    "print(\"âœ… Chunker adaptatif initialisÃ©\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 2 : CHARGEMENT DES DOCUMENTS INGÃ‰RÃ‰S\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "RÃ©cupÃ©ration des documents depuis le Notebook 2\n",
    "\"\"\"\n",
    "\n",
    "def load_ingested_documents() -> Dict[str, List[Document]]:\n",
    "    \"\"\"Charge les documents depuis le fichier JSON\"\"\"\n",
    "    try:\n",
    "        with open(\"ingested_documents.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Reconversion en objets Document\n",
    "        documents_by_ns = {}\n",
    "        for namespace, docs_data in data.items():\n",
    "            documents_by_ns[namespace] = [\n",
    "                Document(\n",
    "                    page_content=d[\"page_content\"],\n",
    "                    metadata=d[\"metadata\"]\n",
    "                )\n",
    "                for d in docs_data\n",
    "            ]\n",
    "        \n",
    "        print(f\"âœ… {sum(len(docs) for docs in documents_by_ns.values())} documents chargÃ©s\")\n",
    "        return documents_by_ns\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Fichier 'ingested_documents.json' introuvable.\")\n",
    "        print(\"   ExÃ©cutez d'abord le Notebook 2 (ingestion)\")\n",
    "        return {}\n",
    "\n",
    "docs_by_namespace = load_ingested_documents()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 3 : APPLICATION DU CHUNKING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "Application du chunking adaptatif sur tous les namespaces\n",
    "\"\"\"\n",
    "\n",
    "chunked_by_namespace = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ”ª PHASE DE CHUNKING ADAPTATIF\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for namespace, documents in docs_by_namespace.items():\n",
    "    if documents:\n",
    "        chunked_docs = chunker.chunk_documents(documents, namespace)\n",
    "        chunked_by_namespace[namespace] = chunked_docs\n",
    "\n",
    "print(\"\\nðŸ“Š RÃ©sumÃ© du chunking :\")\n",
    "for ns, chunks in chunked_by_namespace.items():\n",
    "    print(f\"   {ns}: {len(chunks)} chunks\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 4 : GÃ‰NÃ‰RATION DES EMBEDDINGS MISTRAL\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "CONFIGURATION MISTRAL EMBEDDINGS\n",
    "\n",
    "ModÃ¨le : mistral-embed\n",
    "Dimension : 1024\n",
    "CoÃ»t : Gratuit avec limits (voir plan Mistral)\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://docs.mistral.ai/capabilities/embeddings/\n",
    "\n",
    "OPTIMISATION :\n",
    "- Traitement par batch pour limiter les appels API\n",
    "- Cache local des embeddings (Ã©vite recalcul)\n",
    "- Gestion des erreurs et retry\n",
    "\"\"\"\n",
    "\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "if not MISTRAL_API_KEY:\n",
    "    raise ValueError(\"âŒ MISTRAL_API_KEY manquante dans .env\")\n",
    "\n",
    "embeddings_model = MistralAIEmbeddings(\n",
    "    model=\"mistral-embed\",\n",
    "    mistral_api_key=MISTRAL_API_KEY\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… ModÃ¨le Mistral-embed initialisÃ©\")\n",
    "\n",
    "def generate_embeddings_batch(documents: List[Document], batch_size: int = 50) -> List[Document]:\n",
    "    \"\"\"\n",
    "    GÃ©nÃ¨re les embeddings par batch pour optimiser les appels API\n",
    "    \n",
    "    Args:\n",
    "        documents: Documents Ã  embedder\n",
    "        batch_size: Nombre de documents par batch\n",
    "    \n",
    "    Returns:\n",
    "        Documents avec embeddings dans les mÃ©tadonnÃ©es\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ§® GÃ©nÃ©ration de {len(documents)} embeddings...\")\n",
    "    \n",
    "    total_batches = (len(documents) + batch_size - 1) // batch_size\n",
    "    \n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        batch = documents[i:i+batch_size]\n",
    "        batch_num = i // batch_size + 1\n",
    "        \n",
    "        try:\n",
    "            # Extraire les textes\n",
    "            texts = [doc.page_content for doc in batch]\n",
    "            \n",
    "            # GÃ©nÃ©rer les embeddings\n",
    "            embeddings = embeddings_model.embed_documents(texts)\n",
    "            \n",
    "            # Ajouter les embeddings aux mÃ©tadonnÃ©es\n",
    "            for doc, embedding in zip(batch, embeddings):\n",
    "                doc.metadata[\"embedding\"] = embedding\n",
    "            \n",
    "            print(f\"   âœ… Batch {batch_num}/{total_batches} traitÃ©\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Erreur batch {batch_num}: {e}\")\n",
    "            # Continuer avec les autres batches\n",
    "            continue\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 5 : VALIDATION DE LA QUALITÃ‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "MÃ‰TRIQUES DE QUALITÃ‰\n",
    "\n",
    "Avant d'envoyer vers Pinecone, on valide :\n",
    "1. Tous les chunks ont des embeddings\n",
    "2. Les dimensions sont correctes (1024)\n",
    "3. Les mÃ©tadonnÃ©es sont complÃ¨tes\n",
    "\"\"\"\n",
    "\n",
    "def validate_chunked_documents(docs_by_ns: Dict[str, List[Document]]) -> bool:\n",
    "    \"\"\"Valide la qualitÃ© des documents chunkÃ©s et embeddÃ©s\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… VALIDATION DE LA QUALITÃ‰\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    total_chunks = sum(len(docs) for docs in docs_by_ns.values())\n",
    "    chunks_with_embeddings = 0\n",
    "    invalid_embeddings = []\n",
    "    \n",
    "    for namespace, documents in docs_by_ns.items():\n",
    "        print(f\"\\nðŸ“ Namespace: {namespace}\")\n",
    "        \n",
    "        for i, doc in enumerate(documents):\n",
    "            # VÃ©rifier prÃ©sence embedding\n",
    "            if \"embedding\" in doc.metadata:\n",
    "                chunks_with_embeddings += 1\n",
    "                \n",
    "                # VÃ©rifier dimension\n",
    "                emb_dim = len(doc.metadata[\"embedding\"])\n",
    "                if emb_dim != 1024:\n",
    "                    invalid_embeddings.append((namespace, i, emb_dim))\n",
    "            \n",
    "            # VÃ©rifier mÃ©tadonnÃ©es essentielles\n",
    "            required_metadata = [\"source\", \"namespace\"]\n",
    "            missing = [key for key in required_metadata if key not in doc.metadata]\n",
    "            if missing:\n",
    "                print(f\"   âš ï¸  Chunk {i} : mÃ©tadonnÃ©es manquantes {missing}\")\n",
    "        \n",
    "        print(f\"   âœ… {len(documents)} chunks validÃ©s\")\n",
    "    \n",
    "    # Rapport final\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ðŸ“Š Chunks avec embeddings : {chunks_with_embeddings}/{total_chunks}\")\n",
    "    \n",
    "    if invalid_embeddings:\n",
    "        print(f\"âš ï¸  Embeddings invalides (dimension â‰  1024) : {len(invalid_embeddings)}\")\n",
    "        for ns, idx, dim in invalid_embeddings[:5]:  # Afficher les 5 premiers\n",
    "            print(f\"   - {ns}[{idx}] : dimension {dim}\")\n",
    "    else:\n",
    "        print(\"âœ… Toutes les dimensions sont correctes (1024)\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return chunks_with_embeddings == total_chunks\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 6 : PIPELINE COMPLET\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "Orchestration complÃ¨te : Chunking â†’ Embeddings â†’ Validation\n",
    "\"\"\"\n",
    "\n",
    "def process_all_documents():\n",
    "    \"\"\"Pipeline complet de traitement\"\"\"\n",
    "    \n",
    "    # Ã‰tape 1 : Chunking (dÃ©jÃ  fait)\n",
    "    print(\"\\nâœ… Ã‰tape 1 : Chunking terminÃ©\")\n",
    "    \n",
    "    # Ã‰tape 2 : GÃ©nÃ©ration des embeddings\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ§® Ã‰TAPE 2 : GÃ‰NÃ‰RATION DES EMBEDDINGS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for namespace, documents in chunked_by_namespace.items():\n",
    "        if documents:\n",
    "            print(f\"\\nðŸ“ Traitement namespace '{namespace}'...\")\n",
    "            generate_embeddings_batch(documents)\n",
    "    \n",
    "    # Ã‰tape 3 : Validation\n",
    "    is_valid = validate_chunked_documents(chunked_by_namespace)\n",
    "    \n",
    "    if is_valid:\n",
    "        # Sauvegarde pour le Notebook 4\n",
    "        print(\"\\nðŸ’¾ Sauvegarde des documents pour indexation...\")\n",
    "        \n",
    "        serializable = {}\n",
    "        for ns, docs in chunked_by_namespace.items():\n",
    "            serializable[ns] = [\n",
    "                {\n",
    "                    \"page_content\": doc.page_content,\n",
    "                    \"metadata\": {\n",
    "                        k: v for k, v in doc.metadata.items()\n",
    "                        if k != \"embedding\"  # Embeddings trop gros pour JSON\n",
    "                    },\n",
    "                    \"embedding\": doc.metadata.get(\"embedding\", [])\n",
    "                }\n",
    "                for doc in docs\n",
    "            ]\n",
    "        \n",
    "        with open(\"embedded_documents.json\", \"w\") as f:\n",
    "            json.dump(serializable, f, indent=2)\n",
    "        \n",
    "        print(\"âœ… Documents sauvegardÃ©s dans 'embedded_documents.json'\")\n",
    "        print(\"\\nðŸŽ¯ PrÃªt pour l'indexation Pinecone (Notebook 4)\")\n",
    "    else:\n",
    "        print(\"\\nâŒ Validation Ã©chouÃ©e. VÃ©rifiez les erreurs ci-dessus.\")\n",
    "\n",
    "# ExÃ©cution\n",
    "if __name__ == \"__main__\":\n",
    "    if docs_by_namespace:\n",
    "        process_all_documents()\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  Aucun document Ã  traiter.\")\n",
    "        print(\"   ExÃ©cutez d'abord les Notebooks 1 et 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Clients Pinecone et Mistral initialisÃ©s\n",
      "âœ… 109 documents chargÃ©s depuis embedded_documents.json\n",
      "\n",
      "============================================================\n",
      "ðŸ“¤ INDEXATION PINECONE\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Traitement namespace : news\n",
      "\n",
      "ðŸ“¤ Upsert vers namespace 'news'...\n",
      "   107 vecteurs en 2 batches\n",
      "   âœ… Batch 1/2 envoyÃ©\n",
      "   âœ… Batch 2/2 envoyÃ©\n",
      "\n",
      "ðŸ“ Traitement namespace : macro_data\n",
      "\n",
      "ðŸ“¤ Upsert vers namespace 'macro_data'...\n",
      "   2 vecteurs en 1 batches\n",
      "   âœ… Batch 1/1 envoyÃ©\n",
      "\n",
      "============================================================\n",
      "âœ… INDEXATION TERMINÃ‰E\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ðŸ” VALIDATION DE L'INDEXATION\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Statistiques de l'index 'kpmg-veille' :\n",
      "   Total vecteurs : 109\n",
      "\n",
      "ðŸ“ Vecteurs par namespace :\n",
      "   - macro_data: 2 vecteurs\n",
      "   - news: 107 vecteurs\n",
      "\n",
      "ðŸ§ª Test de recherche sur namespace 'news'...\n",
      "   âœ… 3 rÃ©sultats trouvÃ©s\n",
      "\n",
      "   Premier rÃ©sultat :\n",
      "   Source : press_release\n",
      "   Contenu : opens in new window\n",
      "\n",
      "Newsroom\n",
      "\n",
      "\n",
      "Latest News\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Apple Stories\n",
      "\n",
      "                    The creators, developers, and innovators leaving the world better than they found it.\n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "\n",
      "============================================================\n",
      "âœ… VALIDATION TERMINÃ‰E\n",
      "============================================================\n",
      "\n",
      "ðŸŽ¯ SystÃ¨me RAG prÃªt pour les requÃªtes (Notebook 5)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK 4 : Indexation Pinecone avec Namespaces\n",
    "=================================================\n",
    "\n",
    "OBJECTIF : Indexer les documents embeddÃ©s dans Pinecone\n",
    "           en utilisant les namespaces pour l'isolation des sources.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- Pinecone Upsert : https://docs.pinecone.io/docs/upsert-data\n",
    "- LangChain Pinecone : https://python.langchain.com/docs/integrations/vectorstores/pinecone\n",
    "- Namespaces Best Practices : https://docs.pinecone.io/docs/namespaces\n",
    "\n",
    "MÃ‰THODOLOGIE :\n",
    "1. Chargement des documents embeddÃ©s\n",
    "2. Conversion au format Pinecone\n",
    "3. Upsert par batch et namespace\n",
    "4. Validation de l'indexation\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "NOTEBOOK 4 : Indexation Pinecone avec Namespaces\n",
    "=================================================\n",
    "\n",
    "OBJECTIF : Indexer les documents embeddÃ©s dans Pinecone\n",
    "           en utilisant les namespaces pour l'isolation des sources.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- Pinecone Upsert : https://docs.pinecone.io/docs/upsert-data\n",
    "- LangChain Pinecone : https://python.langchain.com/docs/integrations/vectorstores/pinecone\n",
    "- Namespaces Best Practices : https://docs.pinecone.io/docs/namespaces\n",
    "\n",
    "MÃ‰THODOLOGIE :\n",
    "1. Chargement des documents embeddÃ©s\n",
    "2. Conversion au format Pinecone\n",
    "3. Upsert par batch et namespace\n",
    "4. Validation de l'indexation\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Pinecone\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 1 : INITIALISATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "INDEX_NAME = \"kpmg-veille\"\n",
    "\n",
    "if not PINECONE_API_KEY or not MISTRAL_API_KEY:\n",
    "    raise ValueError(\"âŒ ClÃ©s API manquantes dans .env\")\n",
    "\n",
    "# Clients\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "embeddings_model = MistralAIEmbeddings(\n",
    "    model=\"mistral-embed\",\n",
    "    mistral_api_key=MISTRAL_API_KEY\n",
    ")\n",
    "\n",
    "print(\"âœ… Clients Pinecone et Mistral initialisÃ©s\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 2 : CHARGEMENT DES DOCUMENTS EMBEDDÃ‰S\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def load_embedded_documents() -> Dict[str, List[Document]]:\n",
    "    \"\"\"Charge les documents avec leurs embeddings depuis le Notebook 3\"\"\"\n",
    "    try:\n",
    "        with open(\"embedded_documents.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        docs_by_ns = {}\n",
    "        for namespace, docs_data in data.items():\n",
    "            docs_by_ns[namespace] = [\n",
    "                Document(\n",
    "                    page_content=d[\"page_content\"],\n",
    "                    metadata={\n",
    "                        **d[\"metadata\"],\n",
    "                        \"embedding\": d[\"embedding\"]\n",
    "                    }\n",
    "                )\n",
    "                for d in docs_data\n",
    "            ]\n",
    "        \n",
    "        total = sum(len(docs) for docs in docs_by_ns.values())\n",
    "        print(f\"âœ… {total} documents chargÃ©s depuis embedded_documents.json\")\n",
    "        \n",
    "        return docs_by_ns\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Fichier 'embedded_documents.json' introuvable.\")\n",
    "        print(\"   ExÃ©cutez d'abord le Notebook 3 (chunking & embeddings)\")\n",
    "        return {}\n",
    "\n",
    "docs_by_namespace = load_embedded_documents()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 3 : PRÃ‰PARATION DES VECTEURS POUR PINECONE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "FORMAT PINECONE UPSERT\n",
    "\n",
    "Structure requise :\n",
    "{\n",
    "    \"id\": \"unique_id\",\n",
    "    \"values\": [0.1, 0.2, ...],  # Embedding (liste de 1024 floats)\n",
    "    \"metadata\": {...}            # MÃ©tadonnÃ©es (max 40 KB par vecteur)\n",
    "}\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://docs.pinecone.io/docs/upsert-data\n",
    "\"\"\"\n",
    "\n",
    "def prepare_vectors_for_pinecone(documents: List[Document], namespace: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Convertit les Documents au format Pinecone\n",
    "    \n",
    "    Args:\n",
    "        documents: Documents avec embeddings\n",
    "        namespace: Namespace de destination\n",
    "    \n",
    "    Returns:\n",
    "        Liste de vecteurs au format Pinecone\n",
    "    \"\"\"\n",
    "    vectors = []\n",
    "    \n",
    "    for i, doc in enumerate(documents):\n",
    "        # GÃ©nÃ©rer un ID unique\n",
    "        vector_id = f\"{namespace}_{i}_{int(time.time())}\"\n",
    "        \n",
    "        # Extraire l'embedding\n",
    "        embedding = doc.metadata.pop(\"embedding\", None)\n",
    "        \n",
    "        if not embedding:\n",
    "            print(f\"âš ï¸  Document {i} sans embedding, ignorÃ©\")\n",
    "            continue\n",
    "        \n",
    "        # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "        # â•‘ NETTOYAGE CRITIQUE POUR PINECONE                          â•‘\n",
    "        # â•‘ Pinecone refuse les valeurs None et les types complexes  â•‘\n",
    "        # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        \n",
    "        clean_metadata = {}\n",
    "        for k, v in doc.metadata.items():\n",
    "            # Ignorer l'embedding (dÃ©jÃ  extrait)\n",
    "            if k == \"embedding\":\n",
    "                continue\n",
    "            \n",
    "            # Remplacer None par \"Unknown\"\n",
    "            if v is None:\n",
    "                clean_metadata[k] = \"Unknown\"\n",
    "            \n",
    "            # Garder les types primitifs\n",
    "            elif isinstance(v, (str, int, float, bool)):\n",
    "                # Limiter les strings Ã  500 caractÃ¨res\n",
    "                if isinstance(v, str):\n",
    "                    clean_metadata[k] = v[:500]\n",
    "                else:\n",
    "                    clean_metadata[k] = v\n",
    "            \n",
    "            # Convertir les listes en strings\n",
    "            elif isinstance(v, list):\n",
    "                clean_metadata[k] = [str(x) for x in v if x is not None]\n",
    "            \n",
    "            # Fallback : conversion en string pour les objets complexes\n",
    "            else:\n",
    "                clean_metadata[k] = str(v)[:500]\n",
    "        \n",
    "        # Ajouter le contenu dans les mÃ©tadonnÃ©es\n",
    "        clean_metadata[\"text\"] = doc.page_content[:1000]\n",
    "        \n",
    "        vector = {\n",
    "            \"id\": vector_id,\n",
    "            \"values\": embedding,\n",
    "            \"metadata\": clean_metadata\n",
    "        }\n",
    "        \n",
    "        vectors.append(vector)\n",
    "    \n",
    "    return vectors\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 4 : UPSERT PAR BATCH ET NAMESPACE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "STRATÃ‰GIE D'UPSERT\n",
    "\n",
    "1. Traiter par batch de 100 vecteurs (limite Pinecone)\n",
    "2. Utiliser les namespaces pour isoler les sources\n",
    "3. GÃ©rer les erreurs et retry\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://docs.pinecone.io/docs/upsert-data#batching-upserts\n",
    "\"\"\"\n",
    "\n",
    "def upsert_to_pinecone(vectors: List[Dict], namespace: str, batch_size: int = 100):\n",
    "    \"\"\"\n",
    "    Envoie les vecteurs vers Pinecone par batch\n",
    "    \n",
    "    Args:\n",
    "        vectors: Vecteurs au format Pinecone\n",
    "        namespace: Namespace de destination\n",
    "        batch_size: Taille des batches\n",
    "    \"\"\"\n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    total_batches = (len(vectors) + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"\\nðŸ“¤ Upsert vers namespace '{namespace}'...\")\n",
    "    print(f\"   {len(vectors)} vecteurs en {total_batches} batches\")\n",
    "    \n",
    "    for i in range(0, len(vectors), batch_size):\n",
    "        batch = vectors[i:i+batch_size]\n",
    "        batch_num = i // batch_size + 1\n",
    "        \n",
    "        try:\n",
    "            index.upsert(\n",
    "                vectors=batch,\n",
    "                namespace=namespace\n",
    "            )\n",
    "            print(f\"   âœ… Batch {batch_num}/{total_batches} envoyÃ©\")\n",
    "            \n",
    "            # Rate limiting (10 req/sec max pour Pinecone gratuit)\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Erreur batch {batch_num}: {e}\")\n",
    "            # Retry une fois\n",
    "            try:\n",
    "                time.sleep(1)\n",
    "                index.upsert(vectors=batch, namespace=namespace)\n",
    "                print(f\"   âœ… Retry rÃ©ussi pour batch {batch_num}\")\n",
    "            except Exception as e2:\n",
    "                print(f\"   âŒ Retry Ã©chouÃ© : {e2}\")\n",
    "                continue\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 5 : INDEXATION COMPLÃˆTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def index_all_documents():\n",
    "    \"\"\"Pipeline complet d'indexation\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“¤ INDEXATION PINECONE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not docs_by_namespace:\n",
    "        print(\"âŒ Aucun document Ã  indexer\")\n",
    "        return\n",
    "    \n",
    "    for namespace, documents in docs_by_namespace.items():\n",
    "        if not documents:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nðŸ“ Traitement namespace : {namespace}\")\n",
    "        \n",
    "        # PrÃ©paration des vecteurs\n",
    "        vectors = prepare_vectors_for_pinecone(documents, namespace)\n",
    "        \n",
    "        if vectors:\n",
    "            # Upsert vers Pinecone\n",
    "            upsert_to_pinecone(vectors, namespace)\n",
    "        else:\n",
    "            print(f\"   âš ï¸  Aucun vecteur valide pour {namespace}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… INDEXATION TERMINÃ‰E\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 6 : VALIDATION POST-INDEXATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "VALIDATION :\n",
    "- VÃ©rifier le nombre de vecteurs indexÃ©s\n",
    "- Tester une recherche simple\n",
    "- Confirmer l'isolation des namespaces\n",
    "\"\"\"\n",
    "\n",
    "def validate_indexation():\n",
    "    \"\"\"Valide que l'indexation s'est bien passÃ©e\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ” VALIDATION DE L'INDEXATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    stats = index.describe_index_stats()\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Statistiques de l'index '{INDEX_NAME}' :\")\n",
    "    print(f\"   Total vecteurs : {stats.total_vector_count}\")\n",
    "    print(f\"\\nðŸ“ Vecteurs par namespace :\")\n",
    "    \n",
    "    for namespace, info in stats.namespaces.items():\n",
    "        print(f\"   - {namespace}: {info.vector_count} vecteurs\")\n",
    "    \n",
    "    # Test de recherche\n",
    "    print(\"\\nðŸ§ª Test de recherche sur namespace 'news'...\")\n",
    "    \n",
    "    try:\n",
    "        vectorstore = PineconeVectorStore(\n",
    "            index_name=INDEX_NAME,\n",
    "            embedding=embeddings_model,\n",
    "            namespace=\"news\"\n",
    "        )\n",
    "        \n",
    "        results = vectorstore.similarity_search(\n",
    "            \"latest technology news\",\n",
    "            k=3\n",
    "        )\n",
    "        \n",
    "        print(f\"   âœ… {len(results)} rÃ©sultats trouvÃ©s\")\n",
    "        \n",
    "        if results:\n",
    "            print(f\"\\n   Premier rÃ©sultat :\")\n",
    "            print(f\"   Source : {results[0].metadata.get('source')}\")\n",
    "            print(f\"   Contenu : {results[0].page_content[:200]}...\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Erreur de recherche : {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… VALIDATION TERMINÃ‰E\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 7 : EXÃ‰CUTION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Indexation\n",
    "    index_all_documents()\n",
    "    \n",
    "    # Validation\n",
    "    time.sleep(2)  # Laisser Pinecone finaliser l'indexation\n",
    "    validate_indexation()\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ SystÃ¨me RAG prÃªt pour les requÃªtes (Notebook 5)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faut il Nettoyer les mÃ©tadonnÃ©es avant dâ€™upser ?\n",
    "\n",
    "Pour identifier l'erreur, donner le requirement, l'env et le notebook a claude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ModÃ¨les Mistral initialisÃ©s\n",
      "âœ… Prompt KPMG configurÃ©\n",
      "\n",
      "============================================================\n",
      "ðŸ” ANALYSE EN COURS...\n",
      "============================================================\n",
      "Question : Quelles sont les derniÃ¨res informations sur Apple ?\n",
      "Namespace : Tous (recherche globale)\n",
      "============================================================\n",
      "\n",
      "**Analyse stratÃ©gique des derniÃ¨res Ã©volutions dâ€™Apple (juin 2024)**\n",
      "\n",
      "Apple Inc. (AAPL) traverse une pÃ©riode charniÃ¨re marquÃ©e par des dÃ©fis macroÃ©conomiques, des innovations technologiques et des ajustements stratÃ©giques. Voici une synthÃ¨se des derniÃ¨res informations clÃ©s, structurÃ©e selon les axes financiers, produits, rÃ©glementaires et concurrentiels, avec une attention particuliÃ¨re aux signaux actionnables pour les investisseurs.\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Performance financiÃ¨re et perspectives (Q2 2024)**\n",
      "Apple a publiÃ© ses rÃ©sultats trimestriels pour le **Q2 2024 (clÃ´turÃ© le 30 mars)** le **2 mai 2024**, rÃ©vÃ©lant un **chiffre dâ€™affaires de 90,8 milliards de dollars**, en baisse de **4,3 % en glissement annuel** [SEC Filing 10-Q Apple | â­â­â­ | 2024-05-02]. Cette contraction, la plus marquÃ©e depuis 2019, sâ€™explique principalement par :\n",
      "- Un **recul de 10 % des ventes dâ€™iPhone** (45,9 Md$), attribuÃ© Ã  la **faible demande en Chine** (â€“8 % sur le marchÃ©) et Ã  un cycle de renouvellement plus long [IDC Worldwide Quarterly Mobile Phone Tracker | â­â­ | 2024-05-15].\n",
      "- Une **baisse de 13 % des ventes de Mac** (7,5 Md$), en partie compensÃ©e par la **croissance de 14 % des services** (23,9 Md$, soit 26 % du CA total), portÃ©e par les abonnements (Apple TV+, Apple Music, iCloud) et les commissions de lâ€™App Store.\n",
      "\n",
      "**Marges** : La marge brute sâ€™est maintenue Ã  **38,4 %** (stable YoY), grÃ¢ce Ã  une **optimisation des coÃ»ts de production** (dÃ©localisation partielle vers lâ€™Inde et le Vietnam) et Ã  la **hausse des prix des services** [Bloomberg Intelligence | â­â­ | 2024-05-03]. Le **bÃ©nÃ©fice net** a reculÃ© de **2,6 %** Ã  23,6 Md$, soit **1,53 $ par action** (lÃ©gÃ¨rement au-dessus des attentes des analystes Ã  1,50 $).\n",
      "\n",
      "**Perspectives** : Pour le **Q3 2024**, Apple anticipe une **croissance modÃ©rÃ©e** (guidance revenue \"similaire Ã  Q2\"), avec un **focus sur lâ€™IA et les services** pour compenser la faiblesse du hardware. Les analystes de **Goldman Sachs** maintiennent un objectif de cours Ã  **210 $** (vs. ~190 $ actuel), tabulant sur un **rebond en 2025** avec le cycle iPhone 16 et les avancÃ©es en IA [Goldman Sachs Research | â­â­ | 2024-05-20].\n",
      "\n",
      "---\n",
      "\n",
      "### **2. StratÃ©gie produit : Lâ€™IA et lâ€™iPhone 16 au cÅ“ur des prioritÃ©s**\n",
      "Apple accÃ©lÃ¨re son **pivot vers lâ€™IA gÃ©nÃ©rative**, un domaine oÃ¹ elle accuse un retard face Ã  Microsoft (Copliot) et Google (Gemini). Lors de la **WWDC 2024 (10-14 juin)**, la firme devrait annoncer :\n",
      "- **iOS 18** : IntÃ©gration profonde de lâ€™IA dans Siri (capacitÃ©s de raisonnement avancÃ©es), Messages (gÃ©nÃ©ration de rÃ©ponses contextuelles), et Xcode (assistant de codage pour dÃ©veloppeurs) [Mark Gurman, Bloomberg | â­â­ | 2024-06-01].\n",
      "- **Partenariats stratÃ©giques** : NÃ©gociations avancÃ©es avec **OpenAI** (intÃ©gration de ChatGPT dans iOS) et **Google** (accÃ¨s Ã  Gemini pour les utilisateurs) [The Information | â­â­ | 2024-05-28]. Ces collaborations visent Ã  combler lâ€™Ã©cart technologique sans dÃ©velopper un LLM maison (trop coÃ»teux en R&D).\n",
      "\n",
      "**iPhone 16** (prÃ©vu en **septembre 2024**) :\n",
      "- **Innovations matÃ©rielles** : Capteur dâ€™image **48 MP ultra-large** (amÃ©lioration en basse lumiÃ¨re), bouton **Capture** dÃ©diÃ© Ã  la photo/vidÃ©o, et puce **A18 Pro** (3 nm, +20 % dâ€™efficacitÃ© Ã©nergÃ©tique) [Ming-Chi Kuo, TF International Securities | â­â­ | 2024-05-30].\n",
      "- **Prix** : Hausse attendue de **50 Ã  100 $** sur les modÃ¨les Pro (iPhone 16 Pro Max Ã  ~1 299 $), justifiÃ©e par les coÃ»ts des composants IA [Wedbush Securities | â­â­ | 2024-06-03].\n",
      "\n",
      "**Autres produits** :\n",
      "- **Vision Pro** : Ventes estimÃ©es Ã  **~200 000 unitÃ©s** depuis son lancement en fÃ©vrier (en dessous des attentes initiales de 400 000) [Counterpoint Research | â­â­ | 2024-05-10]. Apple reporterait une version **low-cost** Ã  2026, se concentrant dâ€™abord sur les dÃ©veloppeurs dâ€™apps.\n",
      "- **Mac** : Transition vers des puces **M4** (annoncÃ©es en mai), avec une **autonomie accrue de 30 %** et des performances IA locales (ex : traitement vidÃ©o en temps rÃ©el) [Apple Press Release | â­â­â­ | 2024-05-07].\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Enjeux rÃ©glementaires et gÃ©opolitiques**\n",
      "Apple fait face Ã  des **pressions croissantes** sur plusieurs fronts :\n",
      "- **Union EuropÃ©enne** :\n",
      "  - **Loi sur les MarchÃ©s NumÃ©riques (DMA)** : Apple a dÃ» ouvrir lâ€™iPhone aux **app stores tiers** et aux **paiements alternatifs** en mars 2024, rÃ©duisant ses commissions (de 30 % Ã  ~10-15 % pour les \"core technology fees\"). Impact estimÃ© : **perte de 1 Ã  2 Md$ de revenus annuels** dâ€™ici 2025 [Financial Times | â­â­ | 2024-04-15].\n",
      "  - **Amende de 1,8 Mdâ‚¬** pour **abus de position dominante** sur les services musicaux (affaire Spotify), confirmÃ©e en mai 2024 [European Commission Press Release | â­â­â­ | 2024-05-22].\n",
      "- **Chine** :\n",
      "  - **Interdiction des iPhone** pour les fonctionnaires (Ã©tendue Ã  12 provinces en 2024) et **concurrence accrue de Huawei** (Pura 70 Ultra, sans composants amÃ©ricains). Part de marchÃ© dâ€™Apple en Chine : **15,7 % en Q1 2024** (vs. 19,7 % en Q1 2023) [Counterpoint Research | â­â­ | 2024-04-30].\n",
      "  - **DÃ©localisation** : 25 % de la production dâ€™iPhone dÃ©placÃ©e vers lâ€™**Inde** (Foxconn Chennai) et le **Vietnam** (Luxshare) pour rÃ©duire les risques gÃ©opolitiques [Nikkei Asia | â­â­ | 2024-05-18].\n",
      "- **Ã‰tats-Unis** :\n",
      "  - **Loi antitrust** : ProcÃ¨s en cours avec le **DOJ** (dÃ©partement de la Justice) pour **monopole sur les smartphones**, risque de scission des services (App Store, Apple Pay) dâ€™ici 2025 [Reuters | â­â­ | 2024-06-02].\n",
      "\n",
      "---\n",
      "\n",
      "### **4. Dynamique concurrentielle et risques**\n",
      "- **IA** : Apple reste en retard sur **Microsoft (Copliot + Windows AI)** et **Google (Gemini + Android)**, mais sa **stratÃ©gie \"privacy-first\"** (traitement local des donnÃ©es) pourrait sÃ©duire les entreprises et les rÃ©gulateurs.\n",
      "- **Hardware** : **Samsung** et **Huawei** gagnent du terrain sur les smartphones haut de gamme (pliant Galaxy Z Fold 6 et Pura 70 Ultra avec camÃ©ra 1 pouce).\n",
      "- **Services** : **Spotify** et **Epic Games** contestent les frais de lâ€™App Store, tandis que **Netflix** et **Disney** renforcent leurs plateformes de streaming (concurrence pour Apple TV+).\n",
      "\n",
      "**Risques majeurs** :\n",
      "1. **Ralentissement en Chine** : Si les tensions commerciales sâ€™aggravent, Apple pourrait perdre **5 Ã  7 Md$ de revenus annuels** (20 % de son CA).\n",
      "2. **Retard en IA** : Sans une offre convaincante dâ€™ici 2025, Apple risque de voir son Ã©cosystÃ¨me perdre en attractivitÃ© pour les dÃ©veloppeurs.\n",
      "3. **RÃ©gulation** : Une scission forcÃ©e de lâ€™App Store ou des restrictions sur les puces (ex : interdiction des semi-conducteurs TSMC pour la Chine) pourraient impacter les marges.\n",
      "\n",
      "---\n",
      "\n",
      "### **5. OpportunitÃ©s et recommandations stratÃ©giques**\n",
      "**Pour les investisseurs** :\n",
      "- **Court terme (6-12 mois)** : VolatilitÃ© attendue en raison des **incertitudes rÃ©glementaires** et du **cycle iPhone 16**. Les services (+14 % YoY) et les rachats dâ€™actions (90 Md$ prÃ©vus en 2024) offrent un filet de sÃ©curitÃ©.\n",
      "- **Long terme (2025+)** :\n",
      "  - **IA et santÃ©** : Apple pourrait capitaliser sur son **Ã©cosystÃ¨me fermÃ©** (iPhone + Watch + HealthKit) pour des solutions mÃ©dicales (ex : dÃ©tection prÃ©coce de maladies via lâ€™Apple Watch Series 10).\n",
      "  - **Ã‰mergents** : Lâ€™Inde (2e marchÃ© mondial dâ€™ici 2027) et le BrÃ©sil (production locale annoncÃ©e) sont des relais de croissance.\n",
      "  - **Dividende** : Rendement actuel de **0,5 %**, mais potentiel de hausse avec une **trÃ©sorerie nette de 165 Md$** [YCharts | â­â­â­ | 2024-06-04].\n",
      "\n",
      "**Secteurs Ã  surveiller** :\n",
      "- **Fournisseurs** : **TSMC** (puces 3 nm), **Foxconn** (assemblage Inde), et **Sony** (capteurs photo) bÃ©nÃ©ficieront du cycle iPhone 16.\n",
      "- **Concurrents** : **Nvidia** (puces IA pour les data centers Apple) et **ASML** (machines de lithographie pour les puces maison).\n",
      "\n",
      "---\n",
      "### **SynthÃ¨se actionnable**\n",
      "| **ThÃ¨me**               | **Signal positif**                          | **Signal nÃ©gatif**                          | **Recommandation**                          |\n",
      "|--------------------------|--------------------------------------------|--------------------------------------------|--------------------------------------------|\n",
      "| **Finances**             | Marges stables, services en croissance     | Baisse des ventes dâ€™iPhone en Chine        | SurpondÃ©rer les services (App Store, cloud) |\n",
      "| **Produits**             | IA intÃ©grÃ©e dans iOS 18, iPhone 16 innovant | Vision Pro en dessous des attentes        | Attendre les retours WWDC avant positionnement |\n",
      "| **RÃ©gulation**           | StratÃ©gie \"privacy\" diffÃ©renciante         | Risque de scission aux Ã‰tats-Unis          | Diversifier lâ€™exposition gÃ©o (Inde, UE)    |\n",
      "| **Concurrence**          | Ã‰cosystÃ¨me fermÃ© (fidÃ©lisation clients)    | Retard en IA vs. Microsoft/Google          | Surveiller les partenariats (OpenAI, Google) |\n",
      "\n",
      "---\n",
      "**Prochaines Ã©tapes critiques** :\n",
      "- **10 juin 2024** : WWDC (annonces IA et iOS 18).\n",
      "- **AoÃ»t 2024** : RÃ©sultats Q3 (indicateurs sur la demande iPhone 15 avant le lancement du 16).\n",
      "- **Septembre 2024** : Lancement iPhone 16 et potentiel \"AI event\".\n",
      "\n",
      "**Sources complÃ©mentaires sur demande** :\n",
      "- DÃ©tail des filings SEC (10-K/Q) pour une analyse financiÃ¨re approfondie.\n",
      "- Benchmark concurrentiel (Samsung, Google, Microsoft) sur les segments IA et hardware.\n",
      "- ScÃ©narios de stress rÃ©glementaires (impact dâ€™une scission de lâ€™App Store).\n",
      "\n",
      "---\n",
      "*Cette analyse repose sur des donnÃ©es disponibles au 5 juin 2024. Pour une Ã©valuation personnalisÃ©e (ex : impact sur un portefeuille spÃ©cifique), une modÃ©lisation financiÃ¨re dÃ©taillÃ©e peut Ãªtre rÃ©alisÃ©e sur demande.*\n",
      "\n",
      "âœ… SystÃ¨me RAG KPMG opÃ©rationnel\n",
      "ðŸŽ¯ PrÃªt pour l'interface Gradio (optionnel)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK 5 : RAG Query & Prompt Engineering pour Veille KPMG\n",
    "============================================================\n",
    "\n",
    "OBJECTIF : CrÃ©er un systÃ¨me de requÃªtes RAG optimisÃ© pour la veille stratÃ©gique\n",
    "           avec prompting avancÃ© et citations obligatoires.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- Mistral Prompting : https://docs.mistral.ai/guides/prompting_capabilities/\n",
    "- LangChain RAG : https://python.langchain.com/docs/use_cases/question_answering/\n",
    "- KPMG Requirements : hackathon KPMG (1).pdf\n",
    "\n",
    "EXIGENCES CRITIQUES :\n",
    "âœ“ Citations systÃ©matiques des sources\n",
    "âœ“ Indication de fiabilitÃ© et date\n",
    "âœ“ RÃ©ponses structurÃ©es (pas de bullet points sauf demande explicite)\n",
    "âœ“ IA explicable (chaÃ®ne de raisonnement)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 1 : INITIALISATION DES COMPOSANTS RAG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "INDEX_NAME = \"kpmg-veille\"\n",
    "\n",
    "# ModÃ¨le d'embeddings\n",
    "embeddings = MistralAIEmbeddings(\n",
    "    model=\"mistral-embed\",\n",
    "    mistral_api_key=MISTRAL_API_KEY\n",
    ")\n",
    "\n",
    "# ModÃ¨le LLM (Mistral Medium pour raisonnement)\n",
    "llm = ChatMistralAI(\n",
    "    model=\"mistral-medium\",\n",
    "    temperature=0,  # DÃ©terministe pour analyses factuelles\n",
    "    mistral_api_key=MISTRAL_API_KEY\n",
    ")\n",
    "\n",
    "print(\"âœ… ModÃ¨les Mistral initialisÃ©s\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 2 : RETRIEVERS PAR NAMESPACE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "STRATÃ‰GIE DE RETRIEVAL\n",
    "\n",
    "On crÃ©e un retriever par namespace pour permettre des requÃªtes ciblÃ©es.\n",
    "L'utilisateur peut spÃ©cifier le namespace ou interroger tous les namespaces.\n",
    "\n",
    "PARAMÃˆTRES :\n",
    "- k=5 : Top 5 documents les plus pertinents\n",
    "- score_threshold : Filtrage par similaritÃ© (optionnel)\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://python.langchain.com/docs/modules/data_connection/retrievers/\n",
    "\"\"\"\n",
    "\n",
    "NAMESPACES = [\n",
    "    \"financial_reports\",\n",
    "    \"news\",\n",
    "    \"macro_data\"\n",
    "]\n",
    "\n",
    "def get_retriever(namespace: Optional[str] = None, k: int = 5):\n",
    "    \"\"\"\n",
    "    CrÃ©e un retriever pour un namespace spÃ©cifique ou global\n",
    "    \n",
    "    Args:\n",
    "        namespace: Namespace ciblÃ© (None = tous les namespaces)\n",
    "        k: Nombre de documents Ã  rÃ©cupÃ©rer\n",
    "    \n",
    "    Returns:\n",
    "        Retriever configurÃ©\n",
    "    \"\"\"\n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=embeddings,\n",
    "        namespace=namespace  # None = recherche sur tous les namespaces\n",
    "    )\n",
    "    \n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": k}\n",
    "    )\n",
    "    \n",
    "    return retriever\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 3 : PROMPT ENGINEERING KPMG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "PROMPT STRUCTURÃ‰ SELON LES EXIGENCES KPMG\n",
    "\n",
    "InspirÃ© de vos notes (hackathon KPMG.pdf) :\n",
    "âœ“ Assistant Intelligent de Veille StratÃ©gique\n",
    "âœ“ Citations OBLIGATOIRES avec source, date, fiabilitÃ©\n",
    "âœ“ RÃ©ponse en prose (pas de bullet points par dÃ©faut)\n",
    "âœ“ Indication si donnÃ©es manquantes ou payantes\n",
    "âœ“ CapacitÃ© Ã  demander des prÃ©cisions\n",
    "\n",
    "STRUCTURE :\n",
    "1. RÃ´le et expertise\n",
    "2. Instructions de citation\n",
    "3. Format de rÃ©ponse\n",
    "4. Gestion des cas limites\n",
    "\"\"\"\n",
    "\n",
    "KPMG_PROMPT_TEMPLATE = \"\"\"Vous Ãªtes l'Assistant Intelligent de Veille StratÃ©gique de KPMG Global Strategy Group.\n",
    "\n",
    "Votre mission : Fournir des analyses de marchÃ© prÃ©cises, sourcÃ©es et actionnables pour aider nos clients Ã  prendre des dÃ©cisions d'investissement Ã©clairÃ©es.\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "RÃˆGLES DE CITATION (OBLIGATOIRES)\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "Pour CHAQUE information factuelle (chiffres, dates, faits) vous DEVEZ :\n",
    "1. Citer la source exacte (ex: \"SEC Filing 10-K d'Apple - 2024-01-15\")\n",
    "2. Indiquer le niveau de fiabilitÃ© :\n",
    "   - â­â­â­ : Source primaire (SEC, rapport officiel, yfinance)\n",
    "   - â­â­ : Source secondaire fiable (NewsAPI, presse reconnue)\n",
    "   - â­ : Source tertiaire (blogs, rÃ©seaux sociaux)\n",
    "3. PrÃ©ciser la date de l'information si critique\n",
    "\n",
    "Format de citation : [Source | FiabilitÃ© | Date]\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "CONTEXTE DISPONIBLE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "{context}\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "QUESTION DU CLIENT\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "{question}\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "INSTRUCTIONS DE RÃ‰PONSE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "1. STRUCTURE :\n",
    "   - RÃ©pondez en prose fluide (paragraphes, pas de bullet points)\n",
    "   - Organisez votre rÃ©ponse de faÃ§on logique et narrative\n",
    "   - Utilisez des transitions naturelles entre les idÃ©es\n",
    "\n",
    "2. CONTENU :\n",
    "   - Citez systÃ©matiquement vos sources (format ci-dessus)\n",
    "   - Si une donnÃ©e est manquante : indiquez-le explicitement\n",
    "   - Si une information nÃ©cessite un accÃ¨s payant : prÃ©cisez-le\n",
    "   - Si le contexte est ambigu : demandez des prÃ©cisions au client\n",
    "\n",
    "3. TONE :\n",
    "   - Professionnel mais accessible\n",
    "   - Factuel et analytique\n",
    "   - Confiant sur les donnÃ©es sourcÃ©es, prudent sur les spÃ©culations\n",
    "\n",
    "4. CAS LIMITES :\n",
    "   - Si vous ne trouvez pas l'information : \"Les donnÃ©es disponibles ne permettent pas de rÃ©pondre Ã  cette question. Sources consultÃ©es : [liste]. Je recommande [action].\"\n",
    "   - Si deux sources se contredisent : Mentionnez les deux et expliquez pourquoi\n",
    "   - Si une entreprise est ambiguÃ« : \"J'ai identifiÃ© plusieurs entreprises nommÃ©es [X]. Pouvez-vous prÃ©ciser : secteur, gÃ©ographie, ou autre contexte ?\"\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "RÃ‰PONSE ANALYTIQUE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(KPMG_PROMPT_TEMPLATE)\n",
    "\n",
    "print(\"âœ… Prompt KPMG configurÃ©\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 4 : FORMATAGE DU CONTEXTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "FORMATAGE DES DOCUMENTS RÃ‰CUPÃ‰RÃ‰S\n",
    "\n",
    "On enrichit le contexte avec :\n",
    "- Source et type de document\n",
    "- Date de publication/scraping\n",
    "- Namespace d'origine\n",
    "- Score de pertinence (si disponible)\n",
    "\"\"\"\n",
    "\n",
    "def format_docs(docs) -> str:\n",
    "    \"\"\"\n",
    "    Formate les documents rÃ©cupÃ©rÃ©s pour le prompt\n",
    "    \n",
    "    Args:\n",
    "        docs: Documents LangChain\n",
    "    \n",
    "    Returns:\n",
    "        String formatÃ© avec mÃ©tadonnÃ©es enrichies\n",
    "    \"\"\"\n",
    "    formatted = []\n",
    "    \n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        metadata = doc.metadata\n",
    "        \n",
    "        # Construction de l'entrÃ©e\n",
    "        entry = f\"â”â”â” DOCUMENT {i} â”â”â”\\n\"\n",
    "        entry += f\"Source : {metadata.get('source', 'Unknown')}\\n\"\n",
    "        entry += f\"Type : {metadata.get('namespace', 'Unknown')}\\n\"\n",
    "        \n",
    "        # Date si disponible\n",
    "        date_fields = ['filing_date', 'published_at', 'scrape_date', 'retrieval_date']\n",
    "        for field in date_fields:\n",
    "            if field in metadata:\n",
    "                entry += f\"Date : {metadata[field]}\\n\"\n",
    "                break\n",
    "        \n",
    "        # URL si disponible\n",
    "        if 'url' in metadata:\n",
    "            entry += f\"URL : {metadata['url']}\\n\"\n",
    "        \n",
    "        # Contenu\n",
    "        entry += f\"\\nContenu :\\n{doc.page_content}\\n\"\n",
    "        \n",
    "        formatted.append(entry)\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 5 : CHAÃŽNE RAG COMPLÃˆTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "ARCHITECTURE LCEL (LangChain Expression Language)\n",
    "\n",
    "Pipeline : Retriever â†’ Format Context â†’ Prompt â†’ LLM â†’ Parse\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://python.langchain.com/docs/expression_language/\n",
    "\"\"\"\n",
    "\n",
    "def create_rag_chain(namespace: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    CrÃ©e une chaÃ®ne RAG complÃ¨te\n",
    "    \n",
    "    Args:\n",
    "        namespace: Namespace ciblÃ© (None = tous)\n",
    "    \n",
    "    Returns:\n",
    "        ChaÃ®ne RAG exÃ©cutable\n",
    "    \"\"\"\n",
    "    retriever = get_retriever(namespace=namespace, k=5)\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\n",
    "            \"context\": retriever | format_docs,\n",
    "            \"question\": RunnablePassthrough()\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    return rag_chain\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 6 : INTERFACE DE REQUÃŠTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "FONCTIONS D'INTERFACE UTILISATEUR\n",
    "\n",
    "Permettent d'interroger le systÃ¨me de diffÃ©rentes maniÃ¨res :\n",
    "- RequÃªte simple (tous namespaces)\n",
    "- RequÃªte ciblÃ©e (namespace spÃ©cifique)\n",
    "- RequÃªte multi-namespaces (comparaison)\n",
    "\"\"\"\n",
    "\n",
    "def query_veille(question: str, namespace: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Interface principale de requÃªte\n",
    "    \n",
    "    Args:\n",
    "        question: Question de l'utilisateur\n",
    "        namespace: Namespace ciblÃ© (optionnel)\n",
    "    \n",
    "    Returns:\n",
    "        RÃ©ponse formatÃ©e avec citations\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ” ANALYSE EN COURS...\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Question : {question}\")\n",
    "    \n",
    "    if namespace:\n",
    "        print(f\"Namespace : {namespace}\")\n",
    "    else:\n",
    "        print(\"Namespace : Tous (recherche globale)\")\n",
    "    \n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    try:\n",
    "        chain = create_rag_chain(namespace)\n",
    "        response = chain.invoke(question)\n",
    "        return response\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"âŒ Erreur lors de la requÃªte : {e}\"\n",
    "\n",
    "def compare_namespaces(question: str, namespaces: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Compare les rÃ©ponses de plusieurs namespaces\n",
    "    \n",
    "    Args:\n",
    "        question: Question\n",
    "        namespaces: Liste de namespaces Ã  comparer\n",
    "    \n",
    "    Returns:\n",
    "        Dictionnaire {namespace: rÃ©ponse}\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for ns in namespaces:\n",
    "        print(f\"\\nðŸ“ Interrogation de '{ns}'...\")\n",
    "        results[ns] = query_veille(question, namespace=ns)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 7 : EXEMPLES D'UTILISATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "SCÃ‰NARIOS DE DÃ‰MONSTRATION KPMG\n",
    "\n",
    "Ces exemples illustrent les capacitÃ©s du systÃ¨me :\n",
    "1. Analyse de marchÃ©\n",
    "2. Due diligence d'entreprise\n",
    "3. DÃ©tection de tendances\n",
    "4. Analyse concurrentielle\n",
    "\"\"\"\n",
    "\n",
    "def demo_scenarios():\n",
    "    \"\"\"DÃ©montre les capacitÃ©s du systÃ¨me avec des cas rÃ©els\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"ðŸŽ¯ \"*20)\n",
    "    print(\" DÃ‰MONSTRATION RAG VEILLE KPMG\")\n",
    "    print(\"ðŸŽ¯ \"*20 + \"\\n\")\n",
    "    \n",
    "    scenarios = [\n",
    "        {\n",
    "            \"titre\": \"1. ANALYSE FINANCIÃˆRE D'ENTREPRISE\",\n",
    "            \"question\": \"Quelle est la capitalisation boursiÃ¨re actuelle d'Apple et son Ã©volution ?\",\n",
    "            \"namespace\": \"macro_data\"\n",
    "        },\n",
    "        {\n",
    "            \"titre\": \"2. VEILLE ACTUALITÃ‰S SECTEUR TECH\",\n",
    "            \"question\": \"Quelles sont les derniÃ¨res actualitÃ©s concernant l'intelligence artificielle et la finance ?\",\n",
    "            \"namespace\": \"news\"\n",
    "        },\n",
    "        {\n",
    "            \"titre\": \"3. RECHERCHE GLOBALE (TOUS NAMESPACES)\",\n",
    "            \"question\": \"Quels sont les principaux risques et opportunitÃ©s pour les entreprises tech en 2024 ?\",\n",
    "            \"namespace\": None\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        print(\"\\n\" + \"â”€\"*60)\n",
    "        print(f\"ðŸ“Š {scenario['titre']}\")\n",
    "        print(\"â”€\"*60)\n",
    "        \n",
    "        response = query_veille(\n",
    "            question=scenario['question'],\n",
    "            namespace=scenario['namespace']\n",
    "        )\n",
    "        \n",
    "        print(\"\\nðŸ’¡ RÃ‰PONSE :\\n\")\n",
    "        print(response)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 8 : EXÃ‰CUTION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Exemple simple\n",
    "    question = \"Quelles sont les derniÃ¨res informations sur Apple ?\"\n",
    "    response = query_veille(question)\n",
    "    print(response)\n",
    "    \n",
    "    # DÃ©commenter pour la dÃ©mo complÃ¨te\n",
    "    # demo_scenarios()\n",
    "    \n",
    "    print(\"\\nâœ… SystÃ¨me RAG KPMG opÃ©rationnel\")\n",
    "    print(\"ðŸŽ¯ PrÃªt pour l'interface Gradio (optionnel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Initialisation de l'interface KPMG (mistral-small)...\n",
      "âœ… Variables d'environnement chargÃ©es\n",
      "âœ… Embeddings initialisÃ©s\n",
      "âœ… Retriever configurÃ©\n",
      "âœ… LLM Mistral Small initialisÃ©\n",
      "âœ… Prompt configurÃ©\n",
      "âœ… ChaÃ®ne RAG construite\n",
      "âœ… Modules rechargÃ©s Ã  chaud !\n",
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Gradio Blocks instance: 37 backend functions\n",
       "--------------------------------------------\n",
       "fn_index=0\n",
       " inputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12d5151d0>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12d515310>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12d515590>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12d5156d0>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12d515810>\n",
       " outputs:\n",
       " |-<gradio.components.html.HTML object at 0x12d516210>\n",
       "fn_index=1\n",
       " inputs:\n",
       " |-<gradio.components.slider.Slider object at 0x12d515d10>\n",
       " |-<gradio.components.slider.Slider object at 0x12d515e50>\n",
       " |-<gradio.components.slider.Slider object at 0x12d515f90>\n",
       " outputs:\n",
       " |-<gradio.components.html.HTML object at 0x12d516d50>\n",
       " |-<gradio.components.html.HTML object at 0x12d516e90>\n",
       " |-<gradio.components.html.HTML object at 0x12d516fd0>\n",
       " |-<gradio.components.plot.Plot object at 0x12d517390>\n",
       " |-<gradio.components.html.HTML object at 0x12d517610>\n",
       " |-<gradio.components.dataframe.Dataframe object at 0x12d517750>\n",
       "fn_index=2\n",
       " inputs:\n",
       " |-<gradio.components.slider.Slider object at 0x12d515d10>\n",
       " |-<gradio.components.slider.Slider object at 0x12d515e50>\n",
       " |-<gradio.components.slider.Slider object at 0x12d515f90>\n",
       " outputs:\n",
       " |-<gradio.components.html.HTML object at 0x12d516d50>\n",
       " |-<gradio.components.html.HTML object at 0x12d516e90>\n",
       " |-<gradio.components.html.HTML object at 0x12d516fd0>\n",
       " |-<gradio.components.plot.Plot object at 0x12d517390>\n",
       " |-<gradio.components.html.HTML object at 0x12d517610>\n",
       " |-<gradio.components.dataframe.Dataframe object at 0x12d517750>\n",
       "fn_index=3\n",
       " inputs:\n",
       " |-<gradio.components.slider.Slider object at 0x12d515d10>\n",
       " |-<gradio.components.slider.Slider object at 0x12d515e50>\n",
       " |-<gradio.components.slider.Slider object at 0x12d515f90>\n",
       " outputs:\n",
       " |-<gradio.components.html.HTML object at 0x12d516d50>\n",
       " |-<gradio.components.html.HTML object at 0x12d516e90>\n",
       " |-<gradio.components.html.HTML object at 0x12d516fd0>\n",
       " |-<gradio.components.plot.Plot object at 0x12d517390>\n",
       " |-<gradio.components.html.HTML object at 0x12d517610>\n",
       " |-<gradio.components.dataframe.Dataframe object at 0x12d517750>\n",
       "fn_index=4\n",
       " inputs:\n",
       " |-<gradio.components.slider.Slider object at 0x12d515d10>\n",
       " |-<gradio.components.slider.Slider object at 0x12d515e50>\n",
       " |-<gradio.components.slider.Slider object at 0x12d515f90>\n",
       " outputs:\n",
       " |-<gradio.components.html.HTML object at 0x12d516d50>\n",
       " |-<gradio.components.html.HTML object at 0x12d516e90>\n",
       " |-<gradio.components.html.HTML object at 0x12d516fd0>\n",
       " |-<gradio.components.plot.Plot object at 0x12d517390>\n",
       " |-<gradio.components.html.HTML object at 0x12d517610>\n",
       " |-<gradio.components.dataframe.Dataframe object at 0x12d517750>\n",
       "fn_index=5\n",
       " inputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12d5151d0>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12d515310>\n",
       " outputs:\n",
       " |-<gradio.components.plot.Plot object at 0x12d516710>\n",
       " |-<gradio.components.plot.Plot object at 0x12d516850>\n",
       " |-<gradio.components.plot.Plot object at 0x12d516990>\n",
       "fn_index=6\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.markdown.Markdown object at 0x12d41b4d0>\n",
       " |-<gradio.components.dataframe.Dataframe object at 0x12d41b890>\n",
       " |-<gradio.components.dataframe.Dataframe object at 0x12d41bb10>\n",
       " |-<gradio.components.dataframe.Dataframe object at 0x12d41bd90>\n",
       " |-<gradio.components.dataframe.Dataframe object at 0x12d41ad50>\n",
       " |-<gradio.components.html.HTML object at 0x12d41a490>\n",
       " |-<gradio.components.dataframe.Dataframe object at 0x12d41a850>\n",
       "fn_index=7\n",
       " inputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12c55dd10>\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12c55dd10>\n",
       " |-<gradio.components.state.State object at 0x12c55d810>\n",
       "fn_index=8\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12c55d810>\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       " outputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       "fn_index=9\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12c55d810>\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12c55d6d0>\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       "fn_index=10\n",
       " inputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " |-<gradio.components.state.State object at 0x12c55e710>\n",
       "fn_index=11\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12c55dd10>\n",
       "fn_index=12\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12c55fed0>\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12c55fd90>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12c55fed0>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12c55fd90>\n",
       "fn_index=13\n",
       " inputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12c55dd10>\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " outputs:\n",
       " |-<gradio.components.json_component.JSON object at 0x12c55df90>\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       "fn_index=14\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " |-<gradio.components.state.State object at 0x12c55d810>\n",
       "fn_index=15\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12c55d810>\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " outputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       "fn_index=16\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12c55dd10>\n",
       "fn_index=17\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12c55d810>\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12c55d6d0>\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       "fn_index=18\n",
       " inputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " |-<gradio.components.state.State object at 0x12c55e710>\n",
       "fn_index=19\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12c55dd10>\n",
       "fn_index=20\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12c55fed0>\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12c55fd90>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12c55fed0>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12c55fd90>\n",
       "fn_index=21\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12c55dd10>\n",
       "fn_index=22\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12c55dd10>\n",
       "fn_index=23\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12c55dd10>\n",
       "fn_index=24\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12c55dd10>\n",
       "fn_index=25\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12c55dd10>\n",
       "fn_index=28\n",
       " inputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       " outputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       " |-<gradio.components.textbox.Textbox object at 0x12c55dd10>\n",
       "fn_index=29\n",
       " inputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " |-<gradio.components.state.State object at 0x12c55e710>\n",
       "fn_index=30\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12c55fed0>\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12c55fd90>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12c55fed0>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12c55fd90>\n",
       "fn_index=31\n",
       " inputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       " outputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       " |-<gradio.components.state.State object at 0x12c55d810>\n",
       "fn_index=32\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12c55d810>\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12c55d6d0>\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       "fn_index=33\n",
       " inputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " |-<gradio.components.state.State object at 0x12c55e710>\n",
       "fn_index=34\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12c55fed0>\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12c55fd90>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12c55fed0>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12c55fd90>\n",
       "fn_index=35\n",
       " inputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " |-<gradio.components.state.State object at 0x12c55e710>\n",
       "fn_index=36\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12c55fed0>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12c55fd90>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12c55fed0>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12c55fd90>\n",
       "fn_index=37\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12c55e710>\n",
       " outputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       "fn_index=38\n",
       " inputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12c55d950>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12c55e5d0>\n",
       " |-<gradio.components.state.State object at 0x12c55e710>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ [MARKET GENERATION] Estimation MULTI-MÃ‰THODES du marchÃ© pour : Logiciels de Gestion pour PME en France (Horizon 2025) - EUR\n",
      "âœ… [MARKET GENERATION] 8 Facts Granulaires GÃ©nÃ©rÃ©s\n",
      "ðŸ—‘ï¸ Facts Manager: All facts cleared.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GRADIO INTERFACE - VERSION AVEC MISTRAL-SMALL (GRATUIT)\n",
    "========================================================\n",
    "\n",
    "Cette version utilise mistral-small au lieu de mistral-medium.\n",
    "Performance lÃ©gÃ¨rement infÃ©rieure mais GRATUIT et SUFFISANT pour votre dÃ©mo.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "import kpmg_interface\n",
    "import importlib\n",
    "import analytics_viz\n",
    "import facts_manager\n",
    "import market_estimation_engine\n",
    "import strategic_facts_service\n",
    "\n",
    "from langchain_mistralai import ChatMistralAI, MistralAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# INITIALISATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ðŸ”§ Initialisation de l'interface KPMG (mistral-small)...\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "INDEX_NAME = \"kpmg-veille\"\n",
    "\n",
    "if not MISTRAL_API_KEY or not PINECONE_API_KEY:\n",
    "    raise ValueError(\"âŒ ClÃ©s API manquantes dans .env\")\n",
    "\n",
    "print(\"âœ… Variables d'environnement chargÃ©es\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# COMPOSANTS RAG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "try:\n",
    "    # Embeddings\n",
    "    embeddings = MistralAIEmbeddings(\n",
    "        model=\"mistral-embed\",\n",
    "        mistral_api_key=MISTRAL_API_KEY\n",
    "    )\n",
    "    print(\"âœ… Embeddings initialisÃ©s\")\n",
    "    \n",
    "    # Vector Store\n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=embeddings,\n",
    "        namespace=\"news\"\n",
    "    )\n",
    "    \n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 3}\n",
    "    )\n",
    "    print(\"âœ… Retriever configurÃ©\")\n",
    "    \n",
    "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "    # â•‘ CHANGEMENT CRITIQUE : mistral-medium â†’ mistral-small    â•‘\n",
    "    # â•‘                                                           â•‘\n",
    "    # â•‘ Mistral-small est GRATUIT et suffisant pour du RAG      â•‘\n",
    "    # â•‘ Performance : 85% de mistral-medium Ã  coÃ»t zÃ©ro         â•‘\n",
    "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    \n",
    "    llm = ChatMistralAI(\n",
    "        model=\"mistral-small\",  # âœ… MODÃˆLE GRATUIT\n",
    "        temperature=0,\n",
    "        mistral_api_key=MISTRAL_API_KEY\n",
    "    )\n",
    "    print(\"âœ… LLM Mistral Small initialisÃ©\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur lors de l'initialisation : {e}\")\n",
    "    raise\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PROMPT KPMG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "KPMG_PROMPT_TEMPLATE = \"\"\"Vous Ãªtes l'Assistant Intelligent de Veille StratÃ©gique de KPMG Global Strategy Group.\n",
    "\n",
    "Votre mission : Fournir des analyses de marchÃ© prÃ©cises, sourcÃ©es et actionnables pour aider nos clients Ã  prendre des dÃ©cisions d'investissement Ã©clairÃ©es.\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "RÃˆGLES DE CITATION (OBLIGATOIRES)\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "Pour CHAQUE information factuelle (chiffres, dates, faits) vous DEVEZ :\n",
    "1. Citer la source exacte (ex: \"https://www.apple.com - 2024-01-15\")\n",
    "2. Indiquer le niveau de fiabilitÃ© :\n",
    "   - *** : Source primaire (SEC, rapport officiel, yfinance)\n",
    "   - ** : Source secondaire fiable (NewsAPI, presse reconnue)\n",
    "   - * : Source tertiaire (blogs, rÃ©seaux sociaux)\n",
    "3. PrÃ©ciser la date de l'information si critique\n",
    "\n",
    "Format de citation : [Source au format URL | FiabilitÃ© | Date]\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "CONTEXTE DISPONIBLE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "{context}\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "QUESTION DU CLIENT\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "{question}\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "INSTRUCTIONS DE RÃ‰PONSE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "1. STRUCTURE :\n",
    "   - RÃ©pondez en prose fluide (paragraphes, pas de bullet points)\n",
    "   - Organisez votre rÃ©ponse de faÃ§on logique et narrative\n",
    "   - Utilisez des transitions naturelles entre les idÃ©es\n",
    "\n",
    "2. CONTENU :\n",
    "   - Citez systÃ©matiquement vos sources (format ci-dessus)\n",
    "   - Si une donnÃ©e est manquante : indiquez-le explicitement\n",
    "   - Si une information nÃ©cessite un accÃ¨s payant : prÃ©cisez-le\n",
    "   - Si le contexte est ambigu : demandez des prÃ©cisions au client\n",
    "\n",
    "3. TONE :\n",
    "   - Professionnel mais accessible\n",
    "   - Factuel et analytique\n",
    "   - Confiant sur les donnÃ©es sourcÃ©es, prudent sur les spÃ©culations\n",
    "\n",
    "4. CAS LIMITES :\n",
    "   - Si vous ne trouvez pas l'information : \"Les donnÃ©es disponibles ne permettent pas de rÃ©pondre Ã  cette question. Sources consultÃ©es : [liste]. Je recommande [action].\"\n",
    "   - Si deux sources se contredisent : Mentionnez les deux et expliquez pourquoi\n",
    "   - Si une entreprise est ambiguÃ« : \"J'ai identifiÃ© plusieurs entreprises nommÃ©es [X]. Pouvez-vous prÃ©ciser : secteur, gÃ©ographie, ou autre contexte ?\"\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "RÃ‰PONSE ANALYTIQUE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(KPMG_PROMPT_TEMPLATE )\n",
    "print(\"âœ… Prompt configurÃ©\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CHAÃŽNE RAG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"Formate les documents rÃ©cupÃ©rÃ©s\"\"\"\n",
    "    if not docs:\n",
    "        return \"Aucun document pertinent trouvÃ©.\"\n",
    "    \n",
    "    formatted = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        date = doc.metadata.get('published_at', doc.metadata.get('scrape_date', 'N/A'))\n",
    "        content = doc.page_content[:500]\n",
    "        \n",
    "        formatted.append(f\"[Document {i} - Source: {source} - Date: {date}]\\n{content}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"âœ… ChaÃ®ne RAG construite\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FONCTION STREAMING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def stream_kpmg_response(message, history):\n",
    "    \"\"\"GÃ©nÃ¨re la rÃ©ponse de maniÃ¨re progressive\"\"\"\n",
    "    try:\n",
    "        partial_message = \"\"\n",
    "        \n",
    "        for chunk in rag_chain.stream(message):\n",
    "            partial_message += chunk\n",
    "            yield partial_message\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = f\"\"\"âŒ Erreur lors de la recherche :\n",
    "        \n",
    "DÃ©tails : {str(e)}\n",
    "\n",
    "Suggestions :\n",
    "1. VÃ©rifiez que l'index Pinecone contient des donnÃ©es (âœ… Vous avez 118 vecteurs)\n",
    "2. Testez avec une question plus simple\n",
    "3. VÃ©rifiez les crÃ©dits Mistral sur console.mistral.ai\"\"\"\n",
    "        \n",
    "        yield error_msg\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# INTERFACE GRADIO â€“ STYLE TERMINAL RÃ‰TRO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\" theme = gr.themes.Base().set(\n",
    "    body_background_fill=\"#0f0f0f\",\n",
    "    body_text_color=\"#c6f6d5\",\n",
    "    button_primary_background_fill=\"#0f0f0f\",\n",
    "    button_primary_text_color=\"#c6f6d5\",\n",
    "    input_background_fill=\"#0f0f0f\",\n",
    "    input_border_color=\"#c6f6d5\"\n",
    ")\n",
    "\n",
    "\n",
    "custom_css = \n",
    "@import url('https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@400;600&display=swap');\n",
    "\n",
    "* {\n",
    "    font-family: 'Source Code Pro', monospace;\n",
    "    box-shadow: none !important;\n",
    "    border-radius: 0 !important;\n",
    "}\n",
    "\n",
    "body {\n",
    "    background-color: #0f0f0f;\n",
    "}\n",
    "\n",
    "h1 {\n",
    "    color: #c6f6d5;\n",
    "    text-align: left;\n",
    "    font-weight: 600;\n",
    "    margin-bottom: 8px;\n",
    "}\n",
    "\n",
    ".gr-chatbot {\n",
    "    background: transparent !important;\n",
    "    border: none !important;\n",
    "    padding: 0 !important;\n",
    "}\n",
    "\n",
    ".gr-chatbot .message {\n",
    "    padding: 2px 0 !important;\n",
    "    line-height: 1.6;\n",
    "}\n",
    "\n",
    ".gr-chatbot .message.user {\n",
    "    color: #9ae6b4;\n",
    "}\n",
    "\n",
    ".gr-chatbot .message.bot {\n",
    "    color: #e6fffa;\n",
    "}\n",
    "\n",
    "textarea, input {\n",
    "    background: transparent !important;\n",
    "    color: #c6f6d5 !important;\n",
    "    border: none !important;\n",
    "    border-bottom: 1px solid #c6f6d5 !important;\n",
    "}\n",
    "\n",
    "button {\n",
    "    background: transparent !important;\n",
    "    color: #c6f6d5 !important;\n",
    "    border: none !important;\n",
    "    padding: 4px 8px !important;\n",
    "}\n",
    "\n",
    "button:hover {\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=stream_kpmg_response,\n",
    "    title=\"KPMG Analytics\",\n",
    "    description=\"Assistant de Veille StratÃ©gique alimentÃ© par Mistral-Small.\",\n",
    "    examples=[\n",
    "        \"Quelles sont les derniÃ¨res actualitÃ©s sur Apple ?\",\n",
    "        \"Capitalisation boursiÃ¨re de Microsoft ?\",\n",
    "        \"Risques pour le secteur Tech ?\"\n",
    "    ]\n",
    ")\n",
    "    \n",
    "    # OPTION 2 : Avec partage public (dÃ©commentez pour le jury)\n",
    "    # demo.launch(\n",
    "    #     share=True,\n",
    "    #     inline=False,\n",
    "    #     show_error=True,\n",
    "    #     quiet=False\n",
    "    # )\n",
    "    \n",
    "demo.launch(share=True) \"\"\"\n",
    "importlib.reload(facts_manager)\n",
    "importlib.reload(market_estimation_engine)\n",
    "importlib.reload(analytics_viz)\n",
    "importlib.reload(kpmg_interface)\n",
    "importlib.reload(strategic_facts_service) \n",
    "print(\"âœ… Modules rechargÃ©s Ã  chaud !\")\n",
    "# Lance le dashboard\n",
    "kpmg_interface.launch_dashboard(stream_kpmg_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ \n",
      "   DIAGNOSTIC COMPLET DU SYSTÃˆME RAG KPMG\n",
      "ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ \n",
      "\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Variables d'environnement\n",
      "============================================================\n",
      "   MISTRAL_API_KEY: HMMmZlVbL9...\n",
      "   PINECONE_API_KEY: pcsk_576Qs...\n",
      "âœ… Variables d'environnement : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Ã‰tat de Pinecone\n",
      "============================================================\n",
      "   Index : kpmg-veille\n",
      "   Total vecteurs : 109\n",
      "   Dimension : 1024\n",
      "\n",
      "   ðŸ“ Namespaces :\n",
      "      - news: 107 vecteurs\n",
      "      - macro_data: 2 vecteurs\n",
      "âœ… Ã‰tat de Pinecone : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Mistral Embeddings\n",
      "============================================================\n",
      "   Texte : 'Apple annonce de nouveaux produits'\n",
      "   Dimension : 1024\n",
      "   Type : <class 'list'>\n",
      "   Premiers 5 valeurs : [-0.0162811279296875, 0.0140228271484375, 0.052886962890625, -0.0181427001953125, 0.04644775390625]\n",
      "âœ… Mistral Embeddings : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Mistral LLM\n",
      "============================================================\n",
      "   ModÃ¨le : mistral-medium\n",
      "   Question : Capitale de la France ?\n",
      "   RÃ©ponse : Paris.\n",
      "âœ… Mistral LLM : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Retriever\n",
      "============================================================\n",
      "   Query : 'Apple derniÃ¨res actualitÃ©s'\n",
      "   Namespace : news\n",
      "   RÃ©sultats : 3 documents\n",
      "\n",
      "   ðŸ“„ Premier rÃ©sultat :\n",
      "      Source : press_release\n",
      "      Contenu : Newsroom - Apple\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "AppleStoreMaciPadiPhoneWatch\n",
      "VisionAirPodsTV & HomeEntertainmentAccessoriesSupport\n",
      "\n",
      "\n",
      "0+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsroom\n",
      "\n",
      "...\n",
      "âœ… Retriever : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : ChaÃ®ne RAG complÃ¨te\n",
      "============================================================\n",
      "   Question : 'Quelles sont les derniÃ¨res actualitÃ©s ?'\n",
      "   Traitement...\n",
      "\n",
      "   âœ… RÃ©ponse gÃ©nÃ©rÃ©e (1906 caractÃ¨res) :\n",
      "   Voici quelques-unes des **derniÃ¨res actualitÃ©s** d'Apple (juin 2024) disponibles sur leur **Newsroom** (Ã  vÃ©rifier sur [apple.com/newsroom](https://www.apple.com/newsroom/) pour les mises Ã  jour en temps rÃ©el) :\n",
      "\n",
      "### **Principales annonces rÃ©centes** :\n",
      "1. **WWDC 2024** (10-14 juin) :\n",
      "   - **iOS 18**...\n",
      "âœ… ChaÃ®ne RAG complÃ¨te : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Gradio\n",
      "============================================================\n",
      "   Version : 6.3.0\n",
      "âœ… Gradio : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š RAPPORT FINAL\n",
      "============================================================\n",
      "\n",
      "Tests rÃ©ussis : 7/7\n",
      "\n",
      "ðŸŽ‰ TOUS LES TESTS SONT PASSÃ‰S !\n",
      "âœ… Votre systÃ¨me est prÃªt pour Gradio\n",
      "\n",
      "ðŸ’¡ Prochaine Ã©tape :\n",
      "   ExÃ©cutez la cellule 'gradio_interface_fixed.py'\n",
      "\n",
      "============================================================\n",
      "âœ… Diagnostic terminÃ©\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ [MARKET GENERATION] Estimation MULTI-MÃ‰THODES du marchÃ© pour : Logiciels de Gestion pour PME en France (Horizon 2025) - EUR\n",
      "âœ… [MARKET GENERATION] 8 Facts Granulaires GÃ©nÃ©rÃ©s\n",
      "DEBUG UI: Reloading Engine with 48 facts\n",
      "DEBUG UI: Engine returned DF with shape (48, 6)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SCRIPT DE TEST COMPLET - SYSTÃˆME RAG KPMG\n",
    "==========================================\n",
    "\n",
    "ExÃ©cutez ce script pour diagnostiquer tous les problÃ¨mes potentiels.\n",
    "Copier-coller dans une nouvelle cellule de notebook.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FONCTION DE TEST AVEC GESTION D'ERREURS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def run_test(test_name, test_func):\n",
    "    \"\"\"ExÃ©cute un test et affiche le rÃ©sultat\"\"\"\n",
    "    try:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ðŸ§ª TEST : {test_name}\")\n",
    "        print('='*60)\n",
    "        result = test_func()\n",
    "        print(f\"âœ… {test_name} : RÃ‰USSI\")\n",
    "        return True, result\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {test_name} : Ã‰CHOUÃ‰\")\n",
    "        print(f\"   Erreur : {str(e)}\")\n",
    "        return False, None\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 1 : ENVIRONNEMENT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_environment():\n",
    "    \"\"\"VÃ©rifie les variables d'environnement\"\"\"\n",
    "    load_dotenv()\n",
    "    \n",
    "    required_vars = {\n",
    "        \"MISTRAL_API_KEY\": os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        \"PINECONE_API_KEY\": os.getenv(\"PINECONE_API_KEY\")\n",
    "    }\n",
    "    \n",
    "    missing = [k for k, v in required_vars.items() if not v]\n",
    "    \n",
    "    if missing:\n",
    "        raise ValueError(f\"Variables manquantes : {', '.join(missing)}\")\n",
    "    \n",
    "    for key, value in required_vars.items():\n",
    "        masked = value[:10] + \"...\" if value else \"None\"\n",
    "        print(f\"   {key}: {masked}\")\n",
    "    \n",
    "    return required_vars\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 2 : PINECONE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_pinecone():\n",
    "    \"\"\"VÃ©rifie l'Ã©tat de l'index Pinecone\"\"\"\n",
    "    from pinecone import Pinecone\n",
    "    \n",
    "    pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "    index = pc.Index(\"kpmg-veille\")\n",
    "    stats = index.describe_index_stats()\n",
    "    \n",
    "    print(f\"   Index : kpmg-veille\")\n",
    "    print(f\"   Total vecteurs : {stats.total_vector_count}\")\n",
    "    print(f\"   Dimension : 1024\")\n",
    "    \n",
    "    if stats.total_vector_count == 0:\n",
    "        print(\"   âš ï¸  ATTENTION : Aucune donnÃ©e indexÃ©e !\")\n",
    "        print(\"   â†’ ExÃ©cutez les Notebooks 2, 3 et 4\")\n",
    "        raise ValueError(\"Index vide\")\n",
    "    \n",
    "    print(f\"\\n   ðŸ“ Namespaces :\")\n",
    "    for ns, info in stats.namespaces.items():\n",
    "        print(f\"      - {ns}: {info.vector_count} vecteurs\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 3 : MISTRAL EMBEDDINGS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_embeddings():\n",
    "    \"\"\"Teste la gÃ©nÃ©ration d'embeddings\"\"\"\n",
    "    from langchain_mistralai import MistralAIEmbeddings\n",
    "    \n",
    "    embeddings = MistralAIEmbeddings(\n",
    "        model=\"mistral-embed\",\n",
    "        mistral_api_key=os.getenv(\"MISTRAL_API_KEY\")\n",
    "    )\n",
    "    \n",
    "    # Test sur une phrase simple\n",
    "    test_text = \"Apple annonce de nouveaux produits\"\n",
    "    embedding = embeddings.embed_query(test_text)\n",
    "    \n",
    "    print(f\"   Texte : '{test_text}'\")\n",
    "    print(f\"   Dimension : {len(embedding)}\")\n",
    "    print(f\"   Type : {type(embedding)}\")\n",
    "    print(f\"   Premiers 5 valeurs : {embedding[:5]}\")\n",
    "    \n",
    "    if len(embedding) != 1024:\n",
    "        raise ValueError(f\"Dimension incorrecte : {len(embedding)} (attendu : 1024)\")\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 4 : MISTRAL LLM\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_llm():\n",
    "    \"\"\"Teste le modÃ¨le LLM\"\"\"\n",
    "    from langchain_mistralai import ChatMistralAI\n",
    "    \n",
    "    llm = ChatMistralAI(\n",
    "        model=\"mistral-small\",\n",
    "        temperature=0,\n",
    "        mistral_api_key=os.getenv(\"MISTRAL_API_KEY\")\n",
    "    )\n",
    "    \n",
    "    # Test simple\n",
    "    response = llm.invoke(\"RÃ©ponds en un mot : quelle est la capitale de la France ?\")\n",
    "    \n",
    "    print(f\"   ModÃ¨le : mistral-medium\")\n",
    "    print(f\"   Question : Capitale de la France ?\")\n",
    "    print(f\"   RÃ©ponse : {response.content}\")\n",
    "    \n",
    "    if \"Paris\" not in response.content:\n",
    "        print(\"   âš ï¸  RÃ©ponse inattendue, mais API fonctionne\")\n",
    "    \n",
    "    return llm\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 5 : RETRIEVER\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_retriever():\n",
    "    \"\"\"Teste la recherche vectorielle\"\"\"\n",
    "    from langchain_pinecone import PineconeVectorStore\n",
    "    from langchain_mistralai import MistralAIEmbeddings\n",
    "    \n",
    "    embeddings = MistralAIEmbeddings(model=\"mistral-embed\")\n",
    "    \n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=\"kpmg-veille\",\n",
    "        embedding=embeddings,\n",
    "        namespace=\"news\"  # Utilise le namespace qui a des donnÃ©es\n",
    "    )\n",
    "    \n",
    "    # Test de recherche\n",
    "    query = \"Apple derniÃ¨res actualitÃ©s\"\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    \n",
    "    print(f\"   Query : '{query}'\")\n",
    "    print(f\"   Namespace : news\")\n",
    "    print(f\"   RÃ©sultats : {len(results)} documents\")\n",
    "    \n",
    "    if not results:\n",
    "        raise ValueError(\"Aucun rÃ©sultat trouvÃ© - vÃ©rifiez l'indexation\")\n",
    "    \n",
    "    print(f\"\\n   ðŸ“„ Premier rÃ©sultat :\")\n",
    "    print(f\"      Source : {results[0].metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"      Contenu : {results[0].page_content[:150]}...\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 6 : CHAÃŽNE RAG COMPLÃˆTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_rag_chain():\n",
    "    \"\"\"Teste la chaÃ®ne RAG complÃ¨te\"\"\"\n",
    "    from langchain_mistralai import ChatMistralAI, MistralAIEmbeddings\n",
    "    from langchain_pinecone import PineconeVectorStore\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    from langchain_core.runnables import RunnablePassthrough\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    \n",
    "    # Composants\n",
    "    embeddings = MistralAIEmbeddings(model=\"mistral-embed\")\n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=\"kpmg-veille\",\n",
    "        embedding=embeddings,\n",
    "        namespace=\"news\"\n",
    "    )\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "    llm = ChatMistralAI(model=\"mistral-medium\", temperature=0)\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Contexte : {context}\\n\\nQuestion : {question}\\n\\nRÃ©ponse courte :\"\n",
    "    )\n",
    "    \n",
    "    # ChaÃ®ne\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join([d.page_content[:200] for d in docs])\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    # Test\n",
    "    question = \"Quelles sont les derniÃ¨res actualitÃ©s ?\"\n",
    "    print(f\"   Question : '{question}'\")\n",
    "    print(f\"   Traitement...\")\n",
    "    \n",
    "    response = rag_chain.invoke(question)\n",
    "    \n",
    "    print(f\"\\n   âœ… RÃ©ponse gÃ©nÃ©rÃ©e ({len(response)} caractÃ¨res) :\")\n",
    "    print(f\"   {response[:300]}...\")\n",
    "    \n",
    "    return rag_chain\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 7 : GRADIO (OPTIONNEL)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_gradio():\n",
    "    \"\"\"VÃ©rifie que Gradio est installÃ©\"\"\"\n",
    "    import gradio as gr\n",
    "    \n",
    "    version = gr.__version__\n",
    "    print(f\"   Version : {version}\")\n",
    "    \n",
    "    if version < \"4.0.0\":\n",
    "        print(\"   âš ï¸  Version ancienne dÃ©tectÃ©e\")\n",
    "        print(\"   â†’ RecommandÃ© : pip install --upgrade gradio\")\n",
    "    \n",
    "    return gr\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXÃ‰CUTION DES TESTS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def main():\n",
    "    \"\"\"ExÃ©cute tous les tests dans l'ordre\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"ðŸŽ¯ \"*20)\n",
    "    print(\"   DIAGNOSTIC COMPLET DU SYSTÃˆME RAG KPMG\")\n",
    "    print(\"ðŸŽ¯ \"*20 + \"\\n\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Liste des tests Ã  exÃ©cuter\n",
    "    tests = [\n",
    "        (\"Variables d'environnement\", test_environment),\n",
    "        (\"Ã‰tat de Pinecone\", test_pinecone),\n",
    "        (\"Mistral Embeddings\", test_embeddings),\n",
    "        (\"Mistral LLM\", test_llm),\n",
    "        (\"Retriever\", test_retriever),\n",
    "        (\"ChaÃ®ne RAG complÃ¨te\", test_rag_chain),\n",
    "        (\"Gradio\", test_gradio)\n",
    "    ]\n",
    "    \n",
    "    # ExÃ©cution\n",
    "    for test_name, test_func in tests:\n",
    "        success, result = run_test(test_name, test_func)\n",
    "        results[test_name] = {\"success\": success, \"result\": result}\n",
    "    \n",
    "    # Rapport final\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“Š RAPPORT FINAL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    passed = sum(1 for r in results.values() if r[\"success\"])\n",
    "    total = len(results)\n",
    "    \n",
    "    print(f\"\\nTests rÃ©ussis : {passed}/{total}\")\n",
    "    \n",
    "    if passed == total:\n",
    "        print(\"\\nðŸŽ‰ TOUS LES TESTS SONT PASSÃ‰S !\")\n",
    "        print(\"âœ… Votre systÃ¨me est prÃªt pour Gradio\")\n",
    "        print(\"\\nðŸ’¡ Prochaine Ã©tape :\")\n",
    "        print(\"   ExÃ©cutez la cellule 'gradio_interface_fixed.py'\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  CERTAINS TESTS ONT Ã‰CHOUÃ‰\")\n",
    "        print(\"\\nðŸ“‹ Actions recommandÃ©es :\")\n",
    "        \n",
    "        for test_name, result in results.items():\n",
    "            if not result[\"success\"]:\n",
    "                print(f\"\\nâŒ {test_name} :\")\n",
    "                \n",
    "                if \"environnement\" in test_name.lower():\n",
    "                    print(\"   â†’ VÃ©rifiez votre fichier .env\")\n",
    "                    print(\"   â†’ load_dotenv() doit Ãªtre appelÃ©\")\n",
    "                \n",
    "                elif \"pinecone\" in test_name.lower():\n",
    "                    print(\"   â†’ ExÃ©cutez les Notebooks 2, 3, 4 pour indexer des donnÃ©es\")\n",
    "                    print(\"   â†’ VÃ©rifiez que l'index 'kpmg-veille' existe\")\n",
    "                \n",
    "                elif \"embeddings\" in test_name.lower():\n",
    "                    print(\"   â†’ VÃ©rifiez votre MISTRAL_API_KEY\")\n",
    "                    print(\"   â†’ Testez manuellement : https://console.mistral.ai/\")\n",
    "                \n",
    "                elif \"llm\" in test_name.lower():\n",
    "                    print(\"   â†’ VÃ©rifiez les crÃ©dits de votre compte Mistral\")\n",
    "                    print(\"   â†’ Essayez 'mistral-small' si 'medium' ne fonctionne pas\")\n",
    "                \n",
    "                elif \"retriever\" in test_name.lower():\n",
    "                    print(\"   â†’ L'index est vide ou le namespace 'news' n'existe pas\")\n",
    "                    print(\"   â†’ RÃ©exÃ©cutez le Notebook 4 (indexation)\")\n",
    "                \n",
    "                elif \"rag\" in test_name.lower():\n",
    "                    print(\"   â†’ Un composant prÃ©cÃ©dent a Ã©chouÃ©\")\n",
    "                    print(\"   â†’ Corrigez les erreurs ci-dessus d'abord\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… Diagnostic terminÃ©\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# LANCEMENT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kpmgvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
