{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    PIPELINE DE VEILLE KPMG                  â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                             â”‚\n",
    "â”‚  [Sources] â†’ [Loaders] â†’ [Chunking] â†’ [Embeddings]          â”‚\n",
    "â”‚                              â†“                              â”‚\n",
    "â”‚                     [Pinecone Namespaces]                   â”‚\n",
    "â”‚                              â†“                              â”‚\n",
    "â”‚              [Retriever] â†’ [LLM] â†’ [RÃ©ponse]                â”‚\n",
    "â”‚                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEF d'un namespace = un dossier dans une base\n",
    "\n",
    "index: veille-strategique\n",
    "\n",
    "â”œâ”€â”€ namespace: financial_reports\n",
    "â”‚   â”œâ”€â”€ vecteur_001 (10-K Apple)\n",
    "â”‚   â”œâ”€â”€ vecteur_002 (10-Q Microsoft)\n",
    "â”‚\n",
    "â”œâ”€â”€ namespace: news\n",
    "â”‚   â”œâ”€â”€ vecteur_101 (Google News - OpenAI)\n",
    "â”‚   â”œâ”€â”€ vecteur_102 (Reuters - Tesla)\n",
    "â”‚\n",
    "â”œâ”€â”€ namespace: startups\n",
    "â”‚   â”œâ”€â”€ vecteur_201 (Crunchbase - levÃ©e SÃ©rie A)\n",
    "â”‚\n",
    "â”œâ”€â”€ namespace: macro_data\n",
    "â”‚   â”œâ”€â”€ vecteur_301 (World Bank - inflation UE)\n",
    "â”‚\n",
    "â””â”€â”€ namespace: social_signals\n",
    "    â”œâ”€â”€ vecteur_401 (Reddit sentiment marchÃ©)\n",
    "\n",
    "BUT : Retrieval ciblÃ©, Ã‰viter le bruit, Prompting plus intelligent (Â« RÃ©ponds uniquement Ã  partir des donnÃ©es issues du namespace financial_reports et cite les sources Â»)Ã‡a rÃ©duit les hallucinations, ScalabilitÃ© propre :\n",
    "\n",
    "-Tu peux ajouter de nouvelles sources sans casser lâ€™existant\n",
    "\n",
    "-Tu peux purger un namespace sans toucher aux autres\n",
    "\n",
    "-Tu peux tester des sources expÃ©rimentales (social_signals) sans polluer le corpus principal\n",
    "\n",
    ",  \n",
    "\n",
    "1 index = 1 projet RAG\n",
    "N namespaces = N types de sources\n",
    "\n",
    "Je pourrais meme aller plus loin ; \n",
    "news/google\n",
    "news/press_release\n",
    "social/reddit\n",
    "social/twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom pinecone import Pinecone\\nimport os\\n\\npc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\\nINDEX_NAME = \"kpmg-veille\"\\n\\n# Supprimer TOUS les vecteurs de TOUS les namespaces\\nindex = pc.Index(INDEX_NAME)\\nstats = index.describe_index_stats()\\n\\nfor namespace in stats.namespaces.keys():\\n    print(f\"ðŸ—‘ï¸ Suppression du namespace \\'{namespace}\\'...\")\\n    index.delete(delete_all=True, namespace=namespace)\\n\\nprint(\"âœ… Index nettoyÃ©\")\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean l'index ( ATTENTION A NE PAS EXECUTER A CHAQUZ FOIS !!)\n",
    "\n",
    "'''\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "INDEX_NAME = \"kpmg-veille\"\n",
    "\n",
    "# Supprimer TOUS les vecteurs de TOUS les namespaces\n",
    "index = pc.Index(INDEX_NAME)\n",
    "stats = index.describe_index_stats()\n",
    "\n",
    "for namespace in stats.namespaces.keys():\n",
    "    print(f\"ðŸ—‘ï¸ Suppression du namespace '{namespace}'...\")\n",
    "    index.delete(delete_all=True, namespace=namespace)\n",
    "\n",
    "print(\"âœ… Index nettoyÃ©\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Variables d'environnement chargÃ©es\n",
      "Client Pinecone initialisÃ©\n",
      "ðŸ—‘ï¸  Index 'kpmg-veille' dÃ©tectÃ©. Suppression en cours...\n",
      "âœ… Index supprimÃ© avec succÃ¨s\n",
      "ðŸ”¨ CrÃ©ation de l'index 'kpmg-veille'...\n",
      "âœ… Index crÃ©Ã© et opÃ©rationnel\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š CONFIGURATION DE L'INDEX\n",
      "============================================================\n",
      "Nom : kpmg-veille\n",
      "Dimension : 1024 (Mistral-embed)\n",
      "MÃ©trique : cosine\n",
      "Vecteurs totaux : 0\n",
      "\n",
      "ðŸ“ Namespaces dÃ©finis :\n",
      "   - financial_reports\n",
      "   - news\n",
      "   - startups\n",
      "   - macro_data\n",
      "   - social_signals\n",
      "============================================================\n",
      "\n",
      "âœ… Index prÃªt pour l'ingestion de donnÃ©es\n",
      "\n",
      "âœ… CHECKLIST COMPLÃ‰TÃ‰E :\n",
      "   â˜‘ Index existant supprimÃ©\n",
      "   â˜‘ Nouvel index crÃ©Ã© avec dimension 1024\n",
      "   â˜‘ MÃ©trique cosine configurÃ©e\n",
      "   â˜‘ Serverless spec activÃ©\n",
      "   â˜‘ Namespaces documentÃ©s\n",
      "\n",
      "ðŸŽ¯ PrÃªt pour l'ingestion (Notebook 2)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK 1 : Configuration et Nettoyage Pinecone\n",
    "================================================\n",
    "\n",
    "OBJECTIF : RÃ©initialiser complÃ¨tement l'environnement vectoriel\n",
    "           et crÃ©er une architecture propre avec namespaces.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- Pinecone Docs : https://docs.pinecone.io/docs/python-client\n",
    "- LangChain Pinecone : https://python.langchain.com/docs/integrations/vectorstores/pinecone\n",
    "\n",
    "MÃ‰THODOLOGIE :\n",
    "1. Supprimer l'index existant (stratÃ©gie Option A validÃ©e)\n",
    "2. RecrÃ©er un index optimisÃ© pour Mistral embeddings (dimension 1024)\n",
    "3. Valider la structure des namespaces\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 1 : CHARGEMENT DES VARIABLES D'ENVIRONNEMENT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "    #PINECONE_ENVIRONMENT = os.getenv(\"PINECONE_ENVIRONMENT\", \"us-east-1\")\n",
    "\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"âŒ PINECONE_API_KEY manquante dans .env\")\n",
    "\n",
    "print(\" Variables d'environnement chargÃ©es\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 2 : INITIALISATION CLIENT PINECONE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "JUSTIFICATION : \n",
    "Pinecone v3+ utilise une nouvelle API avec ServerlessSpec.\n",
    "Cela permet une scalabilitÃ© automatique sans gÃ©rer de pods.\n",
    "\n",
    "RÃ©fÃ©rence : https://docs.pinecone.io/docs/new-api\n",
    "\"\"\"\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "print(\"Client Pinecone initialisÃ©\")\n",
    "    #print(f\" Client Pinecone initialisÃ© (Environnement : {PINECONE_ENVIRONMENT})\")\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 3 : SUPPRESSION DE L'INDEX EXISTANT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "STRATÃ‰GIE VALIDÃ‰E : Option A - Suppression totale\n",
    "\n",
    "POURQUOI ?\n",
    "- Garantit un environnement propre sans donnÃ©es parasites\n",
    "- Ã‰vite les conflits de dimension d'embeddings\n",
    "- Permet de repartir sur des mÃ©tadonnÃ©es structurÃ©es\n",
    "\n",
    "ALTERNATIVE NON RETENUE :\n",
    "Option B (namespaces sans suppression) aurait conservÃ© les donnÃ©es \n",
    "de test (Wikipedia, thermodynamique) qui pollueraient la veille.\n",
    "\"\"\"\n",
    "\n",
    "INDEX_NAME = \"kpmg-veille\"\n",
    "def clean_pinecone_index():\n",
    "    \"\"\"Supprime l'index existant s'il existe\"\"\"\n",
    "    try:\n",
    "        existing_indexes = [idx.name for idx in pc.list_indexes()]\n",
    "        \n",
    "        if INDEX_NAME in existing_indexes:\n",
    "            print(f\"ðŸ—‘ï¸  Index '{INDEX_NAME}' dÃ©tectÃ©. Suppression en cours...\")\n",
    "            pc.delete_index(INDEX_NAME)\n",
    "            \n",
    "            # Attendre la suppression complÃ¨te (bonnes pratiques Pinecone)\n",
    "            while INDEX_NAME in [idx.name for idx in pc.list_indexes()]:\n",
    "                print(\"   â³ Attente de la suppression...\")\n",
    "                time.sleep(2)\n",
    "            \n",
    "            print(\"âœ… Index supprimÃ© avec succÃ¨s\")\n",
    "        else:\n",
    "            print(f\"â„¹ï¸  Aucun index '{INDEX_NAME}' trouvÃ© (normal si 1Ã¨re exÃ©cution)\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Erreur lors du nettoyage : {e}\")\n",
    "        raise\n",
    "\n",
    "clean_pinecone_index()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 4 : CRÃ‰ATION DU NOUVEL INDEX\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "CONFIGURATION OPTIMALE POUR MISTRAL EMBEDDINGS\n",
    "\n",
    "1. DIMENSION : 1024\n",
    "   - Mistral-embed gÃ©nÃ¨re des vecteurs de 1024 dimensions\n",
    "   - RÃ©fÃ©rence : https://docs.mistral.ai/capabilities/embeddings/\n",
    "\n",
    "2. MÃ‰TRIQUE : cosine\n",
    "   - Standard pour la similaritÃ© sÃ©mantique\n",
    "   - RecommandÃ©e par LangChain pour les embeddings textuels\n",
    "   - RÃ©fÃ©rence : https://python.langchain.com/docs/modules/data_connection/vectorstores/\n",
    "\n",
    "3. SERVERLESS SPEC :\n",
    "   - Cloud 'aws', RÃ©gion 'us-east-1'\n",
    "   - ScalabilitÃ© automatique (critique pour la veille en production)\n",
    "   - Pas de gestion de pods\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_optimized_index():\n",
    "    \"\"\"CrÃ©e un index Pinecone optimisÃ© pour la veille stratÃ©gique\"\"\"\n",
    "    try:\n",
    "        print(f\"ðŸ”¨ CrÃ©ation de l'index '{INDEX_NAME}'...\")\n",
    "        \n",
    "        pc.create_index(\n",
    "            name=INDEX_NAME,\n",
    "            dimension=1024,  # Dimension Mistral-embed\n",
    "            metric=\"cosine\",  # SimilaritÃ© sÃ©mantique\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\"  # Utiliser votre rÃ©gion Pinecone\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Attendre que l'index soit prÃªt\n",
    "        while not pc.describe_index(INDEX_NAME).status['ready']:\n",
    "            print(\"   â³ Initialisation de l'index...\")\n",
    "            time.sleep(2)\n",
    "        \n",
    "        print(\"âœ… Index crÃ©Ã© et opÃ©rationnel\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur lors de la crÃ©ation : {e}\")\n",
    "        raise\n",
    "\n",
    "create_optimized_index()\n",
    "\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 5 : VALIDATION DE LA STRUCTURE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "ARCHITECTURE DES NAMESPACES\n",
    "\n",
    "Chaque namespace correspond Ã  un type de source de donnÃ©es :\n",
    "- financial_reports : SEC EDGAR, rapports annuels\n",
    "- news : NewsAPI, communiquÃ©s de presse\n",
    "- startups : Crunchbase (futur)\n",
    "- macro_data : yfinance, donnÃ©es Ã©conomiques\n",
    "- social_signals : Reddit, Twitter (futur)\n",
    "\n",
    "AVANTAGES :\n",
    "âœ“ Isolation des sources pour des requÃªtes ciblÃ©es\n",
    "âœ“ PossibilitÃ© de filtrer par namespace lors du retrieval\n",
    "âœ“ Gestion indÃ©pendante du cycle de vie des donnÃ©es\n",
    "âœ“ Facilite le debugging et les audits\n",
    "\"\"\"\n",
    "\n",
    "NAMESPACES = [\n",
    "    \"financial_reports\",\n",
    "    \"news\",\n",
    "    \"startups\",\n",
    "    \"macro_data\",\n",
    "    \"social_signals\"\n",
    "]\n",
    "\n",
    "def validate_index_structure():\n",
    "    \"\"\"Affiche la configuration de l'index\"\"\"\n",
    "    try:\n",
    "        index_stats = pc.Index(INDEX_NAME).describe_index_stats()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ðŸ“Š CONFIGURATION DE L'INDEX\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Nom : {INDEX_NAME}\")\n",
    "        print(f\"Dimension : 1024 (Mistral-embed)\")\n",
    "        print(f\"MÃ©trique : cosine\")\n",
    "        print(f\"Vecteurs totaux : {index_stats.get('total_vector_count', 0)}\")\n",
    "        print(f\"\\nðŸ“ Namespaces dÃ©finis :\")\n",
    "        for ns in NAMESPACES:\n",
    "            print(f\"   - {ns}\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        print(\"âœ… Index prÃªt pour l'ingestion de donnÃ©es\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur de validation : {e}\")\n",
    "        raise\n",
    "\n",
    "validate_index_structure()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 6 : CHECKLIST DE VALIDATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nâœ… CHECKLIST COMPLÃ‰TÃ‰E :\")\n",
    "print(\"   â˜‘ Index existant supprimÃ©\")\n",
    "print(\"   â˜‘ Nouvel index crÃ©Ã© avec dimension 1024\")\n",
    "print(\"   â˜‘ MÃ©trique cosine configurÃ©e\")\n",
    "print(\"   â˜‘ Serverless spec activÃ©\")\n",
    "print(\"   â˜‘ Namespaces documentÃ©s\")\n",
    "print(\"\\nðŸŽ¯ PrÃªt pour l'ingestion (Notebook 2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration des sources initialisÃ©e\n",
      "\n",
      "============================================================\n",
      "ðŸš€ DÃ‰MARRAGE DE L'INGESTION MULTI-SOURCES\n",
      "============================================================\n",
      "\n",
      "\n",
      "ðŸ“° Chargement NewsAPI...\n",
      "[2026-01-25T13:42:30.595879] NEWSAPI - INFO : Recherche : 'technology finance'\n",
      "[2026-01-25T13:42:31.218338] NEWSAPI - SUCCESS : 99 articles rÃ©cupÃ©rÃ©s\n",
      "\n",
      "ðŸ“¢ Chargement communiquÃ©s de presse...\n",
      "[2026-01-25T13:42:31.221999] PRESS_RELEASE - INFO : Scraping https://www.apple.com/newsroom/\n",
      "[2026-01-25T13:42:32.910304] PRESS_RELEASE - SUCCESS : Document chargÃ© depuis https://www.apple.com/newsroom/\n",
      "\n",
      "ðŸ’¹ Chargement donnÃ©es financiÃ¨res...\n",
      "[2026-01-25T13:42:32.916086] YFINANCE - INFO : RÃ©cupÃ©ration donnÃ©es pour AAPL\n",
      "[2026-01-25T13:42:33.664428] YFINANCE - SUCCESS : DonnÃ©es rÃ©cupÃ©rÃ©es pour AAPL\n",
      "[2026-01-25T13:42:39.669644] YFINANCE - INFO : RÃ©cupÃ©ration donnÃ©es pour MSFT\n",
      "[2026-01-25T13:42:40.012119] YFINANCE - SUCCESS : DonnÃ©es rÃ©cupÃ©rÃ©es pour MSFT\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š RÃ‰SUMÃ‰ DE L'INGESTION\n",
      "============================================================\n",
      "   financial_reports: 0 documents\n",
      "   news: 100 documents\n",
      "   macro_data: 2 documents\n",
      "============================================================\n",
      "\n",
      "âœ… Documents sauvegardÃ©s dans 'ingested_documents.json'\n",
      "ðŸŽ¯ PrÃªt pour le chunking et les embeddings (Notebook 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK 2 : Ingestion Multi-Sources\n",
    "====================================\n",
    "\n",
    "OBJECTIF : CrÃ©er un pipeline robuste d'ingestion de donnÃ©es\n",
    "           depuis SEC EDGAR, NewsAPI, communiquÃ©s de presse et yfinance.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- LangChain Document Loaders : https://python.langchain.com/docs/modules/data_connection/document_loaders/\n",
    "- SEC EDGAR : https://www.sec.gov/edgar/sec-api-documentation\n",
    "- NewsAPI : https://newsapi.org/docs\n",
    "- yfinance : https://pypi.org/project/yfinance/\n",
    "\n",
    "ARCHITECTURE :\n",
    "1. Loaders modulaires par source\n",
    "2. MÃ©tadonnÃ©es riches (source, date, type)\n",
    "3. Gestion d'erreurs et retry\n",
    "4. Logging pour traÃ§abilitÃ©\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# APIs externes\n",
    "import yfinance as yf\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 1 : CONFIGURATION DES SOURCES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "BONNES PRATIQUES :\n",
    "- Centraliser les configurations\n",
    "- Utiliser des variables d'environnement pour les clÃ©s API\n",
    "- Documenter les limites de chaque source\n",
    "\"\"\"\n",
    "\n",
    "# NewsAPI (100 requÃªtes/jour gratuit)\n",
    "NEWSAPI_KEY = os.getenv(\"NEWSAPI_KEY\")\n",
    "NEWSAPI_ENDPOINT = \"https://newsapi.org/v2/everything\"\n",
    "\n",
    "# SEC EDGAR (gratuit, nÃ©cessite User-Agent)\n",
    "    #SEC_USER_AGENT = os.getenv(\"SEC_USER_AGENT\", \"VotreNom votre.email@example.com\")\n",
    "    #SEC_BASE_URL = \"https://data.sec.gov/submissions/\"\n",
    "\n",
    "# Configuration logging\n",
    "LOGS_DIR = \"ingestion_logs\"\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "\n",
    "def log_ingestion(source: str, status: str, details: str):\n",
    "    \"\"\"Log les opÃ©rations d'ingestion pour audit\"\"\"\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    log_entry = f\"[{timestamp}] {source} - {status} : {details}\\n\"\n",
    "    \n",
    "    with open(f\"{LOGS_DIR}/ingestion.log\", \"a\") as f:\n",
    "        f.write(log_entry)\n",
    "    \n",
    "    print(log_entry.strip())\n",
    "\n",
    "print(\"âœ… Configuration des sources initialisÃ©e\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 2 : SOURCE 1 - SEC EDGAR\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "SEC EDGAR : Base de donnÃ©es rÃ©glementaire de la SEC (US)\n",
    "\n",
    "JUSTIFICATION DU CHOIX :\n",
    "âœ“ DonnÃ©es structurÃ©es et fiables\n",
    "âœ“ Gratuit avec rate limiting raisonnable (10 req/sec)\n",
    "âœ“ Essentiel pour l'analyse d'entreprises US (contexte KPMG)\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://www.sec.gov/edgar/sec-api-documentation\n",
    "\n",
    "EXIGENCE CRITIQUE :\n",
    "La SEC bloque les requÃªtes sans User-Agent. \n",
    "Format requis : \"Nom email@example.com\"\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "def load_sec_edgar_filing(cik: str, filing_type: str = \"10-K\") -> List[Document]:\n",
    "    \"\"\"\n",
    "    Charge un dÃ©pÃ´t SEC pour une entreprise donnÃ©e\n",
    "    \n",
    "    Args:\n",
    "        cik: Central Index Key de l'entreprise (ex: \"0000320193\" pour Apple)\n",
    "        filing_type: Type de dÃ©pÃ´t (10-K, 10-Q, 8-K, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Liste de Documents LangChain avec mÃ©tadonnÃ©es\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\"User-Agent\": SEC_USER_AGENT}\n",
    "        url = f\"{SEC_BASE_URL}CIK{cik.zfill(10)}.json\"\n",
    "        \n",
    "        log_ingestion(\"SEC_EDGAR\", \"INFO\", f\"RequÃªte pour CIK {cik}\")\n",
    "        \n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        company_name = data.get(\"name\", \"Unknown\")\n",
    "        \n",
    "        # Filtrer les dÃ©pÃ´ts par type\n",
    "        filings = data.get(\"filings\", {}).get(\"recent\", {})\n",
    "        \n",
    "        documents = []\n",
    "        for i, form in enumerate(filings.get(\"form\", [])):\n",
    "            if form == filing_type:\n",
    "                filing_date = filings[\"filingDate\"][i]\n",
    "                accession = filings[\"accessionNumber\"][i]\n",
    "                primary_doc = filings[\"primaryDocument\"][i]\n",
    "                \n",
    "                # URL du document\n",
    "                acc_no_formatted = accession.replace(\"-\", \"\")\n",
    "                doc_url = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{acc_no_formatted}/{primary_doc}\"\n",
    "                \n",
    "                # CrÃ©ation du Document LangChain\n",
    "                doc = Document(\n",
    "                    page_content=f\"SEC Filing {filing_type} for {company_name} on {filing_date}\",\n",
    "                    metadata={\n",
    "                        \"source\": \"sec_edgar\",\n",
    "                        \"company\": company_name,\n",
    "                        \"cik\": cik,\n",
    "                        \"filing_type\": filing_type,\n",
    "                        \"filing_date\": filing_date,\n",
    "                        \"accession_number\": accession,\n",
    "                        \"url\": doc_url,\n",
    "                        \"namespace\": \"financial_reports\"\n",
    "                    }\n",
    "                )\n",
    "                documents.append(doc)\n",
    "        \n",
    "        log_ingestion(\"SEC_EDGAR\", \"SUCCESS\", f\"{len(documents)} documents trouvÃ©s pour {company_name}\")\n",
    "        return documents\n",
    "    \n",
    "    except Exception as e:\n",
    "        log_ingestion(\"SEC_EDGAR\", \"ERROR\", str(e))\n",
    "        return []\n",
    "'''\n",
    "\n",
    "# Exemple d'utilisation (commentÃ© pour Ã©viter rate limiting)\n",
    "# apple_docs = load_sec_edgar_filing(\"0000320193\", \"10-K\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 3 : SOURCE 2 - NEWSAPI\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "NEWSAPI : AgrÃ©gateur d'actualitÃ©s mondiales\n",
    "\n",
    "JUSTIFICATION :\n",
    "âœ“ Alternative gratuite Ã  Google News API (100 req/jour)\n",
    "âœ“ Couvre 150 000+ sources\n",
    "âœ“ Filtrage par mots-clÃ©s, langue, date\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://newsapi.org/docs/endpoints/everything\n",
    "\n",
    "LIMITE PLAN GRATUIT :\n",
    "- Articles limitÃ©s aux 30 derniers jours\n",
    "- Pas d'accÃ¨s aux articles complets (seulement titre + description)\n",
    "\"\"\"\n",
    "\n",
    "def load_newsapi_articles(query: str, language: str = \"en\", days_back: int = 7) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Charge des articles depuis NewsAPI\n",
    "    \n",
    "    Args:\n",
    "        query: Mot-clÃ© de recherche (ex: \"artificial intelligence finance\")\n",
    "        language: Code langue (en, fr, de, etc.)\n",
    "        days_back: Nombre de jours en arriÃ¨re (max 30 pour plan gratuit)\n",
    "    \n",
    "    Returns:\n",
    "        Liste de Documents avec mÃ©tadonnÃ©es structurÃ©es\n",
    "    \"\"\"\n",
    "    if not NEWSAPI_KEY:\n",
    "        log_ingestion(\"NEWSAPI\", \"ERROR\", \"ClÃ© API manquante\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        from_date = (datetime.now() - timedelta(days=days_back)).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"from\": from_date,\n",
    "            \"language\": language,\n",
    "            \"sortBy\": \"relevancy\",\n",
    "            \"apiKey\": NEWSAPI_KEY\n",
    "        }\n",
    "        \n",
    "        log_ingestion(\"NEWSAPI\", \"INFO\", f\"Recherche : '{query}'\")\n",
    "        \n",
    "        response = requests.get(NEWSAPI_ENDPOINT, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        articles = data.get(\"articles\", [])\n",
    "        \n",
    "        documents = []\n",
    "        for article in articles:\n",
    "            content = f\"{article.get('title', '')}. {article.get('description', '')}\"\n",
    "            \n",
    "            doc = Document(\n",
    "                page_content=content,\n",
    "                metadata={\n",
    "                    \"source\": \"newsapi\",\n",
    "                    \"title\": article.get(\"title\"),\n",
    "                    \"author\": article.get(\"author\"),\n",
    "                    \"published_at\": article.get(\"publishedAt\"),\n",
    "                    \"url\": article.get(\"url\"),\n",
    "                    \"source_name\": article.get(\"source\", {}).get(\"name\"),\n",
    "                    \"namespace\": \"news\"\n",
    "                }\n",
    "            )\n",
    "            documents.append(doc)\n",
    "        \n",
    "        log_ingestion(\"NEWSAPI\", \"SUCCESS\", f\"{len(documents)} articles rÃ©cupÃ©rÃ©s\")\n",
    "        return documents\n",
    "    \n",
    "    except Exception as e:\n",
    "        log_ingestion(\"NEWSAPI\", \"ERROR\", str(e))\n",
    "        return []\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# news_docs = load_newsapi_articles(\"fintech investment\", language=\"en\", days_back=7)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 4 : SOURCE 3 - COMMUNIQUÃ‰S DE PRESSE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "WEB SCRAPING : CommuniquÃ©s de presse d'entreprises\n",
    "\n",
    "JUSTIFICATION :\n",
    "âœ“ Source primaire (directement depuis les entreprises)\n",
    "âœ“ DonnÃ©es structurÃ©es et fiables\n",
    "âœ“ Gratuit (scraping Ã©thique avec respect du robots.txt)\n",
    "\n",
    "LOADER CHOISI : WebBaseLoader\n",
    "RÃ©fÃ©rence : https://python.langchain.com/docs/integrations/document_loaders/web_base\n",
    "\n",
    "BONNES PRATIQUES :\n",
    "- VÃ©rifier robots.txt avant de scraper\n",
    "- ImplÃ©menter des dÃ©lais entre requÃªtes (rate limiting)\n",
    "- GÃ©rer les erreurs (timeouts, 404, etc.)\n",
    "\"\"\"\n",
    "\n",
    "def load_press_releases(urls: List[str]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Charge des communiquÃ©s de presse depuis des URLs\n",
    "    \n",
    "    Args:\n",
    "        urls: Liste d'URLs de communiquÃ©s\n",
    "    \n",
    "    Returns:\n",
    "        Documents avec mÃ©tadonnÃ©es enrichies\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for url in urls:\n",
    "        try:\n",
    "            log_ingestion(\"PRESS_RELEASE\", \"INFO\", f\"Scraping {url}\")\n",
    "            \n",
    "            loader = WebBaseLoader(url)\n",
    "            docs = loader.load()\n",
    "            \n",
    "            # Enrichir les mÃ©tadonnÃ©es\n",
    "            for doc in docs:\n",
    "                doc.metadata.update({\n",
    "                    \"source\": \"press_release\",\n",
    "                    \"scrape_date\": datetime.now().isoformat(),\n",
    "                    \"namespace\": \"news\"\n",
    "                })\n",
    "                documents.append(doc)\n",
    "            \n",
    "            # Rate limiting Ã©thique\n",
    "            time.sleep(1)\n",
    "            \n",
    "            log_ingestion(\"PRESS_RELEASE\", \"SUCCESS\", f\"Document chargÃ© depuis {url}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            log_ingestion(\"PRESS_RELEASE\", \"ERROR\", f\"{url} - {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Exemple d'URLs (Ã  adapter selon vos besoins)\n",
    "# press_urls = [\n",
    "#     \"https://www.apple.com/newsroom/2024/01/apple-reports-first-quarter-results/\",\n",
    "#     \"https://investor.fb.com/investor-news/default.aspx\"\n",
    "# ]\n",
    "# press_docs = load_press_releases(press_urls)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 5 : SOURCE 4 - YFINANCE (DONNÃ‰ES FINANCIÃˆRES)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "YFINANCE : DonnÃ©es financiÃ¨res en temps rÃ©el\n",
    "\n",
    "JUSTIFICATION :\n",
    "âœ“ Gratuit et sans clÃ© API\n",
    "âœ“ DonnÃ©es Yahoo Finance (fiables)\n",
    "âœ“ IdÃ©al pour les KPIs financiers (prix, revenus, ratios)\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://pypi.org/project/yfinance/\n",
    "\n",
    "MÃ‰THODOLOGIE :\n",
    "On transforme les donnÃ©es structurÃ©es (JSON) en documents textuels\n",
    "pour les rendre compatibles avec le RAG.\n",
    "\"\"\"\n",
    "\n",
    "def load_yfinance_data(ticker: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Charge les donnÃ©es financiÃ¨res d'une entreprise via yfinance\n",
    "    \n",
    "    Args:\n",
    "        ticker: Symbole boursier (ex: \"AAPL\", \"MSFT\")\n",
    "    \n",
    "    Returns:\n",
    "        Documents avec mÃ©triques financiÃ¨res clÃ©s\n",
    "    \"\"\"\n",
    "    try:\n",
    "        log_ingestion(\"YFINANCE\", \"INFO\", f\"RÃ©cupÃ©ration donnÃ©es pour {ticker}\")\n",
    "        \n",
    "        stock = yf.Ticker(ticker)\n",
    "        info = stock.info\n",
    "        \n",
    "        # Extraire les mÃ©triques clÃ©s\n",
    "        metrics = {\n",
    "            \"market_cap\": info.get(\"marketCap\"),\n",
    "            \"revenue\": info.get(\"totalRevenue\"),\n",
    "            \"profit_margin\": info.get(\"profitMargins\"),\n",
    "            \"pe_ratio\": info.get(\"trailingPE\"),\n",
    "            \"current_price\": info.get(\"currentPrice\"),\n",
    "            \"52week_high\": info.get(\"fiftyTwoWeekHigh\"),\n",
    "            \"52week_low\": info.get(\"fiftyTwoWeekLow\")\n",
    "        }\n",
    "        \n",
    "        # CrÃ©er un texte descriptif\n",
    "        content = f\"\"\"\n",
    "        Financial Overview for {ticker}:\n",
    "        - Market Cap: ${metrics['market_cap']:,} (if available)\n",
    "        - Revenue: ${metrics['revenue']:,}\n",
    "        - Profit Margin: {metrics['profit_margin']:.2%}\n",
    "        - P/E Ratio: {metrics['pe_ratio']}\n",
    "        - Current Price: ${metrics['current_price']}\n",
    "        - 52-Week Range: ${metrics['52week_low']} - ${metrics['52week_high']}\n",
    "        \"\"\"\n",
    "        \n",
    "        doc = Document(\n",
    "            page_content=content,\n",
    "            metadata={\n",
    "                \"source\": \"yfinance\",\n",
    "                \"ticker\": ticker,\n",
    "                \"company_name\": info.get(\"longName\", ticker),\n",
    "                \"sector\": info.get(\"sector\"),\n",
    "                \"industry\": info.get(\"industry\"),\n",
    "                \"retrieval_date\": datetime.now().isoformat(),\n",
    "                \"namespace\": \"macro_data\",\n",
    "                **metrics  # Ajouter toutes les mÃ©triques aux mÃ©tadonnÃ©es\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        log_ingestion(\"YFINANCE\", \"SUCCESS\", f\"DonnÃ©es rÃ©cupÃ©rÃ©es pour {ticker}\")\n",
    "        return [doc]\n",
    "    \n",
    "    except Exception as e:\n",
    "        log_ingestion(\"YFINANCE\", \"ERROR\", f\"{ticker} - {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# apple_finance = load_yfinance_data(\"AAPL\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 6 : PIPELINE D'INGESTION UNIFIÃ‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "FONCTION MAÃŽTRE : Orchestration de toutes les sources\n",
    "\n",
    "Cette fonction permet de lancer l'ingestion de toutes les sources\n",
    "en une seule commande. Elle gÃ¨re les erreurs et retourne un rÃ©sumÃ©.\n",
    "\"\"\"\n",
    "\n",
    "def ingest_all_sources() -> Dict[str, List[Document]]:\n",
    "    \"\"\"\n",
    "    Lance l'ingestion de toutes les sources configurÃ©es\n",
    "    \n",
    "    Returns:\n",
    "        Dictionnaire {namespace: [documents]}\n",
    "    \"\"\"\n",
    "    all_documents = {\n",
    "        \"financial_reports\": [],\n",
    "        \"news\": [],\n",
    "        \"macro_data\": []\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸš€ DÃ‰MARRAGE DE L'INGESTION MULTI-SOURCES\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Source 1 : SEC EDGAR (exemple : Apple)\n",
    "    '''\n",
    "    print(\"ðŸ“Š Chargement SEC EDGAR...\")\n",
    "    sec_docs = load_sec_edgar_filing(\"0000320193\", \"10-K\")\n",
    "    all_documents[\"financial_reports\"].extend(sec_docs)\n",
    "    '''\n",
    "\n",
    "    # Source 2 : NewsAPI (si clÃ© disponible)\n",
    "    if NEWSAPI_KEY:\n",
    "        print(\"\\nðŸ“° Chargement NewsAPI...\")\n",
    "        news_docs = load_newsapi_articles(\"technology finance\", days_back=7)\n",
    "        all_documents[\"news\"].extend(news_docs)\n",
    "    \n",
    "    # Source 3 : CommuniquÃ©s de presse (exemple)\n",
    "    print(\"\\nðŸ“¢ Chargement communiquÃ©s de presse...\")\n",
    "    press_urls = [\n",
    "        \"https://www.apple.com/newsroom/\"\n",
    "    ]\n",
    "    press_docs = load_press_releases(press_urls)\n",
    "    all_documents[\"news\"].extend(press_docs)\n",
    "    \n",
    "    # Source 4 : yfinance (exemple : Apple, Microsoft)\n",
    "    print(\"\\nðŸ’¹ Chargement donnÃ©es financiÃ¨res...\")\n",
    "    for ticker in [\"AAPL\", \"MSFT\"]:\n",
    "        finance_docs = load_yfinance_data(ticker)\n",
    "        all_documents[\"macro_data\"].extend(finance_docs)\n",
    "        time.sleep(6)  # Attendre 6 secondes entre chaque ticker\n",
    "\n",
    "    ''' \n",
    "    âœ… Solution long terme : Mettre en cache les donnÃ©es yfinance dans un fichier JSON.\n",
    "    '''\n",
    "    \n",
    "    # RÃ©sumÃ©\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“Š RÃ‰SUMÃ‰ DE L'INGESTION\")\n",
    "    print(\"=\"*60)\n",
    "    for namespace, docs in all_documents.items():\n",
    "        print(f\"   {namespace}: {len(docs)} documents\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    return all_documents\n",
    "\n",
    "# ExÃ©cution du pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    documents_by_namespace = ingest_all_sources()\n",
    "    \n",
    "    # Sauvegarder les documents pour le Notebook 3\n",
    "    with open(\"ingested_documents.json\", \"w\") as f:\n",
    "        # Conversion en format sÃ©rialisable\n",
    "        serializable = {}\n",
    "        for ns, docs in documents_by_namespace.items():\n",
    "            serializable[ns] = [\n",
    "                {\n",
    "                    \"page_content\": doc.page_content,\n",
    "                    \"metadata\": doc.metadata\n",
    "                }\n",
    "                for doc in docs\n",
    "            ]\n",
    "        json.dump(serializable, f, indent=2)\n",
    "    \n",
    "    print(\"âœ… Documents sauvegardÃ©s dans 'ingested_documents.json'\")\n",
    "    print(\"ðŸŽ¯ PrÃªt pour le chunking et les embeddings (Notebook 3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chunker adaptatif initialisÃ©\n",
      "âœ… 102 documents chargÃ©s\n",
      "\n",
      "============================================================\n",
      "ðŸ”ª PHASE DE CHUNKING ADAPTATIF\n",
      "============================================================\n",
      "\n",
      "ðŸ”ª Chunking pour namespace 'news'...\n",
      "   âœ… 100 docs â†’ 109 chunks\n",
      "\n",
      "ðŸ”ª Chunking pour namespace 'macro_data'...\n",
      "   âœ… 2 docs â†’ 2 chunks\n",
      "\n",
      "ðŸ“Š RÃ©sumÃ© du chunking :\n",
      "   news: 109 chunks\n",
      "   macro_data: 2 chunks\n",
      "\n",
      "âœ… ModÃ¨le Mistral-embed initialisÃ©\n",
      "\n",
      "âœ… Ã‰tape 1 : Chunking terminÃ©\n",
      "\n",
      "============================================================\n",
      "ðŸ§® Ã‰TAPE 2 : GÃ‰NÃ‰RATION DES EMBEDDINGS\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Traitement namespace 'news'...\n",
      "\n",
      "ðŸ§® GÃ©nÃ©ration de 109 embeddings...\n",
      "   âœ… Batch 1/3 traitÃ©\n",
      "   âœ… Batch 2/3 traitÃ©\n",
      "   âœ… Batch 3/3 traitÃ©\n",
      "\n",
      "ðŸ“ Traitement namespace 'macro_data'...\n",
      "\n",
      "ðŸ§® GÃ©nÃ©ration de 2 embeddings...\n",
      "   âœ… Batch 1/1 traitÃ©\n",
      "\n",
      "============================================================\n",
      "âœ… VALIDATION DE LA QUALITÃ‰\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Namespace: news\n",
      "   âœ… 109 chunks validÃ©s\n",
      "\n",
      "ðŸ“ Namespace: macro_data\n",
      "   âœ… 2 chunks validÃ©s\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š Chunks avec embeddings : 111/111\n",
      "âœ… Toutes les dimensions sont correctes (1024)\n",
      "============================================================\n",
      "\n",
      "ðŸ’¾ Sauvegarde des documents pour indexation...\n",
      "âœ… Documents sauvegardÃ©s dans 'embedded_documents.json'\n",
      "\n",
      "ðŸŽ¯ PrÃªt pour l'indexation Pinecone (Notebook 4)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK 3 : Chunking Adaptatif & Embeddings Mistral\n",
    "====================================================\n",
    "\n",
    "OBJECTIF : DÃ©couper les documents de maniÃ¨re intelligente\n",
    "           et gÃ©nÃ©rer des embeddings optimisÃ©s pour Pinecone.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- LangChain Text Splitters : https://python.langchain.com/docs/modules/data_connection/document_transformers/\n",
    "- Mistral Embeddings : https://docs.mistral.ai/capabilities/embeddings/\n",
    "- Chunking Best Practices : https://www.pinecone.io/learn/chunking-strategies/\n",
    "\n",
    "MÃ‰THODOLOGIE :\n",
    "1. Chunking adaptatif selon le type de document\n",
    "2. Enrichissement des mÃ©tadonnÃ©es\n",
    "3. GÃ©nÃ©ration d'embeddings par batch (optimisation)\n",
    "4. Validation de la qualitÃ©\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    HTMLHeaderTextSplitter\n",
    ")\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 1 : STRATÃ‰GIES DE CHUNKING PAR TYPE DE DOCUMENT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "JUSTIFICATION DES CHOIX DE CHUNKING\n",
    "\n",
    "D'aprÃ¨s vos notes (KPMG v2.pdf), le chunking est l'Ã©tape la plus sous-estimÃ©e\n",
    "mais dÃ©terminante pour la qualitÃ© du RAG.\n",
    "\n",
    "PRINCIPES :\n",
    "1. GranularitÃ© adaptÃ©e au contenu\n",
    "   - Petits chunks (500 chars) : KPIs, chiffres prÃ©cis\n",
    "   - Gros chunks (1000+ chars) : analyses, raisonnements\n",
    "\n",
    "2. Overlap significatif (15-20%)\n",
    "   - Ã‰vite de couper les informations critiques\n",
    "   - Maintient la cohÃ©rence contextuelle\n",
    "\n",
    "3. SÃ©parateurs intelligents\n",
    "   - Paragraphes > Phrases > Mots\n",
    "   - PrÃ©serve la structure sÃ©mantique\n",
    "\"\"\"\n",
    "\n",
    "class AdaptiveChunker:\n",
    "    \"\"\"DÃ©coupe intelligente selon le type de document\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Splitter pour rapports financiers (SEC, yfinance)\n",
    "        self.financial_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=800,      # Balance entre dÃ©tail et contexte\n",
    "            chunk_overlap=150,   # ~19% overlap\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "            add_start_index=True  # TraÃ§abilitÃ© dans le document source\n",
    "        )\n",
    "        \n",
    "        # Splitter pour actualitÃ©s (courtes, denses)\n",
    "        self.news_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,      # Articles courts\n",
    "            chunk_overlap=100,   # 20% overlap\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "            add_start_index=True\n",
    "        )\n",
    "        \n",
    "        # Splitter HTML (communiquÃ©s de presse structurÃ©s)\n",
    "        self.html_splitter = HTMLHeaderTextSplitter(\n",
    "            headers_to_split_on=[\n",
    "                (\"h1\", \"Header 1\"),\n",
    "                (\"h2\", \"Header 2\"),\n",
    "                (\"h3\", \"Header 3\"),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def chunk_documents(self, documents: List[Document], namespace: str) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Applique la stratÃ©gie de chunking appropriÃ©e\n",
    "        \n",
    "        Args:\n",
    "            documents: Documents Ã  dÃ©couper\n",
    "            namespace: Type de document (dÃ©termine la stratÃ©gie)\n",
    "        \n",
    "        Returns:\n",
    "            Documents dÃ©coupÃ©s avec mÃ©tadonnÃ©es enrichies\n",
    "        \"\"\"\n",
    "        print(f\"\\nðŸ”ª Chunking pour namespace '{namespace}'...\")\n",
    "        \n",
    "        # SÃ©lection du splitter\n",
    "        if namespace == \"financial_reports\":\n",
    "            splitter = self.financial_splitter\n",
    "        elif namespace == \"news\":\n",
    "            splitter = self.news_splitter\n",
    "        elif namespace == \"macro_data\":\n",
    "            splitter = self.financial_splitter\n",
    "        else:\n",
    "            splitter = self.news_splitter  # DÃ©faut\n",
    "        \n",
    "        # DÃ©coupage\n",
    "        chunked_docs = []\n",
    "        for doc in documents:\n",
    "            chunks = splitter.split_documents([doc])\n",
    "            \n",
    "            # Enrichir chaque chunk avec info de position\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                chunk.metadata.update({\n",
    "                    \"chunk_index\": i,\n",
    "                    \"total_chunks\": len(chunks),\n",
    "                    \"chunking_strategy\": splitter.__class__.__name__\n",
    "                })\n",
    "                chunked_docs.append(chunk)\n",
    "        \n",
    "        print(f\"   âœ… {len(documents)} docs â†’ {len(chunked_docs)} chunks\")\n",
    "        return chunked_docs\n",
    "\n",
    "chunker = AdaptiveChunker()\n",
    "print(\"âœ… Chunker adaptatif initialisÃ©\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 2 : CHARGEMENT DES DOCUMENTS INGÃ‰RÃ‰S\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "RÃ©cupÃ©ration des documents depuis le Notebook 2\n",
    "\"\"\"\n",
    "\n",
    "def load_ingested_documents() -> Dict[str, List[Document]]:\n",
    "    \"\"\"Charge les documents depuis le fichier JSON\"\"\"\n",
    "    try:\n",
    "        with open(\"ingested_documents.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Reconversion en objets Document\n",
    "        documents_by_ns = {}\n",
    "        for namespace, docs_data in data.items():\n",
    "            documents_by_ns[namespace] = [\n",
    "                Document(\n",
    "                    page_content=d[\"page_content\"],\n",
    "                    metadata=d[\"metadata\"]\n",
    "                )\n",
    "                for d in docs_data\n",
    "            ]\n",
    "        \n",
    "        print(f\"âœ… {sum(len(docs) for docs in documents_by_ns.values())} documents chargÃ©s\")\n",
    "        return documents_by_ns\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Fichier 'ingested_documents.json' introuvable.\")\n",
    "        print(\"   ExÃ©cutez d'abord le Notebook 2 (ingestion)\")\n",
    "        return {}\n",
    "\n",
    "docs_by_namespace = load_ingested_documents()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 3 : APPLICATION DU CHUNKING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "Application du chunking adaptatif sur tous les namespaces\n",
    "\"\"\"\n",
    "\n",
    "chunked_by_namespace = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ”ª PHASE DE CHUNKING ADAPTATIF\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for namespace, documents in docs_by_namespace.items():\n",
    "    if documents:\n",
    "        chunked_docs = chunker.chunk_documents(documents, namespace)\n",
    "        chunked_by_namespace[namespace] = chunked_docs\n",
    "\n",
    "print(\"\\nðŸ“Š RÃ©sumÃ© du chunking :\")\n",
    "for ns, chunks in chunked_by_namespace.items():\n",
    "    print(f\"   {ns}: {len(chunks)} chunks\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 4 : GÃ‰NÃ‰RATION DES EMBEDDINGS MISTRAL\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "CONFIGURATION MISTRAL EMBEDDINGS\n",
    "\n",
    "ModÃ¨le : mistral-embed\n",
    "Dimension : 1024\n",
    "CoÃ»t : Gratuit avec limits (voir plan Mistral)\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://docs.mistral.ai/capabilities/embeddings/\n",
    "\n",
    "OPTIMISATION :\n",
    "- Traitement par batch pour limiter les appels API\n",
    "- Cache local des embeddings (Ã©vite recalcul)\n",
    "- Gestion des erreurs et retry\n",
    "\"\"\"\n",
    "\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "if not MISTRAL_API_KEY:\n",
    "    raise ValueError(\"âŒ MISTRAL_API_KEY manquante dans .env\")\n",
    "\n",
    "embeddings_model = MistralAIEmbeddings(\n",
    "    model=\"mistral-embed\",\n",
    "    mistral_api_key=MISTRAL_API_KEY\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… ModÃ¨le Mistral-embed initialisÃ©\")\n",
    "\n",
    "def generate_embeddings_batch(documents: List[Document], batch_size: int = 50) -> List[Document]:\n",
    "    \"\"\"\n",
    "    GÃ©nÃ¨re les embeddings par batch pour optimiser les appels API\n",
    "    \n",
    "    Args:\n",
    "        documents: Documents Ã  embedder\n",
    "        batch_size: Nombre de documents par batch\n",
    "    \n",
    "    Returns:\n",
    "        Documents avec embeddings dans les mÃ©tadonnÃ©es\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ§® GÃ©nÃ©ration de {len(documents)} embeddings...\")\n",
    "    \n",
    "    total_batches = (len(documents) + batch_size - 1) // batch_size\n",
    "    \n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        batch = documents[i:i+batch_size]\n",
    "        batch_num = i // batch_size + 1\n",
    "        \n",
    "        try:\n",
    "            # Extraire les textes\n",
    "            texts = [doc.page_content for doc in batch]\n",
    "            \n",
    "            # GÃ©nÃ©rer les embeddings\n",
    "            embeddings = embeddings_model.embed_documents(texts)\n",
    "            \n",
    "            # Ajouter les embeddings aux mÃ©tadonnÃ©es\n",
    "            for doc, embedding in zip(batch, embeddings):\n",
    "                doc.metadata[\"embedding\"] = embedding\n",
    "            \n",
    "            print(f\"   âœ… Batch {batch_num}/{total_batches} traitÃ©\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Erreur batch {batch_num}: {e}\")\n",
    "            # Continuer avec les autres batches\n",
    "            continue\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 5 : VALIDATION DE LA QUALITÃ‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "MÃ‰TRIQUES DE QUALITÃ‰\n",
    "\n",
    "Avant d'envoyer vers Pinecone, on valide :\n",
    "1. Tous les chunks ont des embeddings\n",
    "2. Les dimensions sont correctes (1024)\n",
    "3. Les mÃ©tadonnÃ©es sont complÃ¨tes\n",
    "\"\"\"\n",
    "\n",
    "def validate_chunked_documents(docs_by_ns: Dict[str, List[Document]]) -> bool:\n",
    "    \"\"\"Valide la qualitÃ© des documents chunkÃ©s et embeddÃ©s\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… VALIDATION DE LA QUALITÃ‰\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    total_chunks = sum(len(docs) for docs in docs_by_ns.values())\n",
    "    chunks_with_embeddings = 0\n",
    "    invalid_embeddings = []\n",
    "    \n",
    "    for namespace, documents in docs_by_ns.items():\n",
    "        print(f\"\\nðŸ“ Namespace: {namespace}\")\n",
    "        \n",
    "        for i, doc in enumerate(documents):\n",
    "            # VÃ©rifier prÃ©sence embedding\n",
    "            if \"embedding\" in doc.metadata:\n",
    "                chunks_with_embeddings += 1\n",
    "                \n",
    "                # VÃ©rifier dimension\n",
    "                emb_dim = len(doc.metadata[\"embedding\"])\n",
    "                if emb_dim != 1024:\n",
    "                    invalid_embeddings.append((namespace, i, emb_dim))\n",
    "            \n",
    "            # VÃ©rifier mÃ©tadonnÃ©es essentielles\n",
    "            required_metadata = [\"source\", \"namespace\"]\n",
    "            missing = [key for key in required_metadata if key not in doc.metadata]\n",
    "            if missing:\n",
    "                print(f\"   âš ï¸  Chunk {i} : mÃ©tadonnÃ©es manquantes {missing}\")\n",
    "        \n",
    "        print(f\"   âœ… {len(documents)} chunks validÃ©s\")\n",
    "    \n",
    "    # Rapport final\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ðŸ“Š Chunks avec embeddings : {chunks_with_embeddings}/{total_chunks}\")\n",
    "    \n",
    "    if invalid_embeddings:\n",
    "        print(f\"âš ï¸  Embeddings invalides (dimension â‰  1024) : {len(invalid_embeddings)}\")\n",
    "        for ns, idx, dim in invalid_embeddings[:5]:  # Afficher les 5 premiers\n",
    "            print(f\"   - {ns}[{idx}] : dimension {dim}\")\n",
    "    else:\n",
    "        print(\"âœ… Toutes les dimensions sont correctes (1024)\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return chunks_with_embeddings == total_chunks\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 6 : PIPELINE COMPLET\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "Orchestration complÃ¨te : Chunking â†’ Embeddings â†’ Validation\n",
    "\"\"\"\n",
    "\n",
    "def process_all_documents():\n",
    "    \"\"\"Pipeline complet de traitement\"\"\"\n",
    "    \n",
    "    # Ã‰tape 1 : Chunking (dÃ©jÃ  fait)\n",
    "    print(\"\\nâœ… Ã‰tape 1 : Chunking terminÃ©\")\n",
    "    \n",
    "    # Ã‰tape 2 : GÃ©nÃ©ration des embeddings\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ§® Ã‰TAPE 2 : GÃ‰NÃ‰RATION DES EMBEDDINGS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for namespace, documents in chunked_by_namespace.items():\n",
    "        if documents:\n",
    "            print(f\"\\nðŸ“ Traitement namespace '{namespace}'...\")\n",
    "            generate_embeddings_batch(documents)\n",
    "    \n",
    "    # Ã‰tape 3 : Validation\n",
    "    is_valid = validate_chunked_documents(chunked_by_namespace)\n",
    "    \n",
    "    if is_valid:\n",
    "        # Sauvegarde pour le Notebook 4\n",
    "        print(\"\\nðŸ’¾ Sauvegarde des documents pour indexation...\")\n",
    "        \n",
    "        serializable = {}\n",
    "        for ns, docs in chunked_by_namespace.items():\n",
    "            serializable[ns] = [\n",
    "                {\n",
    "                    \"page_content\": doc.page_content,\n",
    "                    \"metadata\": {\n",
    "                        k: v for k, v in doc.metadata.items()\n",
    "                        if k != \"embedding\"  # Embeddings trop gros pour JSON\n",
    "                    },\n",
    "                    \"embedding\": doc.metadata.get(\"embedding\", [])\n",
    "                }\n",
    "                for doc in docs\n",
    "            ]\n",
    "        \n",
    "        with open(\"embedded_documents.json\", \"w\") as f:\n",
    "            json.dump(serializable, f, indent=2)\n",
    "        \n",
    "        print(\"âœ… Documents sauvegardÃ©s dans 'embedded_documents.json'\")\n",
    "        print(\"\\nðŸŽ¯ PrÃªt pour l'indexation Pinecone (Notebook 4)\")\n",
    "    else:\n",
    "        print(\"\\nâŒ Validation Ã©chouÃ©e. VÃ©rifiez les erreurs ci-dessus.\")\n",
    "\n",
    "# ExÃ©cution\n",
    "if __name__ == \"__main__\":\n",
    "    if docs_by_namespace:\n",
    "        process_all_documents()\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  Aucun document Ã  traiter.\")\n",
    "        print(\"   ExÃ©cutez d'abord les Notebooks 1 et 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Clients Pinecone et Mistral initialisÃ©s\n",
      "âœ… 111 documents chargÃ©s depuis embedded_documents.json\n",
      "\n",
      "============================================================\n",
      "ðŸ“¤ INDEXATION PINECONE\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Traitement namespace : news\n",
      "\n",
      "ðŸ“¤ Upsert vers namespace 'news'...\n",
      "   109 vecteurs en 2 batches\n",
      "   âœ… Batch 1/2 envoyÃ©\n",
      "   âœ… Batch 2/2 envoyÃ©\n",
      "\n",
      "ðŸ“ Traitement namespace : macro_data\n",
      "\n",
      "ðŸ“¤ Upsert vers namespace 'macro_data'...\n",
      "   2 vecteurs en 1 batches\n",
      "   âœ… Batch 1/1 envoyÃ©\n",
      "\n",
      "============================================================\n",
      "âœ… INDEXATION TERMINÃ‰E\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ðŸ” VALIDATION DE L'INDEXATION\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Statistiques de l'index 'kpmg-veille' :\n",
      "   Total vecteurs : 111\n",
      "\n",
      "ðŸ“ Vecteurs par namespace :\n",
      "   - macro_data: 2 vecteurs\n",
      "   - news: 109 vecteurs\n",
      "\n",
      "ðŸ§ª Test de recherche sur namespace 'news'...\n",
      "   âœ… 3 rÃ©sultats trouvÃ©s\n",
      "\n",
      "   Premier rÃ©sultat :\n",
      "   Source : press_release\n",
      "   Contenu : opens in new window\n",
      "\n",
      "Newsroom\n",
      "\n",
      "\n",
      "Latest News\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Apple Stories\n",
      "\n",
      "                    The creators, developers, and innovators leaving the world better than they found it.\n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "\n",
      "============================================================\n",
      "âœ… VALIDATION TERMINÃ‰E\n",
      "============================================================\n",
      "\n",
      "ðŸŽ¯ SystÃ¨me RAG prÃªt pour les requÃªtes (Notebook 5)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK 4 : Indexation Pinecone avec Namespaces\n",
    "=================================================\n",
    "\n",
    "OBJECTIF : Indexer les documents embeddÃ©s dans Pinecone\n",
    "           en utilisant les namespaces pour l'isolation des sources.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- Pinecone Upsert : https://docs.pinecone.io/docs/upsert-data\n",
    "- LangChain Pinecone : https://python.langchain.com/docs/integrations/vectorstores/pinecone\n",
    "- Namespaces Best Practices : https://docs.pinecone.io/docs/namespaces\n",
    "\n",
    "MÃ‰THODOLOGIE :\n",
    "1. Chargement des documents embeddÃ©s\n",
    "2. Conversion au format Pinecone\n",
    "3. Upsert par batch et namespace\n",
    "4. Validation de l'indexation\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "NOTEBOOK 4 : Indexation Pinecone avec Namespaces\n",
    "=================================================\n",
    "\n",
    "OBJECTIF : Indexer les documents embeddÃ©s dans Pinecone\n",
    "           en utilisant les namespaces pour l'isolation des sources.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- Pinecone Upsert : https://docs.pinecone.io/docs/upsert-data\n",
    "- LangChain Pinecone : https://python.langchain.com/docs/integrations/vectorstores/pinecone\n",
    "- Namespaces Best Practices : https://docs.pinecone.io/docs/namespaces\n",
    "\n",
    "MÃ‰THODOLOGIE :\n",
    "1. Chargement des documents embeddÃ©s\n",
    "2. Conversion au format Pinecone\n",
    "3. Upsert par batch et namespace\n",
    "4. Validation de l'indexation\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Pinecone\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 1 : INITIALISATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "INDEX_NAME = \"kpmg-veille\"\n",
    "\n",
    "if not PINECONE_API_KEY or not MISTRAL_API_KEY:\n",
    "    raise ValueError(\"âŒ ClÃ©s API manquantes dans .env\")\n",
    "\n",
    "# Clients\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "embeddings_model = MistralAIEmbeddings(\n",
    "    model=\"mistral-embed\",\n",
    "    mistral_api_key=MISTRAL_API_KEY\n",
    ")\n",
    "\n",
    "print(\"âœ… Clients Pinecone et Mistral initialisÃ©s\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 2 : CHARGEMENT DES DOCUMENTS EMBEDDÃ‰S\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def load_embedded_documents() -> Dict[str, List[Document]]:\n",
    "    \"\"\"Charge les documents avec leurs embeddings depuis le Notebook 3\"\"\"\n",
    "    try:\n",
    "        with open(\"embedded_documents.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        docs_by_ns = {}\n",
    "        for namespace, docs_data in data.items():\n",
    "            docs_by_ns[namespace] = [\n",
    "                Document(\n",
    "                    page_content=d[\"page_content\"],\n",
    "                    metadata={\n",
    "                        **d[\"metadata\"],\n",
    "                        \"embedding\": d[\"embedding\"]\n",
    "                    }\n",
    "                )\n",
    "                for d in docs_data\n",
    "            ]\n",
    "        \n",
    "        total = sum(len(docs) for docs in docs_by_ns.values())\n",
    "        print(f\"âœ… {total} documents chargÃ©s depuis embedded_documents.json\")\n",
    "        \n",
    "        return docs_by_ns\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Fichier 'embedded_documents.json' introuvable.\")\n",
    "        print(\"   ExÃ©cutez d'abord le Notebook 3 (chunking & embeddings)\")\n",
    "        return {}\n",
    "\n",
    "docs_by_namespace = load_embedded_documents()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 3 : PRÃ‰PARATION DES VECTEURS POUR PINECONE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "FORMAT PINECONE UPSERT\n",
    "\n",
    "Structure requise :\n",
    "{\n",
    "    \"id\": \"unique_id\",\n",
    "    \"values\": [0.1, 0.2, ...],  # Embedding (liste de 1024 floats)\n",
    "    \"metadata\": {...}            # MÃ©tadonnÃ©es (max 40 KB par vecteur)\n",
    "}\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://docs.pinecone.io/docs/upsert-data\n",
    "\"\"\"\n",
    "\n",
    "def prepare_vectors_for_pinecone(documents: List[Document], namespace: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Convertit les Documents au format Pinecone\n",
    "    \n",
    "    Args:\n",
    "        documents: Documents avec embeddings\n",
    "        namespace: Namespace de destination\n",
    "    \n",
    "    Returns:\n",
    "        Liste de vecteurs au format Pinecone\n",
    "    \"\"\"\n",
    "    vectors = []\n",
    "    \n",
    "    for i, doc in enumerate(documents):\n",
    "        # GÃ©nÃ©rer un ID unique\n",
    "        vector_id = f\"{namespace}_{i}_{int(time.time())}\"\n",
    "        \n",
    "        # Extraire l'embedding\n",
    "        embedding = doc.metadata.pop(\"embedding\", None)\n",
    "        \n",
    "        if not embedding:\n",
    "            print(f\"âš ï¸  Document {i} sans embedding, ignorÃ©\")\n",
    "            continue\n",
    "        \n",
    "        # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "        # â•‘ NETTOYAGE CRITIQUE POUR PINECONE                          â•‘\n",
    "        # â•‘ Pinecone refuse les valeurs None et les types complexes  â•‘\n",
    "        # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        \n",
    "        clean_metadata = {}\n",
    "        for k, v in doc.metadata.items():\n",
    "            # Ignorer l'embedding (dÃ©jÃ  extrait)\n",
    "            if k == \"embedding\":\n",
    "                continue\n",
    "            \n",
    "            # Remplacer None par \"Unknown\"\n",
    "            if v is None:\n",
    "                clean_metadata[k] = \"Unknown\"\n",
    "            \n",
    "            # Garder les types primitifs\n",
    "            elif isinstance(v, (str, int, float, bool)):\n",
    "                # Limiter les strings Ã  500 caractÃ¨res\n",
    "                if isinstance(v, str):\n",
    "                    clean_metadata[k] = v[:500]\n",
    "                else:\n",
    "                    clean_metadata[k] = v\n",
    "            \n",
    "            # Convertir les listes en strings\n",
    "            elif isinstance(v, list):\n",
    "                clean_metadata[k] = [str(x) for x in v if x is not None]\n",
    "            \n",
    "            # Fallback : conversion en string pour les objets complexes\n",
    "            else:\n",
    "                clean_metadata[k] = str(v)[:500]\n",
    "        \n",
    "        # Ajouter le contenu dans les mÃ©tadonnÃ©es\n",
    "        clean_metadata[\"text\"] = doc.page_content[:1000]\n",
    "        \n",
    "        vector = {\n",
    "            \"id\": vector_id,\n",
    "            \"values\": embedding,\n",
    "            \"metadata\": clean_metadata\n",
    "        }\n",
    "        \n",
    "        vectors.append(vector)\n",
    "    \n",
    "    return vectors\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 4 : UPSERT PAR BATCH ET NAMESPACE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "STRATÃ‰GIE D'UPSERT\n",
    "\n",
    "1. Traiter par batch de 100 vecteurs (limite Pinecone)\n",
    "2. Utiliser les namespaces pour isoler les sources\n",
    "3. GÃ©rer les erreurs et retry\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://docs.pinecone.io/docs/upsert-data#batching-upserts\n",
    "\"\"\"\n",
    "\n",
    "def upsert_to_pinecone(vectors: List[Dict], namespace: str, batch_size: int = 100):\n",
    "    \"\"\"\n",
    "    Envoie les vecteurs vers Pinecone par batch\n",
    "    \n",
    "    Args:\n",
    "        vectors: Vecteurs au format Pinecone\n",
    "        namespace: Namespace de destination\n",
    "        batch_size: Taille des batches\n",
    "    \"\"\"\n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    total_batches = (len(vectors) + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"\\nðŸ“¤ Upsert vers namespace '{namespace}'...\")\n",
    "    print(f\"   {len(vectors)} vecteurs en {total_batches} batches\")\n",
    "    \n",
    "    for i in range(0, len(vectors), batch_size):\n",
    "        batch = vectors[i:i+batch_size]\n",
    "        batch_num = i // batch_size + 1\n",
    "        \n",
    "        try:\n",
    "            index.upsert(\n",
    "                vectors=batch,\n",
    "                namespace=namespace\n",
    "            )\n",
    "            print(f\"   âœ… Batch {batch_num}/{total_batches} envoyÃ©\")\n",
    "            \n",
    "            # Rate limiting (10 req/sec max pour Pinecone gratuit)\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Erreur batch {batch_num}: {e}\")\n",
    "            # Retry une fois\n",
    "            try:\n",
    "                time.sleep(1)\n",
    "                index.upsert(vectors=batch, namespace=namespace)\n",
    "                print(f\"   âœ… Retry rÃ©ussi pour batch {batch_num}\")\n",
    "            except Exception as e2:\n",
    "                print(f\"   âŒ Retry Ã©chouÃ© : {e2}\")\n",
    "                continue\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 5 : INDEXATION COMPLÃˆTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def index_all_documents():\n",
    "    \"\"\"Pipeline complet d'indexation\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“¤ INDEXATION PINECONE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not docs_by_namespace:\n",
    "        print(\"âŒ Aucun document Ã  indexer\")\n",
    "        return\n",
    "    \n",
    "    for namespace, documents in docs_by_namespace.items():\n",
    "        if not documents:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nðŸ“ Traitement namespace : {namespace}\")\n",
    "        \n",
    "        # PrÃ©paration des vecteurs\n",
    "        vectors = prepare_vectors_for_pinecone(documents, namespace)\n",
    "        \n",
    "        if vectors:\n",
    "            # Upsert vers Pinecone\n",
    "            upsert_to_pinecone(vectors, namespace)\n",
    "        else:\n",
    "            print(f\"   âš ï¸  Aucun vecteur valide pour {namespace}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… INDEXATION TERMINÃ‰E\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 6 : VALIDATION POST-INDEXATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "VALIDATION :\n",
    "- VÃ©rifier le nombre de vecteurs indexÃ©s\n",
    "- Tester une recherche simple\n",
    "- Confirmer l'isolation des namespaces\n",
    "\"\"\"\n",
    "\n",
    "def validate_indexation():\n",
    "    \"\"\"Valide que l'indexation s'est bien passÃ©e\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ” VALIDATION DE L'INDEXATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    stats = index.describe_index_stats()\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Statistiques de l'index '{INDEX_NAME}' :\")\n",
    "    print(f\"   Total vecteurs : {stats.total_vector_count}\")\n",
    "    print(f\"\\nðŸ“ Vecteurs par namespace :\")\n",
    "    \n",
    "    for namespace, info in stats.namespaces.items():\n",
    "        print(f\"   - {namespace}: {info.vector_count} vecteurs\")\n",
    "    \n",
    "    # Test de recherche\n",
    "    print(\"\\nðŸ§ª Test de recherche sur namespace 'news'...\")\n",
    "    \n",
    "    try:\n",
    "        vectorstore = PineconeVectorStore(\n",
    "            index_name=INDEX_NAME,\n",
    "            embedding=embeddings_model,\n",
    "            namespace=\"news\"\n",
    "        )\n",
    "        \n",
    "        results = vectorstore.similarity_search(\n",
    "            \"latest technology news\",\n",
    "            k=3\n",
    "        )\n",
    "        \n",
    "        print(f\"   âœ… {len(results)} rÃ©sultats trouvÃ©s\")\n",
    "        \n",
    "        if results:\n",
    "            print(f\"\\n   Premier rÃ©sultat :\")\n",
    "            print(f\"   Source : {results[0].metadata.get('source')}\")\n",
    "            print(f\"   Contenu : {results[0].page_content[:200]}...\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Erreur de recherche : {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… VALIDATION TERMINÃ‰E\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 7 : EXÃ‰CUTION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Indexation\n",
    "    index_all_documents()\n",
    "    \n",
    "    # Validation\n",
    "    time.sleep(2)  # Laisser Pinecone finaliser l'indexation\n",
    "    validate_indexation()\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ SystÃ¨me RAG prÃªt pour les requÃªtes (Notebook 5)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faut il Nettoyer les mÃ©tadonnÃ©es avant dâ€™upser ?\n",
    "\n",
    "Pour identifier l'erreur, donner le requirement, l'env et le notebook a claude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ModÃ¨les Mistral initialisÃ©s\n",
      "âœ… Prompt KPMG configurÃ©\n",
      "\n",
      "============================================================\n",
      "ðŸ” ANALYSE EN COURS...\n",
      "============================================================\n",
      "Question : Quelles sont les derniÃ¨res informations sur Apple ?\n",
      "Namespace : Tous (recherche globale)\n",
      "============================================================\n",
      "\n",
      "**Analyse stratÃ©gique des derniÃ¨res Ã©volutions dâ€™Apple (juin 2024)**\n",
      "\n",
      "Apple Inc. (AAPL) traverse une pÃ©riode charniÃ¨re marquÃ©e par des dÃ©fis macroÃ©conomiques, des innovations technologiques et des ajustements stratÃ©giques. Voici une synthÃ¨se des dÃ©veloppements rÃ©cents, structurÃ©e selon les axes financiers, produits, rÃ©glementaires et concurrentiels, avec une attention particuliÃ¨re aux signaux actionnables pour les investisseurs.\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Performance financiÃ¨re et perspectives : un trimestre mitigÃ© dans un contexte de ralentissement**\n",
      "Apple a publiÃ© ses rÃ©sultats du **second trimestre fiscal 2024 (clÃ´turÃ© le 30 mars)** le 2 mai, rÃ©vÃ©lant une **baisse de 4,3 % du chiffre dâ€™affaires annuel** Ã  **90,8 milliards de dollars**, en deÃ§Ã  des attentes des analystes (consensus Ã  90,9 Md$). Le bÃ©nÃ©fice net a reculÃ© de 2,2 % Ã  23,6 Md$, soit **1,53 $ par action** (stable sur un an) [SEC Filing 10-Q Apple | â­â­â­ | 2024-05-02]. Cette performance reflÃ¨te principalement :\n",
      "- **Un dÃ©clin des ventes dâ€™iPhone (-10 % en glissement annuel)** Ã  45,9 Md$, attribuÃ© Ã  un marchÃ© des smartphones mature et Ã  une concurrence accrue en Chine (oÃ¹ les revenus ont chutÃ© de 8 %).\n",
      "- **La croissance des Services (+14 % Ã  23,9 Md$)** reste le point fort, portÃ©e par les abonnements (Apple TV+, Apple Music, iCloud) et les commissions de lâ€™App Store. Ce segment reprÃ©sente dÃ©sormais **26 % du CA total**, confirmant la stratÃ©gie de diversification vers des revenus rÃ©currents.\n",
      "- **Les ventes de Mac (+4 % Ã  7,5 Md$)** et dâ€™iPad (+17 % Ã  5,6 Md$) ont surpris positivement, grÃ¢ce aux mises Ã  jour des puces M3 et Ã  une demande professionnelle rÃ©siliente.\n",
      "\n",
      "Pour le **trimestre en cours (Q3 2024)**, Apple anticipe une **croissance similaire Ã  celle du Q2**, avec des vents contraires persistants en Chine et une reprise attendue des ventes dâ€™iPhone avec le lancement probable de lâ€™**iPhone 16 en septembre** [Earnings Call Transcript, Seeking Alpha | â­â­ | 2024-05-02]. Les analystes de **Goldman Sachs** maintiennent une cible de cours Ã  **210 $** (vs. ~190 $ actuel), soulignant la sous-Ã©valuation relative du titre (PER 2024e ~28x, infÃ©rieur Ã  la moyenne historique) [Goldman Sachs Research | â­â­ | 2024-05-15].\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Innovations produits : lâ€™IA et la rÃ©alitÃ© mixte au cÅ“ur de la feuille de route**\n",
      "Apple a officiellement annoncÃ© son entrÃ©e dans lâ€™Ã¨re de lâ€™**intelligence artificielle gÃ©nÃ©rative** lors de la **WWDC 2024 (10 juin)**, avec :\n",
      "- **Apple Intelligence** : une couche dâ€™IA intÃ©grÃ©e Ã  iOS 18, iPadOS et macOS, incluant des fonctionnalitÃ©s comme la **rÃ©Ã©criture de textes**, la **gÃ©nÃ©ration dâ€™images** (via un partenariat avec Adobe Firefly), et un **assistant personnel avancÃ©** capable dâ€™agir sur les applications. Contrairement Ã  Microsoft Copilot, Apple mise sur une **approche \"on-device\"** pour la confidentialitÃ©, avec des modÃ¨les lÃ©gers (ex. **3B paramÃ¨tres**) optimisÃ©s pour ses puces [Keynote WWDC 2024 | â­â­â­ | 2024-06-10].\n",
      "- **Vision Pro** : aprÃ¨s un lancement commercial en **fÃ©vrier 2024** (prix : 3 499 $), le casque de rÃ©alitÃ© mixte a connu des **ventes initiales estimÃ©es Ã  200 000 unitÃ©s** (vs. 400 000 attendues), limitÃ©es par son coÃ»t et son poids [IDC Report | â­â­ | 2024-04-15]. Apple aurait cependant **accÃ©lÃ©rÃ© le dÃ©veloppement dâ€™une version \"Pro Lite\"** (prix cible ~1 500 $) pour 2025, selon des fuites de la chaÃ®ne dâ€™approvisionnement [Bloomberg, Mark Gurman | â­â­ | 2024-06-05].\n",
      "\n",
      "Dans lâ€™**Ã©cosystÃ¨me matÃ©riel**, les rumeurs persistent autour :\n",
      "- Dâ€™un **iPhone 16 avec bouton dâ€™action programmable** et Ã©cran plus grand (6,3\" pour le modÃ¨le Pro), ainsi que des **capteurs dâ€™IA dÃ©diÃ©s** pour le traitement local [DigiTimes | â­â­ | 2024-05-20].\n",
      "- Dâ€™une **nouvelle gÃ©nÃ©ration de puces M4** pour les Mac, gravÃ©es en **3 nm** par TSMC, avec des gains dâ€™efficacitÃ© Ã©nergÃ©tique de 20 % [Nikkei Asia | â­â­ | 2024-06-01].\n",
      "\n",
      "---\n",
      "### **3. Enjeux rÃ©glementaires : pressions anticoncurrentielles et gÃ©opolitiques**\n",
      "Apple fait face Ã  des **risques juridiques majeurs** :\n",
      "- **Affaire DOJ vs. Apple (mars 2024)** : le DÃ©partement de la Justice amÃ©ricain a dÃ©posÃ© une plainte pour **monopole sur les smartphones**, accusant Apple de **restreindre les concurrents** (ex. bloqueurs de messages entre iOS et Android, limitations sur les paiements sans contact). Une dÃ©cision pourrait prendre **2-3 ans**, mais une condamnation entraÃ®nerait des **changements structurels** (ex. ouverture de lâ€™App Store Ã  des stores tiers) [DOJ Complaint | â­â­â­ | 2024-03-21].\n",
      "- **RÃ¨glement DMA en UE** : depuis mars 2024, Apple doit permettre les **boutiques dâ€™apps alternatives** et les **systÃ¨mes de paiement tiers** en Europe, sous peine dâ€™amendes jusquâ€™Ã  **10 % du CA mondial**. La Commission europÃ©enne a dÃ©jÃ  ouvert une enquÃªte pour **non-conformitÃ©** sur les frais imposÃ©s aux dÃ©veloppeurs (jusquâ€™Ã  0,50 â‚¬ par tÃ©lÃ©chargement) [European Commission Press Release | â­â­â­ | 2024-04-30].\n",
      "- **Chine** : les tensions avec PÃ©kin sâ€™intensifient aprÃ¨s lâ€™**interdiction des iPhone pour les fonctionnaires** (septembre 2023) et les **restrictions sur les apps Ã©trangÃ¨res** (ex. WhatsApp bloquÃ©). Apple a annoncÃ© un **investissement de 1 Md$** dans un centre de R&D Ã  Shanghai pour apaiser les relations [Caixin Global | â­â­ | 2024-05-10].\n",
      "\n",
      "---\n",
      "### **4. Dynamique concurrentielle : guerre des Ã©cosystÃ¨mes et bataille de lâ€™IA**\n",
      "- **Vs. Microsoft/Samsung** : la collaboration **Microsoft-Copilot sur Windows** et les **Galaxy AI de Samsung** (ex. traduction en temps rÃ©el) exercent une pression sur lâ€™Ã©cosystÃ¨me fermÃ© dâ€™Apple. Cependant, Apple mise sur son **avance en intÃ©gration matÃ©riel/logiciel** (ex. puces M3 vs. Qualcomm Snapdragon X).\n",
      "- **Vs. Google** : lâ€™**IA gÃ©nÃ©rative** (Gemini) et les **Pixel 9** (attendus en octobre avec des capteurs IA dÃ©diÃ©s) ciblent directement lâ€™iPhone. Google a Ã©galement annoncÃ© des **frais rÃ©duits** pour les dÃ©veloppeurs sur le Play Store (15 % vs. 30 % dâ€™Apple), exploitant les faiblesses rÃ©glementaires de son rival [Alphabet Earnings Call | â­â­â­ | 2024-04-25].\n",
      "- **Vs. Meta** : les **lunettes Ray-Ban Meta** (299 $) et le **Quest 3** (499 $) concurrencent le Vision Pro sur le marchÃ© de la rÃ©alitÃ© mixte, avec un avantage prix. Meta a cependant Ã©chouÃ© Ã  percer le segment premium, laissant Ã  Apple une **marge de manÅ“uvre sur le haut de gamme** [Counterpoint Research | â­â­ | 2024-05-28].\n",
      "\n",
      "---\n",
      "### **5. Signaux ESG et risques extra-financiers**\n",
      "- **NeutralitÃ© carbone** : Apple a atteint son objectif de **100 % dâ€™Ã©lectricitÃ© renouvelable** pour ses opÃ©rations (2023) et vise une **chaÃ®ne dâ€™approvisionnement neutre en carbone dâ€™ici 2030**. Cependant, des ONG critiquent son **dÃ©pendance aux minerais de conflit** (ex. cobalt du Congo) [Apple ESG Report 2023 | â­â­â­ | 2024-04-10].\n",
      "- **Travail forcÃ©** : un rapport de **Tech Transparency Project** a rÃ©vÃ©lÃ© des liens indirects avec des fournisseurs chinois accusÃ©s dâ€™utiliser du **travail ouÃ¯ghour**. Apple a rompu avec 3 sous-traitants, mais le risque rÃ©putationnel persiste [Reuters | â­â­ | 2024-03-15].\n",
      "\n",
      "---\n",
      "### **6. Recommandations stratÃ©giques pour les investisseurs**\n",
      "**OpportunitÃ©s :**\n",
      "- **Services et IA** : le segment Services (marge ~70 %) et lâ€™intÃ©gration de lâ€™IA pourraient **ajouter 5-10 % au CA dâ€™ici 2026**. Les partenariats avec des acteurs comme **OpenAI** (intÃ©gration de ChatGPT dans iOS 18) renforcent cette thÃ¨se.\n",
      "- **Rachats dâ€™actions** : Apple a annoncÃ© un **programme de 110 Md$** (2024-2025), soit ~5 % de sa capitalisation, soutenant le cours Ã  court terme [SEC 8-K | â­â­â­ | 2024-05-02].\n",
      "- **Dividende** : avec un rendement de **0,5 %** et une croissance annuelle de **5-7 %**, Apple reste attractive pour les investisseurs value.\n",
      "\n",
      "**Risques :**\n",
      "- **DÃ©pendance Ã  la Chine** (19 % du CA en 2023) : une escalade des tensions commercialess pourrait impacter **10-15 % des revenus**.\n",
      "- **RÃ©gulation** : une condamnation dans lâ€™affaire DOJ pourrait **rÃ©duire les marges de lâ€™App Store** (actuellement ~78 %).\n",
      "- **Innovation** : le succÃ¨s du Vision Pro et de lâ€™IA sera critique pour justifier la prime de valorisation.\n",
      "\n",
      "**ScÃ©narios :**\n",
      "- **Bull Case (240 $)** : succÃ¨s de lâ€™iPhone 16, adoption massive de lâ€™IA, et rÃ©solution des litiges rÃ©glementaires.\n",
      "- **Base Case (200 $)** : croissance modÃ©rÃ©e des Services, pression en Chine, et statu quo rÃ©glementaire.\n",
      "- **Bear Case (160 $)** : condamnation DOJ, Ã©chec du Vision Pro, et rÃ©cession aux Ã‰tats-Unis.\n",
      "\n",
      "---\n",
      "### **Sources complÃ©mentaires pour approfondir**\n",
      "- **DonnÃ©es financiÃ¨res** : [Yahoo Finance (AAPL)](https://finance.yahoo.com/quote/AAPL/) | â­â­â­\n",
      "- **Analyse concurrentielle** : [Counterpoint Research â€“ Smartphone Market Share Q1 2024](https://www.counterpointresearch.com/) | â­â­\n",
      "- **RÃ©gulation** : [DOJ Antitrust Division â€“ Apple Case](https://www.justice.gov/atr) | â­â­â­\n",
      "\n",
      "---\n",
      "**Prochaines Ã©tapes suggÃ©rÃ©es :**\n",
      "1. **Surveiller** les prÃ©commandes de lâ€™iPhone 16 (septembre 2024) pour Ã©valuer la demande.\n",
      "2. **Analyser** lâ€™impact des premiÃ¨res applications tierces utilisant Apple Intelligence (disponibles en bÃªta cet Ã©tÃ©).\n",
      "3. **Ã‰valuer** les rÃ©actions des rÃ©gulateurs europÃ©ens Ã  la conformitÃ© DMA dâ€™Apple (dÃ©but 2025).\n",
      "\n",
      "Souhaitez-vous une analyse approfondie sur un axe spÃ©cifique (ex. chaÃ®ne dâ€™approvisionnement en Chine, benchmark des puces M4 vs. Snapdragon X) ?\n",
      "\n",
      "âœ… SystÃ¨me RAG KPMG opÃ©rationnel\n",
      "ðŸŽ¯ PrÃªt pour l'interface Gradio (optionnel)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK 5 : RAG Query & Prompt Engineering pour Veille KPMG\n",
    "============================================================\n",
    "\n",
    "OBJECTIF : CrÃ©er un systÃ¨me de requÃªtes RAG optimisÃ© pour la veille stratÃ©gique\n",
    "           avec prompting avancÃ© et citations obligatoires.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- Mistral Prompting : https://docs.mistral.ai/guides/prompting_capabilities/\n",
    "- LangChain RAG : https://python.langchain.com/docs/use_cases/question_answering/\n",
    "- KPMG Requirements : hackathon KPMG (1).pdf\n",
    "\n",
    "EXIGENCES CRITIQUES :\n",
    "âœ“ Citations systÃ©matiques des sources\n",
    "âœ“ Indication de fiabilitÃ© et date\n",
    "âœ“ RÃ©ponses structurÃ©es (pas de bullet points sauf demande explicite)\n",
    "âœ“ IA explicable (chaÃ®ne de raisonnement)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 1 : INITIALISATION DES COMPOSANTS RAG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "INDEX_NAME = \"kpmg-veille\"\n",
    "\n",
    "# ModÃ¨le d'embeddings\n",
    "embeddings = MistralAIEmbeddings(\n",
    "    model=\"mistral-embed\",\n",
    "    mistral_api_key=MISTRAL_API_KEY\n",
    ")\n",
    "\n",
    "# ModÃ¨le LLM (Mistral Medium pour raisonnement)\n",
    "llm = ChatMistralAI(\n",
    "    model=\"mistral-medium\",\n",
    "    temperature=0,  # DÃ©terministe pour analyses factuelles\n",
    "    mistral_api_key=MISTRAL_API_KEY\n",
    ")\n",
    "\n",
    "print(\"âœ… ModÃ¨les Mistral initialisÃ©s\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 2 : RETRIEVERS PAR NAMESPACE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "STRATÃ‰GIE DE RETRIEVAL\n",
    "\n",
    "On crÃ©e un retriever par namespace pour permettre des requÃªtes ciblÃ©es.\n",
    "L'utilisateur peut spÃ©cifier le namespace ou interroger tous les namespaces.\n",
    "\n",
    "PARAMÃˆTRES :\n",
    "- k=5 : Top 5 documents les plus pertinents\n",
    "- score_threshold : Filtrage par similaritÃ© (optionnel)\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://python.langchain.com/docs/modules/data_connection/retrievers/\n",
    "\"\"\"\n",
    "\n",
    "NAMESPACES = [\n",
    "    \"financial_reports\",\n",
    "    \"news\",\n",
    "    \"macro_data\"\n",
    "]\n",
    "\n",
    "def get_retriever(namespace: Optional[str] = None, k: int = 5):\n",
    "    \"\"\"\n",
    "    CrÃ©e un retriever pour un namespace spÃ©cifique ou global\n",
    "    \n",
    "    Args:\n",
    "        namespace: Namespace ciblÃ© (None = tous les namespaces)\n",
    "        k: Nombre de documents Ã  rÃ©cupÃ©rer\n",
    "    \n",
    "    Returns:\n",
    "        Retriever configurÃ©\n",
    "    \"\"\"\n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=embeddings,\n",
    "        namespace=namespace  # None = recherche sur tous les namespaces\n",
    "    )\n",
    "    \n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": k}\n",
    "    )\n",
    "    \n",
    "    return retriever\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 3 : PROMPT ENGINEERING KPMG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "PROMPT STRUCTURÃ‰ SELON LES EXIGENCES KPMG\n",
    "\n",
    "InspirÃ© de vos notes (hackathon KPMG.pdf) :\n",
    "âœ“ Assistant Intelligent de Veille StratÃ©gique\n",
    "âœ“ Citations OBLIGATOIRES avec source, date, fiabilitÃ©\n",
    "âœ“ RÃ©ponse en prose (pas de bullet points par dÃ©faut)\n",
    "âœ“ Indication si donnÃ©es manquantes ou payantes\n",
    "âœ“ CapacitÃ© Ã  demander des prÃ©cisions\n",
    "\n",
    "STRUCTURE :\n",
    "1. RÃ´le et expertise\n",
    "2. Instructions de citation\n",
    "3. Format de rÃ©ponse\n",
    "4. Gestion des cas limites\n",
    "\"\"\"\n",
    "\n",
    "KPMG_PROMPT_TEMPLATE = \"\"\"Vous Ãªtes l'Assistant Intelligent de Veille StratÃ©gique de KPMG Global Strategy Group.\n",
    "\n",
    "Votre mission : Fournir des analyses de marchÃ© prÃ©cises, sourcÃ©es et actionnables pour aider nos clients Ã  prendre des dÃ©cisions d'investissement Ã©clairÃ©es.\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "RÃˆGLES DE CITATION (OBLIGATOIRES)\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "Pour CHAQUE information factuelle (chiffres, dates, faits) vous DEVEZ :\n",
    "1. Citer la source exacte (ex: \"SEC Filing 10-K d'Apple - 2024-01-15\")\n",
    "2. Indiquer le niveau de fiabilitÃ© :\n",
    "   - â­â­â­ : Source primaire (SEC, rapport officiel, yfinance)\n",
    "   - â­â­ : Source secondaire fiable (NewsAPI, presse reconnue)\n",
    "   - â­ : Source tertiaire (blogs, rÃ©seaux sociaux)\n",
    "3. PrÃ©ciser la date de l'information si critique\n",
    "\n",
    "Format de citation : [Source | FiabilitÃ© | Date]\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "CONTEXTE DISPONIBLE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "{context}\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "QUESTION DU CLIENT\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "{question}\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "INSTRUCTIONS DE RÃ‰PONSE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "1. STRUCTURE :\n",
    "   - RÃ©pondez en prose fluide (paragraphes, pas de bullet points)\n",
    "   - Organisez votre rÃ©ponse de faÃ§on logique et narrative\n",
    "   - Utilisez des transitions naturelles entre les idÃ©es\n",
    "\n",
    "2. CONTENU :\n",
    "   - Citez systÃ©matiquement vos sources (format ci-dessus)\n",
    "   - Si une donnÃ©e est manquante : indiquez-le explicitement\n",
    "   - Si une information nÃ©cessite un accÃ¨s payant : prÃ©cisez-le\n",
    "   - Si le contexte est ambigu : demandez des prÃ©cisions au client\n",
    "\n",
    "3. TONE :\n",
    "   - Professionnel mais accessible\n",
    "   - Factuel et analytique\n",
    "   - Confiant sur les donnÃ©es sourcÃ©es, prudent sur les spÃ©culations\n",
    "\n",
    "4. CAS LIMITES :\n",
    "   - Si vous ne trouvez pas l'information : \"Les donnÃ©es disponibles ne permettent pas de rÃ©pondre Ã  cette question. Sources consultÃ©es : [liste]. Je recommande [action].\"\n",
    "   - Si deux sources se contredisent : Mentionnez les deux et expliquez pourquoi\n",
    "   - Si une entreprise est ambiguÃ« : \"J'ai identifiÃ© plusieurs entreprises nommÃ©es [X]. Pouvez-vous prÃ©ciser : secteur, gÃ©ographie, ou autre contexte ?\"\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "RÃ‰PONSE ANALYTIQUE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(KPMG_PROMPT_TEMPLATE)\n",
    "\n",
    "print(\"âœ… Prompt KPMG configurÃ©\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 4 : FORMATAGE DU CONTEXTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "FORMATAGE DES DOCUMENTS RÃ‰CUPÃ‰RÃ‰S\n",
    "\n",
    "On enrichit le contexte avec :\n",
    "- Source et type de document\n",
    "- Date de publication/scraping\n",
    "- Namespace d'origine\n",
    "- Score de pertinence (si disponible)\n",
    "\"\"\"\n",
    "\n",
    "def format_docs(docs) -> str:\n",
    "    \"\"\"\n",
    "    Formate les documents rÃ©cupÃ©rÃ©s pour le prompt\n",
    "    \n",
    "    Args:\n",
    "        docs: Documents LangChain\n",
    "    \n",
    "    Returns:\n",
    "        String formatÃ© avec mÃ©tadonnÃ©es enrichies\n",
    "    \"\"\"\n",
    "    formatted = []\n",
    "    \n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        metadata = doc.metadata\n",
    "        \n",
    "        # Construction de l'entrÃ©e\n",
    "        entry = f\"â”â”â” DOCUMENT {i} â”â”â”\\n\"\n",
    "        entry += f\"Source : {metadata.get('source', 'Unknown')}\\n\"\n",
    "        entry += f\"Type : {metadata.get('namespace', 'Unknown')}\\n\"\n",
    "        \n",
    "        # Date si disponible\n",
    "        date_fields = ['filing_date', 'published_at', 'scrape_date', 'retrieval_date']\n",
    "        for field in date_fields:\n",
    "            if field in metadata:\n",
    "                entry += f\"Date : {metadata[field]}\\n\"\n",
    "                break\n",
    "        \n",
    "        # URL si disponible\n",
    "        if 'url' in metadata:\n",
    "            entry += f\"URL : {metadata['url']}\\n\"\n",
    "        \n",
    "        # Contenu\n",
    "        entry += f\"\\nContenu :\\n{doc.page_content}\\n\"\n",
    "        \n",
    "        formatted.append(entry)\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 5 : CHAÃŽNE RAG COMPLÃˆTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "ARCHITECTURE LCEL (LangChain Expression Language)\n",
    "\n",
    "Pipeline : Retriever â†’ Format Context â†’ Prompt â†’ LLM â†’ Parse\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://python.langchain.com/docs/expression_language/\n",
    "\"\"\"\n",
    "\n",
    "def create_rag_chain(namespace: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    CrÃ©e une chaÃ®ne RAG complÃ¨te\n",
    "    \n",
    "    Args:\n",
    "        namespace: Namespace ciblÃ© (None = tous)\n",
    "    \n",
    "    Returns:\n",
    "        ChaÃ®ne RAG exÃ©cutable\n",
    "    \"\"\"\n",
    "    retriever = get_retriever(namespace=namespace, k=5)\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\n",
    "            \"context\": retriever | format_docs,\n",
    "            \"question\": RunnablePassthrough()\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    return rag_chain\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 6 : INTERFACE DE REQUÃŠTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "FONCTIONS D'INTERFACE UTILISATEUR\n",
    "\n",
    "Permettent d'interroger le systÃ¨me de diffÃ©rentes maniÃ¨res :\n",
    "- RequÃªte simple (tous namespaces)\n",
    "- RequÃªte ciblÃ©e (namespace spÃ©cifique)\n",
    "- RequÃªte multi-namespaces (comparaison)\n",
    "\"\"\"\n",
    "\n",
    "def query_veille(question: str, namespace: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Interface principale de requÃªte\n",
    "    \n",
    "    Args:\n",
    "        question: Question de l'utilisateur\n",
    "        namespace: Namespace ciblÃ© (optionnel)\n",
    "    \n",
    "    Returns:\n",
    "        RÃ©ponse formatÃ©e avec citations\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ” ANALYSE EN COURS...\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Question : {question}\")\n",
    "    \n",
    "    if namespace:\n",
    "        print(f\"Namespace : {namespace}\")\n",
    "    else:\n",
    "        print(\"Namespace : Tous (recherche globale)\")\n",
    "    \n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    try:\n",
    "        chain = create_rag_chain(namespace)\n",
    "        response = chain.invoke(question)\n",
    "        return response\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"âŒ Erreur lors de la requÃªte : {e}\"\n",
    "\n",
    "def compare_namespaces(question: str, namespaces: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Compare les rÃ©ponses de plusieurs namespaces\n",
    "    \n",
    "    Args:\n",
    "        question: Question\n",
    "        namespaces: Liste de namespaces Ã  comparer\n",
    "    \n",
    "    Returns:\n",
    "        Dictionnaire {namespace: rÃ©ponse}\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for ns in namespaces:\n",
    "        print(f\"\\nðŸ“ Interrogation de '{ns}'...\")\n",
    "        results[ns] = query_veille(question, namespace=ns)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 7 : EXEMPLES D'UTILISATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "SCÃ‰NARIOS DE DÃ‰MONSTRATION KPMG\n",
    "\n",
    "Ces exemples illustrent les capacitÃ©s du systÃ¨me :\n",
    "1. Analyse de marchÃ©\n",
    "2. Due diligence d'entreprise\n",
    "3. DÃ©tection de tendances\n",
    "4. Analyse concurrentielle\n",
    "\"\"\"\n",
    "\n",
    "def demo_scenarios():\n",
    "    \"\"\"DÃ©montre les capacitÃ©s du systÃ¨me avec des cas rÃ©els\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"ðŸŽ¯ \"*20)\n",
    "    print(\" DÃ‰MONSTRATION RAG VEILLE KPMG\")\n",
    "    print(\"ðŸŽ¯ \"*20 + \"\\n\")\n",
    "    \n",
    "    scenarios = [\n",
    "        {\n",
    "            \"titre\": \"1. ANALYSE FINANCIÃˆRE D'ENTREPRISE\",\n",
    "            \"question\": \"Quelle est la capitalisation boursiÃ¨re actuelle d'Apple et son Ã©volution ?\",\n",
    "            \"namespace\": \"macro_data\"\n",
    "        },\n",
    "        {\n",
    "            \"titre\": \"2. VEILLE ACTUALITÃ‰S SECTEUR TECH\",\n",
    "            \"question\": \"Quelles sont les derniÃ¨res actualitÃ©s concernant l'intelligence artificielle et la finance ?\",\n",
    "            \"namespace\": \"news\"\n",
    "        },\n",
    "        {\n",
    "            \"titre\": \"3. RECHERCHE GLOBALE (TOUS NAMESPACES)\",\n",
    "            \"question\": \"Quels sont les principaux risques et opportunitÃ©s pour les entreprises tech en 2024 ?\",\n",
    "            \"namespace\": None\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        print(\"\\n\" + \"â”€\"*60)\n",
    "        print(f\"ðŸ“Š {scenario['titre']}\")\n",
    "        print(\"â”€\"*60)\n",
    "        \n",
    "        response = query_veille(\n",
    "            question=scenario['question'],\n",
    "            namespace=scenario['namespace']\n",
    "        )\n",
    "        \n",
    "        print(\"\\nðŸ’¡ RÃ‰PONSE :\\n\")\n",
    "        print(response)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 8 : EXÃ‰CUTION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Exemple simple\n",
    "    question = \"Quelles sont les derniÃ¨res informations sur Apple ?\"\n",
    "    response = query_veille(question)\n",
    "    print(response)\n",
    "    \n",
    "    # DÃ©commenter pour la dÃ©mo complÃ¨te\n",
    "    # demo_scenarios()\n",
    "    \n",
    "    print(\"\\nâœ… SystÃ¨me RAG KPMG opÃ©rationnel\")\n",
    "    print(\"ðŸŽ¯ PrÃªt pour l'interface Gradio (optionnel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Initialisation de l'interface KPMG (mistral-small)...\n",
      "âœ… Variables d'environnement chargÃ©es\n",
      "âœ… Embeddings initialisÃ©s\n",
      "âœ… Retriever configurÃ©\n",
      "âœ… LLM Mistral Small initialisÃ©\n",
      "âœ… Prompt configurÃ©\n",
      "âœ… ChaÃ®ne RAG construite\n",
      "âœ… Modules rechargÃ©s Ã  chaud !\n",
      "* Running on local URL:  http://127.0.0.1:7875\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Gradio Blocks instance: 37 backend functions\n",
       "--------------------------------------------\n",
       "fn_index=0\n",
       " inputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f2fc910>\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f2fc2d0>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12f2fc410>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12f2fc550>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12f2fc690>\n",
       " outputs:\n",
       " |-<gradio.components.number.Number object at 0x12f2fda90>\n",
       " |-<gradio.components.slider.Slider object at 0x12f2fdbd0>\n",
       " |-<gradio.components.slider.Slider object at 0x12f2fdd10>\n",
       "fn_index=1\n",
       " inputs:\n",
       " |-<gradio.components.radio.Radio object at 0x12f2fd950>\n",
       " |-<gradio.components.number.Number object at 0x12f2fda90>\n",
       " |-<gradio.components.slider.Slider object at 0x12f2fdbd0>\n",
       " |-<gradio.components.slider.Slider object at 0x12f2fdd10>\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f2fc910>\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f2fc2d0>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12f2fc410>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12f2fc550>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12f2fc690>\n",
       " outputs:\n",
       " |-<gradio.components.plot.Plot object at 0x12f2fd6d0>\n",
       " |-<gradio.components.plot.Plot object at 0x12f2fe0d0>\n",
       " |-<gradio.components.html.HTML object at 0x12f2fe5d0>\n",
       " |-<gradio.components.dataframe.Dataframe object at 0x12f2fead0>\n",
       "fn_index=2\n",
       " inputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f2fc910>\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f2fc2d0>\n",
       " outputs:\n",
       " |-<gradio.components.plot.Plot object at 0x12f2fd090>\n",
       " |-<gradio.components.plot.Plot object at 0x12f2fd1d0>\n",
       " |-<gradio.components.plot.Plot object at 0x12f2fd310>\n",
       "fn_index=3\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f2fc2d0>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12f2fc410>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12f2fc550>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12f2fc690>\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f2fc910>\n",
       " |-<gradio.components.number.Number object at 0x12f2fda90>\n",
       " |-<gradio.components.slider.Slider object at 0x12f2fdbd0>\n",
       " |-<gradio.components.slider.Slider object at 0x12f2fdd10>\n",
       "fn_index=4\n",
       " inputs:\n",
       " |-<gradio.components.radio.Radio object at 0x12f2fd950>\n",
       " |-<gradio.components.number.Number object at 0x12f2fda90>\n",
       " |-<gradio.components.slider.Slider object at 0x12f2fdbd0>\n",
       " |-<gradio.components.slider.Slider object at 0x12f2fdd10>\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f2fc910>\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f2fc2d0>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12f2fc410>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12f2fc550>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12f2fc690>\n",
       " outputs:\n",
       " |-<gradio.components.plot.Plot object at 0x12f2fd6d0>\n",
       " |-<gradio.components.plot.Plot object at 0x12f2fe0d0>\n",
       " |-<gradio.components.html.HTML object at 0x12f2fe5d0>\n",
       " |-<gradio.components.dataframe.Dataframe object at 0x12f2fead0>\n",
       "fn_index=5\n",
       " inputs:\n",
       " |-<gradio.components.radio.Radio object at 0x12f2fd950>\n",
       " |-<gradio.components.number.Number object at 0x12f2fda90>\n",
       " |-<gradio.components.slider.Slider object at 0x12f2fdbd0>\n",
       " |-<gradio.components.slider.Slider object at 0x12f2fdd10>\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f2fc910>\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f2fc2d0>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12f2fc410>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12f2fc550>\n",
       " |-<gradio.components.dropdown.Dropdown object at 0x12f2fc690>\n",
       " outputs:\n",
       " |-<gradio.components.plot.Plot object at 0x12f2fd6d0>\n",
       " |-<gradio.components.plot.Plot object at 0x12f2fe0d0>\n",
       " |-<gradio.components.html.HTML object at 0x12f2fe5d0>\n",
       " |-<gradio.components.dataframe.Dataframe object at 0x12f2fead0>\n",
       "fn_index=6\n",
       " inputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f2ff610>\n",
       " outputs:\n",
       " |-<gradio.components.html.HTML object at 0x12f2ffb10>\n",
       " |-<gradio.components.plot.Plot object at 0x12f2ffc50>\n",
       " |-<gradio.components.dataframe.Dataframe object at 0x12f318050>\n",
       "fn_index=7\n",
       " inputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f432d50>\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f432d50>\n",
       " |-<gradio.components.state.State object at 0x12f432850>\n",
       "fn_index=8\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12f432850>\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       " outputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       "fn_index=9\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12f432850>\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12f432990>\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       "fn_index=10\n",
       " inputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " |-<gradio.components.state.State object at 0x12f433250>\n",
       "fn_index=11\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f432d50>\n",
       "fn_index=12\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12f432710>\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12f4325d0>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12f432710>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12f4325d0>\n",
       "fn_index=13\n",
       " inputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f432d50>\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " outputs:\n",
       " |-<gradio.components.json_component.JSON object at 0x12f432fd0>\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       "fn_index=14\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " |-<gradio.components.state.State object at 0x12f432850>\n",
       "fn_index=15\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12f432850>\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " outputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       "fn_index=16\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f432d50>\n",
       "fn_index=17\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12f432850>\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12f432990>\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       "fn_index=18\n",
       " inputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " |-<gradio.components.state.State object at 0x12f433250>\n",
       "fn_index=19\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f432d50>\n",
       "fn_index=20\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12f432710>\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12f4325d0>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12f432710>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12f4325d0>\n",
       "fn_index=21\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f432d50>\n",
       "fn_index=22\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f432d50>\n",
       "fn_index=23\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f432d50>\n",
       "fn_index=24\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f432d50>\n",
       "fn_index=25\n",
       " inputs:\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f432d50>\n",
       "fn_index=28\n",
       " inputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       " outputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       " |-<gradio.components.textbox.Textbox object at 0x12f432d50>\n",
       "fn_index=29\n",
       " inputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " |-<gradio.components.state.State object at 0x12f433250>\n",
       "fn_index=30\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12f432710>\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12f4325d0>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12f432710>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12f4325d0>\n",
       "fn_index=31\n",
       " inputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       " outputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       " |-<gradio.components.state.State object at 0x12f432850>\n",
       "fn_index=32\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12f432850>\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12f432990>\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       "fn_index=33\n",
       " inputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " |-<gradio.components.state.State object at 0x12f433250>\n",
       "fn_index=34\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12f432710>\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12f4325d0>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12f432710>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12f4325d0>\n",
       "fn_index=35\n",
       " inputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " |-<gradio.components.state.State object at 0x12f433250>\n",
       "fn_index=36\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12f432710>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12f4325d0>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12f432710>\n",
       " |-<gradio.components.browser_state.BrowserState object at 0x12f4325d0>\n",
       "fn_index=37\n",
       " inputs:\n",
       " |-<gradio.components.state.State object at 0x12f433250>\n",
       " outputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       "fn_index=38\n",
       " inputs:\n",
       " |-<gradio.components.chatbot.Chatbot object at 0x12f432ad0>\n",
       " outputs:\n",
       " |-<gradio.components.state.State object at 0x12f433110>\n",
       " |-<gradio.components.state.State object at 0x12f433250>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ NOUVELLE SESSION : Nettoyage et GÃ©nÃ©ration des Facts...\n",
      "ðŸ—‘ï¸ Facts Manager: All facts cleared.\n",
      "ðŸ”„ [MARKET GENERATION] Estimation du marchÃ© pour : Logiciels de Gestion (ERP/CRM) pour PME en France - 2025\n",
      "âœ… [MARKET GENERATION] 3 facts gÃ©nÃ©rÃ©s pour le scope\n",
      "ðŸšœ [HARVEST] DÃ©marrage de la moisson de donnÃ©es concurrentielles...\n",
      "ðŸ•µï¸â€â™‚ï¸ [COMPETITORS] Recherche des concurrents pour : Logiciels de Gestion (ERP/CRM) pour PME en France - 2025\n",
      "âœ… [COMPETITORS] TrouvÃ©s : ['SAP', 'CRM', 'SAGE.L', 'DATS.L', 'COD']\n",
      "   â¬‡ï¸ Ingestion financiÃ¨re : SAGE.L\n",
      "ðŸ”„ Ingesting financials for SAGE.L...\n",
      "ðŸ“¦ [FACTS] Cache hit pour SAGE.L\n",
      "âœ… Ingested financial facts for SAGE.L\n",
      "   â¬‡ï¸ Ingestion financiÃ¨re : DATS.L\n",
      "ðŸ”„ Ingesting financials for DATS.L...\n",
      "ðŸ“¦ [FACTS] Cache hit pour DATS.L\n",
      "âœ… Ingested financial facts for DATS.L\n",
      "   â¬‡ï¸ Ingestion financiÃ¨re : SAP\n",
      "ðŸ”„ Ingesting financials for SAP...\n",
      "ðŸ“¦ [FACTS] Cache hit pour SAP\n",
      "âœ… Ingested financial facts for SAP\n",
      "   â¬‡ï¸ Ingestion financiÃ¨re : COD\n",
      "ðŸ”„ Ingesting financials for COD...\n",
      "ðŸ“¦ [FACTS] Cache hit pour COD\n",
      "âœ… Ingested financial facts for COD\n",
      "   â¬‡ï¸ Ingestion financiÃ¨re : CRM\n",
      "ðŸ”„ Ingesting financials for CRM...\n",
      "ðŸ“¦ [FACTS] Cache hit pour CRM\n",
      "âœ… Ingested financial facts for CRM\n",
      "âœ… [HARVEST] 5 concurrents scannÃ©s et ingÃ©rÃ©s.\n",
      "âœ… Session initialisÃ©e avec succÃ¨s. Total Facts: 9\n",
      "ðŸš€ NOUVELLE SESSION : Nettoyage et GÃ©nÃ©ration des Facts...\n",
      "ðŸ—‘ï¸ Facts Manager: All facts cleared.\n",
      "ðŸ”„ [MARKET GENERATION] Estimation du marchÃ© pour : Logiciels de Gestion (ERP/CRM) pour PME en France - 2025\n",
      "âœ… [MARKET GENERATION] 3 facts gÃ©nÃ©rÃ©s pour le scope\n",
      "ðŸšœ [HARVEST] DÃ©marrage de la moisson de donnÃ©es concurrentielles...\n",
      "ðŸ•µï¸â€â™‚ï¸ [COMPETITORS] Recherche des concurrents pour : Logiciels de Gestion (ERP/CRM) pour PME en France - 2025\n",
      "âœ… [COMPETITORS] TrouvÃ©s : ['SAP', 'CRM', 'SAGE.L', 'DTE', 'CODI']\n",
      "   â¬‡ï¸ Ingestion financiÃ¨re : SAGE.L\n",
      "ðŸ”„ Ingesting financials for SAGE.L...\n",
      "ðŸ“¦ [FACTS] Cache hit pour SAGE.L\n",
      "âœ… Ingested financial facts for SAGE.L\n",
      "   â¬‡ï¸ Ingestion financiÃ¨re : CODI\n",
      "ðŸ”„ Ingesting financials for CODI...\n",
      "ðŸ“¦ [FACTS] Cache hit pour CODI\n",
      "âœ… Ingested financial facts for CODI\n",
      "   â¬‡ï¸ Ingestion financiÃ¨re : SAP\n",
      "ðŸ”„ Ingesting financials for SAP...\n",
      "ðŸ“¦ [FACTS] Cache hit pour SAP\n",
      "âœ… Ingested financial facts for SAP\n",
      "   â¬‡ï¸ Ingestion financiÃ¨re : DTE\n",
      "ðŸ”„ Ingesting financials for DTE...\n",
      "ðŸ“¦ [FACTS] Cache hit pour DTE\n",
      "âœ… Ingested financial facts for DTE\n",
      "   â¬‡ï¸ Ingestion financiÃ¨re : CRM\n",
      "ðŸ”„ Ingesting financials for CRM...\n",
      "ðŸ“¦ [FACTS] Cache hit pour CRM\n",
      "âœ… Ingested financial facts for CRM\n",
      "âœ… [HARVEST] 5 concurrents scannÃ©s et ingÃ©rÃ©s.\n",
      "âœ… Session initialisÃ©e avec succÃ¨s. Total Facts: 9\n",
      "\n",
      "ðŸš€ [DEBUG] STARTING MARKET ESTIMATION\n",
      "   - Inputs: Ind='Logiciels de Gestion (ERP/CRM) pour PME', Reg='France', Hor='2025', Cur='EUR'\n",
      "   - Generated Scope: 'Logiciels de Gestion (ERP/CRM) pour PME en France (Horizon 2025) - EUR'\n",
      "   - Calling LLM for Market Sizing Facts...\n",
      "ðŸ”„ [MARKET GENERATION] Estimation du marchÃ© pour : Logiciels de Gestion (ERP/CRM) pour PME en France (Horizon 2025) - EUR\n",
      "âœ… [MARKET GENERATION] 1 facts gÃ©nÃ©rÃ©s pour le scope\n",
      "   âœ… LLM returned 1 facts:\n",
      "      -> tam_global_market: 1200000000 (Statista 2024)\n",
      "   - Updated Manager Values: TAM=1200000000, SAM=30, SOM=3\n",
      "ðŸ•µï¸â€â™‚ï¸ [COMPETITORS] Recherche des concurrents pour : Logiciels de Gestion (ERP/CRM) pour PME en France (Horizon 2025) - EUR\n",
      "âœ… [COMPETITORS] TrouvÃ©s : ['SAP', 'CRM', 'SAGE.L', 'DATS.L', 'COD']\n",
      "\n",
      "ðŸ“Š [DEBUG] FINAL FACTS TABLE STATE:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/robincrifo/Documents/KPMG/kpmg/HACK-KPMG/kpmgvenv/lib/python3.13/site-packages/gradio/queueing.py\", line 766, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/robincrifo/Documents/KPMG/kpmg/HACK-KPMG/kpmgvenv/lib/python3.13/site-packages/gradio/route_utils.py\", line 355, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/robincrifo/Documents/KPMG/kpmg/HACK-KPMG/kpmgvenv/lib/python3.13/site-packages/gradio/blocks.py\", line 2152, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/robincrifo/Documents/KPMG/kpmg/HACK-KPMG/kpmgvenv/lib/python3.13/site-packages/gradio/blocks.py\", line 1629, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/robincrifo/Documents/KPMG/kpmg/HACK-KPMG/kpmgvenv/lib/python3.13/site-packages/anyio/to_thread.py\", line 63, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/robincrifo/Documents/KPMG/kpmg/HACK-KPMG/kpmgvenv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2502, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/robincrifo/Documents/KPMG/kpmg/HACK-KPMG/kpmgvenv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 986, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/robincrifo/Documents/KPMG/kpmg/HACK-KPMG/kpmgvenv/lib/python3.13/site-packages/gradio/utils.py\", line 1034, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/Users/robincrifo/Documents/KPMG/kpmg/HACK-KPMG/kpmg_interface.py\", line 384, in run_full_market_estimation\n",
      "    print(mgr.get_all_facts_as_dataframe().to_string())\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'FactsManager' object has no attribute 'get_all_facts_as_dataframe'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GRADIO INTERFACE - VERSION AVEC MISTRAL-SMALL (GRATUIT)\n",
    "========================================================\n",
    "\n",
    "Cette version utilise mistral-small au lieu de mistral-medium.\n",
    "Performance lÃ©gÃ¨rement infÃ©rieure mais GRATUIT et SUFFISANT pour votre dÃ©mo.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "import kpmg_interface\n",
    "import importlib\n",
    "import analytics_viz\n",
    "import facts_manager\n",
    "import market_estimation_engine\n",
    "import strategic_facts_service\n",
    "\n",
    "from langchain_mistralai import ChatMistralAI, MistralAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# INITIALISATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ðŸ”§ Initialisation de l'interface KPMG (mistral-small)...\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "INDEX_NAME = \"kpmg-veille\"\n",
    "\n",
    "if not MISTRAL_API_KEY or not PINECONE_API_KEY:\n",
    "    raise ValueError(\"âŒ ClÃ©s API manquantes dans .env\")\n",
    "\n",
    "print(\"âœ… Variables d'environnement chargÃ©es\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# COMPOSANTS RAG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "try:\n",
    "    # Embeddings\n",
    "    embeddings = MistralAIEmbeddings(\n",
    "        model=\"mistral-embed\",\n",
    "        mistral_api_key=MISTRAL_API_KEY\n",
    "    )\n",
    "    print(\"âœ… Embeddings initialisÃ©s\")\n",
    "    \n",
    "    # Vector Store\n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=embeddings,\n",
    "        namespace=\"news\"\n",
    "    )\n",
    "    \n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 3}\n",
    "    )\n",
    "    print(\"âœ… Retriever configurÃ©\")\n",
    "    \n",
    "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "    # â•‘ CHANGEMENT CRITIQUE : mistral-medium â†’ mistral-small    â•‘\n",
    "    # â•‘                                                           â•‘\n",
    "    # â•‘ Mistral-small est GRATUIT et suffisant pour du RAG      â•‘\n",
    "    # â•‘ Performance : 85% de mistral-medium Ã  coÃ»t zÃ©ro         â•‘\n",
    "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    \n",
    "    llm = ChatMistralAI(\n",
    "        model=\"mistral-small\",  # âœ… MODÃˆLE GRATUIT\n",
    "        temperature=0,\n",
    "        mistral_api_key=MISTRAL_API_KEY\n",
    "    )\n",
    "    print(\"âœ… LLM Mistral Small initialisÃ©\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur lors de l'initialisation : {e}\")\n",
    "    raise\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PROMPT KPMG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "KPMG_PROMPT_TEMPLATE = \"\"\"Vous Ãªtes l'Assistant Intelligent de Veille StratÃ©gique de KPMG Global Strategy Group.\n",
    "\n",
    "Votre mission : Fournir des analyses de marchÃ© prÃ©cises, sourcÃ©es et actionnables pour aider nos clients Ã  prendre des dÃ©cisions d'investissement Ã©clairÃ©es.\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "RÃˆGLES DE CITATION (OBLIGATOIRES)\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "Pour CHAQUE information factuelle (chiffres, dates, faits) vous DEVEZ :\n",
    "1. Citer la source exacte (ex: \"https://www.apple.com - 2024-01-15\")\n",
    "2. Indiquer le niveau de fiabilitÃ© :\n",
    "   - *** : Source primaire (SEC, rapport officiel, yfinance)\n",
    "   - ** : Source secondaire fiable (NewsAPI, presse reconnue)\n",
    "   - * : Source tertiaire (blogs, rÃ©seaux sociaux)\n",
    "3. PrÃ©ciser la date de l'information si critique\n",
    "\n",
    "Format de citation : [Source au format URL | FiabilitÃ© | Date]\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "CONTEXTE DISPONIBLE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "{context}\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "QUESTION DU CLIENT\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "{question}\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "INSTRUCTIONS DE RÃ‰PONSE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "1. STRUCTURE :\n",
    "   - RÃ©pondez en prose fluide (paragraphes, pas de bullet points)\n",
    "   - Organisez votre rÃ©ponse de faÃ§on logique et narrative\n",
    "   - Utilisez des transitions naturelles entre les idÃ©es\n",
    "\n",
    "2. CONTENU :\n",
    "   - Citez systÃ©matiquement vos sources (format ci-dessus)\n",
    "   - Si une donnÃ©e est manquante : indiquez-le explicitement\n",
    "   - Si une information nÃ©cessite un accÃ¨s payant : prÃ©cisez-le\n",
    "   - Si le contexte est ambigu : demandez des prÃ©cisions au client\n",
    "\n",
    "3. TONE :\n",
    "   - Professionnel mais accessible\n",
    "   - Factuel et analytique\n",
    "   - Confiant sur les donnÃ©es sourcÃ©es, prudent sur les spÃ©culations\n",
    "\n",
    "4. CAS LIMITES :\n",
    "   - Si vous ne trouvez pas l'information : \"Les donnÃ©es disponibles ne permettent pas de rÃ©pondre Ã  cette question. Sources consultÃ©es : [liste]. Je recommande [action].\"\n",
    "   - Si deux sources se contredisent : Mentionnez les deux et expliquez pourquoi\n",
    "   - Si une entreprise est ambiguÃ« : \"J'ai identifiÃ© plusieurs entreprises nommÃ©es [X]. Pouvez-vous prÃ©ciser : secteur, gÃ©ographie, ou autre contexte ?\"\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "RÃ‰PONSE ANALYTIQUE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(KPMG_PROMPT_TEMPLATE )\n",
    "print(\"âœ… Prompt configurÃ©\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CHAÃŽNE RAG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"Formate les documents rÃ©cupÃ©rÃ©s\"\"\"\n",
    "    if not docs:\n",
    "        return \"Aucun document pertinent trouvÃ©.\"\n",
    "    \n",
    "    formatted = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        date = doc.metadata.get('published_at', doc.metadata.get('scrape_date', 'N/A'))\n",
    "        content = doc.page_content[:500]\n",
    "        \n",
    "        formatted.append(f\"[Document {i} - Source: {source} - Date: {date}]\\n{content}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"âœ… ChaÃ®ne RAG construite\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FONCTION STREAMING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def stream_kpmg_response(message, history):\n",
    "    \"\"\"GÃ©nÃ¨re la rÃ©ponse de maniÃ¨re progressive\"\"\"\n",
    "    try:\n",
    "        partial_message = \"\"\n",
    "        \n",
    "        for chunk in rag_chain.stream(message):\n",
    "            partial_message += chunk\n",
    "            yield partial_message\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = f\"\"\"âŒ Erreur lors de la recherche :\n",
    "        \n",
    "DÃ©tails : {str(e)}\n",
    "\n",
    "Suggestions :\n",
    "1. VÃ©rifiez que l'index Pinecone contient des donnÃ©es (âœ… Vous avez 118 vecteurs)\n",
    "2. Testez avec une question plus simple\n",
    "3. VÃ©rifiez les crÃ©dits Mistral sur console.mistral.ai\"\"\"\n",
    "        \n",
    "        yield error_msg\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# INTERFACE GRADIO â€“ STYLE TERMINAL RÃ‰TRO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\" theme = gr.themes.Base().set(\n",
    "    body_background_fill=\"#0f0f0f\",\n",
    "    body_text_color=\"#c6f6d5\",\n",
    "    button_primary_background_fill=\"#0f0f0f\",\n",
    "    button_primary_text_color=\"#c6f6d5\",\n",
    "    input_background_fill=\"#0f0f0f\",\n",
    "    input_border_color=\"#c6f6d5\"\n",
    ")\n",
    "\n",
    "\n",
    "custom_css = \n",
    "@import url('https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@400;600&display=swap');\n",
    "\n",
    "* {\n",
    "    font-family: 'Source Code Pro', monospace;\n",
    "    box-shadow: none !important;\n",
    "    border-radius: 0 !important;\n",
    "}\n",
    "\n",
    "body {\n",
    "    background-color: #0f0f0f;\n",
    "}\n",
    "\n",
    "h1 {\n",
    "    color: #c6f6d5;\n",
    "    text-align: left;\n",
    "    font-weight: 600;\n",
    "    margin-bottom: 8px;\n",
    "}\n",
    "\n",
    ".gr-chatbot {\n",
    "    background: transparent !important;\n",
    "    border: none !important;\n",
    "    padding: 0 !important;\n",
    "}\n",
    "\n",
    ".gr-chatbot .message {\n",
    "    padding: 2px 0 !important;\n",
    "    line-height: 1.6;\n",
    "}\n",
    "\n",
    ".gr-chatbot .message.user {\n",
    "    color: #9ae6b4;\n",
    "}\n",
    "\n",
    ".gr-chatbot .message.bot {\n",
    "    color: #e6fffa;\n",
    "}\n",
    "\n",
    "textarea, input {\n",
    "    background: transparent !important;\n",
    "    color: #c6f6d5 !important;\n",
    "    border: none !important;\n",
    "    border-bottom: 1px solid #c6f6d5 !important;\n",
    "}\n",
    "\n",
    "button {\n",
    "    background: transparent !important;\n",
    "    color: #c6f6d5 !important;\n",
    "    border: none !important;\n",
    "    padding: 4px 8px !important;\n",
    "}\n",
    "\n",
    "button:hover {\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=stream_kpmg_response,\n",
    "    title=\"KPMG Analytics\",\n",
    "    description=\"Assistant de Veille StratÃ©gique alimentÃ© par Mistral-Small.\",\n",
    "    examples=[\n",
    "        \"Quelles sont les derniÃ¨res actualitÃ©s sur Apple ?\",\n",
    "        \"Capitalisation boursiÃ¨re de Microsoft ?\",\n",
    "        \"Risques pour le secteur Tech ?\"\n",
    "    ]\n",
    ")\n",
    "    \n",
    "    # OPTION 2 : Avec partage public (dÃ©commentez pour le jury)\n",
    "    # demo.launch(\n",
    "    #     share=True,\n",
    "    #     inline=False,\n",
    "    #     show_error=True,\n",
    "    #     quiet=False\n",
    "    # )\n",
    "    \n",
    "demo.launch(share=True) \"\"\"\n",
    "importlib.reload(facts_manager)\n",
    "importlib.reload(market_estimation_engine)\n",
    "importlib.reload(analytics_viz)\n",
    "importlib.reload(kpmg_interface)\n",
    "importlib.reload(strategic_facts_service) \n",
    "print(\"âœ… Modules rechargÃ©s Ã  chaud !\")\n",
    "# Lance le dashboard\n",
    "kpmg_interface.launch_dashboard(stream_kpmg_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ \n",
      "   DIAGNOSTIC COMPLET DU SYSTÃˆME RAG KPMG\n",
      "ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ \n",
      "\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Variables d'environnement\n",
      "============================================================\n",
      "   MISTRAL_API_KEY: HMMmZlVbL9...\n",
      "   PINECONE_API_KEY: pcsk_576Qs...\n",
      "âœ… Variables d'environnement : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Ã‰tat de Pinecone\n",
      "============================================================\n",
      "   Index : kpmg-veille\n",
      "   Total vecteurs : 111\n",
      "   Dimension : 1024\n",
      "\n",
      "   ðŸ“ Namespaces :\n",
      "      - news: 109 vecteurs\n",
      "      - macro_data: 2 vecteurs\n",
      "âœ… Ã‰tat de Pinecone : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Mistral Embeddings\n",
      "============================================================\n",
      "   Texte : 'Apple annonce de nouveaux produits'\n",
      "   Dimension : 1024\n",
      "   Type : <class 'list'>\n",
      "   Premiers 5 valeurs : [-0.01617431640625, 0.01390838623046875, 0.052734375, -0.0182037353515625, 0.046600341796875]\n",
      "âœ… Mistral Embeddings : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Mistral LLM\n",
      "============================================================\n",
      "DEBUG: Returning 4 components. DF Shape: (5, 7)\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š CONTENU ACTUEL DU FACTS MANAGER (Toutes les donnÃ©es rÃ©cupÃ©rÃ©es)\n",
      "============================================================\n",
      "ðŸ”¹ [market_estimation] tam_global_market: 0 EUR | Gartner 2023 (N/A/N/A)\n",
      "ðŸ”¹ [market_estimation] sam_percent: 20 % | HypothÃ¨se Interne (N/A/N/A)\n",
      "ðŸ”¹ [market_estimation] som_share: 5 % | Plan StratÃ©gique 2025 (N/A/N/A)\n",
      "ðŸ”¹ [market_estimation] total_potential_customers: 15000 companies | INSEE (N/A/N/A)\n",
      "ðŸ”¹ [market_estimation] average_price: None EUR/year | TBD (N/A/N/A)\n",
      "ðŸ”¹ [competition] competitor_list: ['Competitor A', 'Competitor B', 'Competitor C'] list | Manual (N/A/N/A)\n",
      "ðŸ”¹ [competition] competitor_a_revenue: 50000000 EUR | Annual Report 2022 (N/A/N/A)\n",
      "ðŸ”¹ [context] market_scope: telephone text | User Input (N/A/N/A)\n",
      "ðŸ”¹ [financials] last_revenue: 416161000000.0 USD | Yahoo Finance (2026-01-25) (N/A/N/A)\n",
      "ðŸ”¹ [financials] last_net_income: 112010000000.0 USD | Yahoo Finance (2026-01-25) (N/A/N/A)\n",
      "ðŸ”¹ [financials] employees: 166000 people | Yahoo Finance (2026-01-25) (N/A/N/A)\n",
      "ðŸ”¹ [financials] market_cap: 3665126490112 USD | Yahoo Finance (2026-01-25) (N/A/N/A)\n",
      "ðŸ”¹ [financials] net_margin_percent: 26.91506412181824 % | Yahoo Finance (2026-01-25) (N/A/N/A)\n",
      "ðŸ”¹ [strategic_analysis] swot_data: {'strengths': [{'item': 'Marge nette Ã©levÃ©e (26.9%)', 'evidence': 'ðŸ“Š DonnÃ©e financiÃ¨re rÃ©elle', 'source': 'financial'}, {'item': 'ROE excellent (151.9%)', 'evidence': 'ðŸ“Š DonnÃ©e financiÃ¨re rÃ©elle', 'source': 'financial'}, {'item': 'Marque mondiale forte', 'evidence': 'Reconnaissance et fidÃ©litÃ©', 'source': 'Interbrand Best Global Brands 2023', 'source_type': 'analyse_marche'}, {'item': 'Ã‰cosystÃ¨me intÃ©grÃ©', 'evidence': 'Synergie produits/services', 'source': 'Apple Annual Report 2023', 'source_type': 'rapport_financier'}, {'item': 'Innovation continue', 'evidence': 'Lancement produits rÃ©guliers', 'source': 'Bloomberg Tech Review 2023', 'source_type': 'presse'}], 'weaknesses': [{'item': 'Prix Ã©levÃ©s', 'evidence': \"BarriÃ¨re d'entrÃ©e Ã©levÃ©e\", 'source': 'Forrester Consumer Tech 2023', 'source_type': 'analyse_marche'}, {'item': 'DÃ©pendance iPhone', 'evidence': 'Revenus concentrÃ©s', 'source': 'WSJ Tech Analysis 2023', 'source_type': 'presse'}, {'item': 'FragilitÃ© logistique', 'evidence': 'PÃ©nuries de composants', 'source': 'Reuters Supply Chain 2023', 'source_type': 'presse'}], 'opportunities': [{'item': 'TrÃ©sorerie disponible (FCF: $98.8B)', 'evidence': \"ðŸ“Š DonnÃ©e financiÃ¨re rÃ©elle - CapacitÃ© d'investissement\", 'source': 'financial'}, {'item': 'Croissance services', 'evidence': 'Abonnements en hausse', 'source': 'Gartner Tech Forecast 2024', 'source_type': 'analyse_marche'}, {'item': 'MarchÃ©s Ã©mergents', 'evidence': 'Demande en Asie', 'source': 'McKinsey Emerging Markets 2023', 'source_type': 'analyse_marche'}, {'item': 'IA et rÃ©alitÃ© virtuelle', 'evidence': 'Investissements R&D', 'source': 'Apple Developer Conference 2023', 'source_type': 'rapport_financier'}], 'threats': [{'item': 'Concurrence Android', 'evidence': 'Part de marchÃ© menacÃ©e', 'source': 'IDC Smartphone Report 2023', 'source_type': 'analyse_marche'}, {'item': 'RÃ©gulations strictes', 'evidence': 'LÃ©gislations anti-trust', 'source': 'EU Commission Tech Report 2023', 'source_type': 'regulateur'}, {'item': 'Risques gÃ©opolitiques', 'evidence': 'Tensions Chine/USA', 'source': 'Financial Times Tech 2023', 'source_type': 'presse'}]} json | Mistral AI Analysis (N/A/N/A)\n",
      "ðŸ”¹ [strategic_analysis] bcg_data: [{'name': 'iPhone', 'market_share': 0.75, 'growth': 0.5, 'revenue_weight': 50, 'source': 'IDC Smartphone Market 2023'}, {'name': 'Services (Apple Music, iCloud)', 'market_share': 0.6, 'growth': 0.8, 'revenue_weight': 25, 'source': 'Gartner Digital Services 2023'}, {'name': 'Mac & iPad', 'market_share': 0.4, 'growth': 0.3, 'revenue_weight': 15, 'source': 'Counterpoint Research 2023'}, {'name': 'Wearables (Apple Watch, AirPods)', 'market_share': 0.3, 'growth': 0.7, 'revenue_weight': 10, 'source': 'Statista Wearables 2023'}] json | Mistral AI Analysis (N/A/N/A)\n",
      "ðŸ”¹ [strategic_analysis] pestel_data: {'Politique': {'score': 7, 'details': 'StabilitÃ© rÃ©glementaire aux USA', 'source': 'Reuters Tech Policy 2024'}, 'Economique': {'score': 5, 'details': \"Inflation et taux d'intÃ©rÃªt\", 'source': 'Bloomberg Economic Outlook 2024'}, 'Societal': {'score': 4, 'details': \"PrÃ©fÃ©rence pour l'Ã©cologie\", 'source': 'McKinsey Consumer Trends 2024'}, 'Technologique': {'score': 8, 'details': 'AvancÃ©es en IA et 5G', 'source': 'Gartner Tech Trends 2024'}, 'Environnemental': {'score': 6, 'details': 'Pressions pour la durabilitÃ©', 'source': 'CDP Corporate Sustainability 2024'}, 'Legal': {'score': 5, 'details': 'Lutte contre les monopoles', 'source': 'EU Commission Antitrust 2024'}} json | Mistral AI Analysis (N/A/N/A)\n",
      "============================================================\n",
      "\n",
      "   ModÃ¨le : mistral-medium\n",
      "   Question : Capitale de la France ?\n",
      "   RÃ©ponse : Paris.\n",
      "âœ… Mistral LLM : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Retriever\n",
      "============================================================\n",
      "   Query : 'Apple derniÃ¨res actualitÃ©s'\n",
      "   Namespace : news\n",
      "   RÃ©sultats : 3 documents\n",
      "\n",
      "   ðŸ“„ Premier rÃ©sultat :\n",
      "      Source : press_release\n",
      "      Contenu : Newsroom - Apple\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "AppleStoreMaciPadiPhoneWatch\n",
      "VisionAirPodsTV & HomeEntertainmentAccessoriesSupport\n",
      "\n",
      "\n",
      "0+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsroom\n",
      "\n",
      "...\n",
      "âœ… Retriever : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : ChaÃ®ne RAG complÃ¨te\n",
      "============================================================\n",
      "   Question : 'Quelles sont les derniÃ¨res actualitÃ©s ?'\n",
      "   Traitement...\n",
      "\n",
      "   âœ… RÃ©ponse gÃ©nÃ©rÃ©e (2084 caractÃ¨res) :\n",
      "   Voici quelques-unes des **derniÃ¨res actualitÃ©s** d'Apple (juin 2024) disponibles sur leur **Newsroom** (Ã  vÃ©rifier sur [apple.com/newsroom](https://www.apple.com/newsroom/) pour les mises Ã  jour en temps rÃ©el) :\n",
      "\n",
      "### **Principales annonces rÃ©centes** :\n",
      "1. **WWDC 2024** (10â€“14 juin) :\n",
      "   - **iOS 18**...\n",
      "âœ… ChaÃ®ne RAG complÃ¨te : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Gradio\n",
      "============================================================\n",
      "   Version : 6.3.0\n",
      "âœ… Gradio : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š RAPPORT FINAL\n",
      "============================================================\n",
      "\n",
      "Tests rÃ©ussis : 7/7\n",
      "\n",
      "ðŸŽ‰ TOUS LES TESTS SONT PASSÃ‰S !\n",
      "âœ… Votre systÃ¨me est prÃªt pour Gradio\n",
      "\n",
      "ðŸ’¡ Prochaine Ã©tape :\n",
      "   ExÃ©cutez la cellule 'gradio_interface_fixed.py'\n",
      "\n",
      "============================================================\n",
      "âœ… Diagnostic terminÃ©\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SCRIPT DE TEST COMPLET - SYSTÃˆME RAG KPMG\n",
    "==========================================\n",
    "\n",
    "ExÃ©cutez ce script pour diagnostiquer tous les problÃ¨mes potentiels.\n",
    "Copier-coller dans une nouvelle cellule de notebook.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FONCTION DE TEST AVEC GESTION D'ERREURS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def run_test(test_name, test_func):\n",
    "    \"\"\"ExÃ©cute un test et affiche le rÃ©sultat\"\"\"\n",
    "    try:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ðŸ§ª TEST : {test_name}\")\n",
    "        print('='*60)\n",
    "        result = test_func()\n",
    "        print(f\"âœ… {test_name} : RÃ‰USSI\")\n",
    "        return True, result\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {test_name} : Ã‰CHOUÃ‰\")\n",
    "        print(f\"   Erreur : {str(e)}\")\n",
    "        return False, None\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 1 : ENVIRONNEMENT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_environment():\n",
    "    \"\"\"VÃ©rifie les variables d'environnement\"\"\"\n",
    "    load_dotenv()\n",
    "    \n",
    "    required_vars = {\n",
    "        \"MISTRAL_API_KEY\": os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        \"PINECONE_API_KEY\": os.getenv(\"PINECONE_API_KEY\")\n",
    "    }\n",
    "    \n",
    "    missing = [k for k, v in required_vars.items() if not v]\n",
    "    \n",
    "    if missing:\n",
    "        raise ValueError(f\"Variables manquantes : {', '.join(missing)}\")\n",
    "    \n",
    "    for key, value in required_vars.items():\n",
    "        masked = value[:10] + \"...\" if value else \"None\"\n",
    "        print(f\"   {key}: {masked}\")\n",
    "    \n",
    "    return required_vars\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 2 : PINECONE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_pinecone():\n",
    "    \"\"\"VÃ©rifie l'Ã©tat de l'index Pinecone\"\"\"\n",
    "    from pinecone import Pinecone\n",
    "    \n",
    "    pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "    index = pc.Index(\"kpmg-veille\")\n",
    "    stats = index.describe_index_stats()\n",
    "    \n",
    "    print(f\"   Index : kpmg-veille\")\n",
    "    print(f\"   Total vecteurs : {stats.total_vector_count}\")\n",
    "    print(f\"   Dimension : 1024\")\n",
    "    \n",
    "    if stats.total_vector_count == 0:\n",
    "        print(\"   âš ï¸  ATTENTION : Aucune donnÃ©e indexÃ©e !\")\n",
    "        print(\"   â†’ ExÃ©cutez les Notebooks 2, 3 et 4\")\n",
    "        raise ValueError(\"Index vide\")\n",
    "    \n",
    "    print(f\"\\n   ðŸ“ Namespaces :\")\n",
    "    for ns, info in stats.namespaces.items():\n",
    "        print(f\"      - {ns}: {info.vector_count} vecteurs\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 3 : MISTRAL EMBEDDINGS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_embeddings():\n",
    "    \"\"\"Teste la gÃ©nÃ©ration d'embeddings\"\"\"\n",
    "    from langchain_mistralai import MistralAIEmbeddings\n",
    "    \n",
    "    embeddings = MistralAIEmbeddings(\n",
    "        model=\"mistral-embed\",\n",
    "        mistral_api_key=os.getenv(\"MISTRAL_API_KEY\")\n",
    "    )\n",
    "    \n",
    "    # Test sur une phrase simple\n",
    "    test_text = \"Apple annonce de nouveaux produits\"\n",
    "    embedding = embeddings.embed_query(test_text)\n",
    "    \n",
    "    print(f\"   Texte : '{test_text}'\")\n",
    "    print(f\"   Dimension : {len(embedding)}\")\n",
    "    print(f\"   Type : {type(embedding)}\")\n",
    "    print(f\"   Premiers 5 valeurs : {embedding[:5]}\")\n",
    "    \n",
    "    if len(embedding) != 1024:\n",
    "        raise ValueError(f\"Dimension incorrecte : {len(embedding)} (attendu : 1024)\")\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 4 : MISTRAL LLM\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_llm():\n",
    "    \"\"\"Teste le modÃ¨le LLM\"\"\"\n",
    "    from langchain_mistralai import ChatMistralAI\n",
    "    \n",
    "    llm = ChatMistralAI(\n",
    "        model=\"mistral-small\",\n",
    "        temperature=0,\n",
    "        mistral_api_key=os.getenv(\"MISTRAL_API_KEY\")\n",
    "    )\n",
    "    \n",
    "    # Test simple\n",
    "    response = llm.invoke(\"RÃ©ponds en un mot : quelle est la capitale de la France ?\")\n",
    "    \n",
    "    print(f\"   ModÃ¨le : mistral-medium\")\n",
    "    print(f\"   Question : Capitale de la France ?\")\n",
    "    print(f\"   RÃ©ponse : {response.content}\")\n",
    "    \n",
    "    if \"Paris\" not in response.content:\n",
    "        print(\"   âš ï¸  RÃ©ponse inattendue, mais API fonctionne\")\n",
    "    \n",
    "    return llm\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 5 : RETRIEVER\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_retriever():\n",
    "    \"\"\"Teste la recherche vectorielle\"\"\"\n",
    "    from langchain_pinecone import PineconeVectorStore\n",
    "    from langchain_mistralai import MistralAIEmbeddings\n",
    "    \n",
    "    embeddings = MistralAIEmbeddings(model=\"mistral-embed\")\n",
    "    \n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=\"kpmg-veille\",\n",
    "        embedding=embeddings,\n",
    "        namespace=\"news\"  # Utilise le namespace qui a des donnÃ©es\n",
    "    )\n",
    "    \n",
    "    # Test de recherche\n",
    "    query = \"Apple derniÃ¨res actualitÃ©s\"\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    \n",
    "    print(f\"   Query : '{query}'\")\n",
    "    print(f\"   Namespace : news\")\n",
    "    print(f\"   RÃ©sultats : {len(results)} documents\")\n",
    "    \n",
    "    if not results:\n",
    "        raise ValueError(\"Aucun rÃ©sultat trouvÃ© - vÃ©rifiez l'indexation\")\n",
    "    \n",
    "    print(f\"\\n   ðŸ“„ Premier rÃ©sultat :\")\n",
    "    print(f\"      Source : {results[0].metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"      Contenu : {results[0].page_content[:150]}...\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 6 : CHAÃŽNE RAG COMPLÃˆTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_rag_chain():\n",
    "    \"\"\"Teste la chaÃ®ne RAG complÃ¨te\"\"\"\n",
    "    from langchain_mistralai import ChatMistralAI, MistralAIEmbeddings\n",
    "    from langchain_pinecone import PineconeVectorStore\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    from langchain_core.runnables import RunnablePassthrough\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    \n",
    "    # Composants\n",
    "    embeddings = MistralAIEmbeddings(model=\"mistral-embed\")\n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=\"kpmg-veille\",\n",
    "        embedding=embeddings,\n",
    "        namespace=\"news\"\n",
    "    )\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "    llm = ChatMistralAI(model=\"mistral-medium\", temperature=0)\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Contexte : {context}\\n\\nQuestion : {question}\\n\\nRÃ©ponse courte :\"\n",
    "    )\n",
    "    \n",
    "    # ChaÃ®ne\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join([d.page_content[:200] for d in docs])\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    # Test\n",
    "    question = \"Quelles sont les derniÃ¨res actualitÃ©s ?\"\n",
    "    print(f\"   Question : '{question}'\")\n",
    "    print(f\"   Traitement...\")\n",
    "    \n",
    "    response = rag_chain.invoke(question)\n",
    "    \n",
    "    print(f\"\\n   âœ… RÃ©ponse gÃ©nÃ©rÃ©e ({len(response)} caractÃ¨res) :\")\n",
    "    print(f\"   {response[:300]}...\")\n",
    "    \n",
    "    return rag_chain\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 7 : GRADIO (OPTIONNEL)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_gradio():\n",
    "    \"\"\"VÃ©rifie que Gradio est installÃ©\"\"\"\n",
    "    import gradio as gr\n",
    "    \n",
    "    version = gr.__version__\n",
    "    print(f\"   Version : {version}\")\n",
    "    \n",
    "    if version < \"4.0.0\":\n",
    "        print(\"   âš ï¸  Version ancienne dÃ©tectÃ©e\")\n",
    "        print(\"   â†’ RecommandÃ© : pip install --upgrade gradio\")\n",
    "    \n",
    "    return gr\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXÃ‰CUTION DES TESTS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def main():\n",
    "    \"\"\"ExÃ©cute tous les tests dans l'ordre\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"ðŸŽ¯ \"*20)\n",
    "    print(\"   DIAGNOSTIC COMPLET DU SYSTÃˆME RAG KPMG\")\n",
    "    print(\"ðŸŽ¯ \"*20 + \"\\n\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Liste des tests Ã  exÃ©cuter\n",
    "    tests = [\n",
    "        (\"Variables d'environnement\", test_environment),\n",
    "        (\"Ã‰tat de Pinecone\", test_pinecone),\n",
    "        (\"Mistral Embeddings\", test_embeddings),\n",
    "        (\"Mistral LLM\", test_llm),\n",
    "        (\"Retriever\", test_retriever),\n",
    "        (\"ChaÃ®ne RAG complÃ¨te\", test_rag_chain),\n",
    "        (\"Gradio\", test_gradio)\n",
    "    ]\n",
    "    \n",
    "    # ExÃ©cution\n",
    "    for test_name, test_func in tests:\n",
    "        success, result = run_test(test_name, test_func)\n",
    "        results[test_name] = {\"success\": success, \"result\": result}\n",
    "    \n",
    "    # Rapport final\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“Š RAPPORT FINAL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    passed = sum(1 for r in results.values() if r[\"success\"])\n",
    "    total = len(results)\n",
    "    \n",
    "    print(f\"\\nTests rÃ©ussis : {passed}/{total}\")\n",
    "    \n",
    "    if passed == total:\n",
    "        print(\"\\nðŸŽ‰ TOUS LES TESTS SONT PASSÃ‰S !\")\n",
    "        print(\"âœ… Votre systÃ¨me est prÃªt pour Gradio\")\n",
    "        print(\"\\nðŸ’¡ Prochaine Ã©tape :\")\n",
    "        print(\"   ExÃ©cutez la cellule 'gradio_interface_fixed.py'\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  CERTAINS TESTS ONT Ã‰CHOUÃ‰\")\n",
    "        print(\"\\nðŸ“‹ Actions recommandÃ©es :\")\n",
    "        \n",
    "        for test_name, result in results.items():\n",
    "            if not result[\"success\"]:\n",
    "                print(f\"\\nâŒ {test_name} :\")\n",
    "                \n",
    "                if \"environnement\" in test_name.lower():\n",
    "                    print(\"   â†’ VÃ©rifiez votre fichier .env\")\n",
    "                    print(\"   â†’ load_dotenv() doit Ãªtre appelÃ©\")\n",
    "                \n",
    "                elif \"pinecone\" in test_name.lower():\n",
    "                    print(\"   â†’ ExÃ©cutez les Notebooks 2, 3, 4 pour indexer des donnÃ©es\")\n",
    "                    print(\"   â†’ VÃ©rifiez que l'index 'kpmg-veille' existe\")\n",
    "                \n",
    "                elif \"embeddings\" in test_name.lower():\n",
    "                    print(\"   â†’ VÃ©rifiez votre MISTRAL_API_KEY\")\n",
    "                    print(\"   â†’ Testez manuellement : https://console.mistral.ai/\")\n",
    "                \n",
    "                elif \"llm\" in test_name.lower():\n",
    "                    print(\"   â†’ VÃ©rifiez les crÃ©dits de votre compte Mistral\")\n",
    "                    print(\"   â†’ Essayez 'mistral-small' si 'medium' ne fonctionne pas\")\n",
    "                \n",
    "                elif \"retriever\" in test_name.lower():\n",
    "                    print(\"   â†’ L'index est vide ou le namespace 'news' n'existe pas\")\n",
    "                    print(\"   â†’ RÃ©exÃ©cutez le Notebook 4 (indexation)\")\n",
    "                \n",
    "                elif \"rag\" in test_name.lower():\n",
    "                    print(\"   â†’ Un composant prÃ©cÃ©dent a Ã©chouÃ©\")\n",
    "                    print(\"   â†’ Corrigez les erreurs ci-dessus d'abord\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… Diagnostic terminÃ©\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# LANCEMENT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kpmgvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
