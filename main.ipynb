{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    PIPELINE DE VEILLE KPMG                  â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                             â”‚\n",
    "â”‚  [Sources] â†’ [Loaders] â†’ [Chunking] â†’ [Embeddings]          â”‚\n",
    "â”‚                              â†“                              â”‚\n",
    "â”‚                     [Pinecone Namespaces]                   â”‚\n",
    "â”‚                              â†“                              â”‚\n",
    "â”‚              [Retriever] â†’ [LLM] â†’ [RÃ©ponse]                â”‚\n",
    "â”‚                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEF d'un namespace = un dossier dans une base\n",
    "\n",
    "index: veille-strategique\n",
    "\n",
    "â”œâ”€â”€ namespace: financial_reports\n",
    "â”‚   â”œâ”€â”€ vecteur_001 (10-K Apple)\n",
    "â”‚   â”œâ”€â”€ vecteur_002 (10-Q Microsoft)\n",
    "â”‚\n",
    "â”œâ”€â”€ namespace: news\n",
    "â”‚   â”œâ”€â”€ vecteur_101 (Google News - OpenAI)\n",
    "â”‚   â”œâ”€â”€ vecteur_102 (Reuters - Tesla)\n",
    "â”‚\n",
    "â”œâ”€â”€ namespace: startups\n",
    "â”‚   â”œâ”€â”€ vecteur_201 (Crunchbase - levÃ©e SÃ©rie A)\n",
    "â”‚\n",
    "â”œâ”€â”€ namespace: macro_data\n",
    "â”‚   â”œâ”€â”€ vecteur_301 (World Bank - inflation UE)\n",
    "â”‚\n",
    "â””â”€â”€ namespace: social_signals\n",
    "    â”œâ”€â”€ vecteur_401 (Reddit sentiment marchÃ©)\n",
    "\n",
    "BUT : Retrieval ciblÃ©, Ã‰viter le bruit, Prompting plus intelligent (Â« RÃ©ponds uniquement Ã  partir des donnÃ©es issues du namespace financial_reports et cite les sources Â»)Ã‡a rÃ©duit les hallucinations, ScalabilitÃ© propre :\n",
    "\n",
    "-Tu peux ajouter de nouvelles sources sans casser lâ€™existant\n",
    "\n",
    "-Tu peux purger un namespace sans toucher aux autres\n",
    "\n",
    "-Tu peux tester des sources expÃ©rimentales (social_signals) sans polluer le corpus principal\n",
    "\n",
    ",  \n",
    "\n",
    "1 index = 1 projet RAG\n",
    "N namespaces = N types de sources\n",
    "\n",
    "Je pourrais meme aller plus loin ; \n",
    "news/google\n",
    "news/press_release\n",
    "social/reddit\n",
    "social/twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—‘ï¸ Suppression du namespace 'news'...\n",
      "âœ… Index nettoyÃ©\n"
     ]
    }
   ],
   "source": [
    "# Clean l'index ( ATTENTION A NE PAS EXECUTER A CHAQUZ FOIS !!)\n",
    "\n",
    "'''\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "INDEX_NAME = \"kpmg-veille\"\n",
    "\n",
    "# Supprimer TOUS les vecteurs de TOUS les namespaces\n",
    "index = pc.Index(INDEX_NAME)\n",
    "stats = index.describe_index_stats()\n",
    "\n",
    "for namespace in stats.namespaces.keys():\n",
    "    print(f\"ðŸ—‘ï¸ Suppression du namespace '{namespace}'...\")\n",
    "    index.delete(delete_all=True, namespace=namespace)\n",
    "\n",
    "print(\"âœ… Index nettoyÃ©\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Variables d'environnement chargÃ©es\n",
      "Client Pinecone initialisÃ©\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š CONFIGURATION DE L'INDEX\n",
      "============================================================\n",
      "Nom : kpmg-veille\n",
      "Dimension : 1024 (Mistral-embed)\n",
      "MÃ©trique : cosine\n",
      "Vecteurs totaux : 0\n",
      "\n",
      "ðŸ“ Namespaces dÃ©finis :\n",
      "   - financial_reports\n",
      "   - news\n",
      "   - startups\n",
      "   - macro_data\n",
      "   - social_signals\n",
      "============================================================\n",
      "\n",
      "âœ… Index prÃªt pour l'ingestion de donnÃ©es\n",
      "\n",
      "âœ… CHECKLIST COMPLÃ‰TÃ‰E :\n",
      "   â˜‘ Index existant supprimÃ©\n",
      "   â˜‘ Nouvel index crÃ©Ã© avec dimension 1024\n",
      "   â˜‘ MÃ©trique cosine configurÃ©e\n",
      "   â˜‘ Serverless spec activÃ©\n",
      "   â˜‘ Namespaces documentÃ©s\n",
      "\n",
      "ðŸŽ¯ PrÃªt pour l'ingestion (Notebook 2)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK 1 : Configuration et Nettoyage Pinecone\n",
    "================================================\n",
    "\n",
    "OBJECTIF : RÃ©initialiser complÃ¨tement l'environnement vectoriel\n",
    "           et crÃ©er une architecture propre avec namespaces.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- Pinecone Docs : https://docs.pinecone.io/docs/python-client\n",
    "- LangChain Pinecone : https://python.langchain.com/docs/integrations/vectorstores/pinecone\n",
    "\n",
    "MÃ‰THODOLOGIE :\n",
    "1. Supprimer l'index existant (stratÃ©gie Option A validÃ©e)\n",
    "2. RecrÃ©er un index optimisÃ© pour Mistral embeddings (dimension 1024)\n",
    "3. Valider la structure des namespaces\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 1 : CHARGEMENT DES VARIABLES D'ENVIRONNEMENT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "    #PINECONE_ENVIRONMENT = os.getenv(\"PINECONE_ENVIRONMENT\", \"us-east-1\")\n",
    "\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"âŒ PINECONE_API_KEY manquante dans .env\")\n",
    "\n",
    "print(\" Variables d'environnement chargÃ©es\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 2 : INITIALISATION CLIENT PINECONE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "JUSTIFICATION : \n",
    "Pinecone v3+ utilise une nouvelle API avec ServerlessSpec.\n",
    "Cela permet une scalabilitÃ© automatique sans gÃ©rer de pods.\n",
    "\n",
    "RÃ©fÃ©rence : https://docs.pinecone.io/docs/new-api\n",
    "\"\"\"\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "print(\"Client Pinecone initialisÃ©\")\n",
    "    #print(f\" Client Pinecone initialisÃ© (Environnement : {PINECONE_ENVIRONMENT})\")\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 3 : SUPPRESSION DE L'INDEX EXISTANT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "STRATÃ‰GIE VALIDÃ‰E : Option A - Suppression totale\n",
    "\n",
    "POURQUOI ?\n",
    "- Garantit un environnement propre sans donnÃ©es parasites\n",
    "- Ã‰vite les conflits de dimension d'embeddings\n",
    "- Permet de repartir sur des mÃ©tadonnÃ©es structurÃ©es\n",
    "\n",
    "ALTERNATIVE NON RETENUE :\n",
    "Option B (namespaces sans suppression) aurait conservÃ© les donnÃ©es \n",
    "de test (Wikipedia, thermodynamique) qui pollueraient la veille.\n",
    "\"\"\"\n",
    "\n",
    "INDEX_NAME = \"kpmg-veille\"\n",
    "'''\n",
    "def clean_pinecone_index():\n",
    "    \"\"\"Supprime l'index existant s'il existe\"\"\"\n",
    "    try:\n",
    "        existing_indexes = [idx.name for idx in pc.list_indexes()]\n",
    "        \n",
    "        if INDEX_NAME in existing_indexes:\n",
    "            print(f\"ðŸ—‘ï¸  Index '{INDEX_NAME}' dÃ©tectÃ©. Suppression en cours...\")\n",
    "            pc.delete_index(INDEX_NAME)\n",
    "            \n",
    "            # Attendre la suppression complÃ¨te (bonnes pratiques Pinecone)\n",
    "            while INDEX_NAME in [idx.name for idx in pc.list_indexes()]:\n",
    "                print(\"   â³ Attente de la suppression...\")\n",
    "                time.sleep(2)\n",
    "            \n",
    "            print(\"âœ… Index supprimÃ© avec succÃ¨s\")\n",
    "        else:\n",
    "            print(f\"â„¹ï¸  Aucun index '{INDEX_NAME}' trouvÃ© (normal si 1Ã¨re exÃ©cution)\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Erreur lors du nettoyage : {e}\")\n",
    "        raise\n",
    "\n",
    "clean_pinecone_index()\n",
    "'''\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 4 : CRÃ‰ATION DU NOUVEL INDEX\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "CONFIGURATION OPTIMALE POUR MISTRAL EMBEDDINGS\n",
    "\n",
    "1. DIMENSION : 1024\n",
    "   - Mistral-embed gÃ©nÃ¨re des vecteurs de 1024 dimensions\n",
    "   - RÃ©fÃ©rence : https://docs.mistral.ai/capabilities/embeddings/\n",
    "\n",
    "2. MÃ‰TRIQUE : cosine\n",
    "   - Standard pour la similaritÃ© sÃ©mantique\n",
    "   - RecommandÃ©e par LangChain pour les embeddings textuels\n",
    "   - RÃ©fÃ©rence : https://python.langchain.com/docs/modules/data_connection/vectorstores/\n",
    "\n",
    "3. SERVERLESS SPEC :\n",
    "   - Cloud 'aws', RÃ©gion 'us-east-1'\n",
    "   - ScalabilitÃ© automatique (critique pour la veille en production)\n",
    "   - Pas de gestion de pods\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "def create_optimized_index():\n",
    "    \"\"\"CrÃ©e un index Pinecone optimisÃ© pour la veille stratÃ©gique\"\"\"\n",
    "    try:\n",
    "        print(f\"ðŸ”¨ CrÃ©ation de l'index '{INDEX_NAME}'...\")\n",
    "        \n",
    "        pc.create_index(\n",
    "            name=INDEX_NAME,\n",
    "            dimension=1024,  # Dimension Mistral-embed\n",
    "            metric=\"cosine\",  # SimilaritÃ© sÃ©mantique\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\"  # Utiliser votre rÃ©gion Pinecone\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Attendre que l'index soit prÃªt\n",
    "        while not pc.describe_index(INDEX_NAME).status['ready']:\n",
    "            print(\"   â³ Initialisation de l'index...\")\n",
    "            time.sleep(2)\n",
    "        \n",
    "        print(\"âœ… Index crÃ©Ã© et opÃ©rationnel\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur lors de la crÃ©ation : {e}\")\n",
    "        raise\n",
    "\n",
    "create_optimized_index()\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 5 : VALIDATION DE LA STRUCTURE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "ARCHITECTURE DES NAMESPACES\n",
    "\n",
    "Chaque namespace correspond Ã  un type de source de donnÃ©es :\n",
    "- financial_reports : SEC EDGAR, rapports annuels\n",
    "- news : NewsAPI, communiquÃ©s de presse\n",
    "- startups : Crunchbase (futur)\n",
    "- macro_data : yfinance, donnÃ©es Ã©conomiques\n",
    "- social_signals : Reddit, Twitter (futur)\n",
    "\n",
    "AVANTAGES :\n",
    "âœ“ Isolation des sources pour des requÃªtes ciblÃ©es\n",
    "âœ“ PossibilitÃ© de filtrer par namespace lors du retrieval\n",
    "âœ“ Gestion indÃ©pendante du cycle de vie des donnÃ©es\n",
    "âœ“ Facilite le debugging et les audits\n",
    "\"\"\"\n",
    "\n",
    "NAMESPACES = [\n",
    "    \"financial_reports\",\n",
    "    \"news\",\n",
    "    \"startups\",\n",
    "    \"macro_data\",\n",
    "    \"social_signals\"\n",
    "]\n",
    "\n",
    "def validate_index_structure():\n",
    "    \"\"\"Affiche la configuration de l'index\"\"\"\n",
    "    try:\n",
    "        index_stats = pc.Index(INDEX_NAME).describe_index_stats()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ðŸ“Š CONFIGURATION DE L'INDEX\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Nom : {INDEX_NAME}\")\n",
    "        print(f\"Dimension : 1024 (Mistral-embed)\")\n",
    "        print(f\"MÃ©trique : cosine\")\n",
    "        print(f\"Vecteurs totaux : {index_stats.get('total_vector_count', 0)}\")\n",
    "        print(f\"\\nðŸ“ Namespaces dÃ©finis :\")\n",
    "        for ns in NAMESPACES:\n",
    "            print(f\"   - {ns}\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        print(\"âœ… Index prÃªt pour l'ingestion de donnÃ©es\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur de validation : {e}\")\n",
    "        raise\n",
    "\n",
    "validate_index_structure()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 6 : CHECKLIST DE VALIDATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"\\nâœ… CHECKLIST COMPLÃ‰TÃ‰E :\")\n",
    "print(\"   â˜‘ Index existant supprimÃ©\")\n",
    "print(\"   â˜‘ Nouvel index crÃ©Ã© avec dimension 1024\")\n",
    "print(\"   â˜‘ MÃ©trique cosine configurÃ©e\")\n",
    "print(\"   â˜‘ Serverless spec activÃ©\")\n",
    "print(\"   â˜‘ Namespaces documentÃ©s\")\n",
    "print(\"\\nðŸŽ¯ PrÃªt pour l'ingestion (Notebook 2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration des sources initialisÃ©e\n",
      "\n",
      "============================================================\n",
      "ðŸš€ DÃ‰MARRAGE DE L'INGESTION MULTI-SOURCES\n",
      "============================================================\n",
      "\n",
      "\n",
      "ðŸ“° Chargement NewsAPI...\n",
      "[2026-01-04T13:55:51.798994] NEWSAPI - INFO : Recherche : 'technology finance'\n",
      "[2026-01-04T13:55:53.063556] NEWSAPI - SUCCESS : 99 articles rÃ©cupÃ©rÃ©s\n",
      "\n",
      "ðŸ“¢ Chargement communiquÃ©s de presse...\n",
      "[2026-01-04T13:55:53.069019] PRESS_RELEASE - INFO : Scraping https://www.apple.com/newsroom/\n",
      "[2026-01-04T13:55:54.860091] PRESS_RELEASE - SUCCESS : Document chargÃ© depuis https://www.apple.com/newsroom/\n",
      "\n",
      "ðŸ’¹ Chargement donnÃ©es financiÃ¨res...\n",
      "[2026-01-04T13:55:54.867835] YFINANCE - INFO : RÃ©cupÃ©ration donnÃ©es pour AAPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "429 Client Error: Too Many Requests for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/AAPL?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=AAPL&crumb=Edge%3A+Too+Many+Requests\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-04T13:55:57.894684] YFINANCE - ERROR : AAPL - Expecting value: line 1 column 1 (char 0)\n",
      "[2026-01-04T13:56:03.903441] YFINANCE - INFO : RÃ©cupÃ©ration donnÃ©es pour MSFT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "429 Client Error: Too Many Requests for url: https://query2.finance.yahoo.com/v10/finance/quoteSummary/MSFT?modules=financialData%2CquoteType%2CdefaultKeyStatistics%2CassetProfile%2CsummaryDetail&corsDomain=finance.yahoo.com&formatted=false&symbol=MSFT&crumb=Edge%3A+Too+Many+Requests\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-04T13:56:06.476502] YFINANCE - ERROR : MSFT - Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š RÃ‰SUMÃ‰ DE L'INGESTION\n",
      "============================================================\n",
      "   financial_reports: 0 documents\n",
      "   news: 100 documents\n",
      "   macro_data: 0 documents\n",
      "============================================================\n",
      "\n",
      "âœ… Documents sauvegardÃ©s dans 'ingested_documents.json'\n",
      "ðŸŽ¯ PrÃªt pour le chunking et les embeddings (Notebook 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK 2 : Ingestion Multi-Sources\n",
    "====================================\n",
    "\n",
    "OBJECTIF : CrÃ©er un pipeline robuste d'ingestion de donnÃ©es\n",
    "           depuis SEC EDGAR, NewsAPI, communiquÃ©s de presse et yfinance.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- LangChain Document Loaders : https://python.langchain.com/docs/modules/data_connection/document_loaders/\n",
    "- SEC EDGAR : https://www.sec.gov/edgar/sec-api-documentation\n",
    "- NewsAPI : https://newsapi.org/docs\n",
    "- yfinance : https://pypi.org/project/yfinance/\n",
    "\n",
    "ARCHITECTURE :\n",
    "1. Loaders modulaires par source\n",
    "2. MÃ©tadonnÃ©es riches (source, date, type)\n",
    "3. Gestion d'erreurs et retry\n",
    "4. Logging pour traÃ§abilitÃ©\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# APIs externes\n",
    "import yfinance as yf\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 1 : CONFIGURATION DES SOURCES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "BONNES PRATIQUES :\n",
    "- Centraliser les configurations\n",
    "- Utiliser des variables d'environnement pour les clÃ©s API\n",
    "- Documenter les limites de chaque source\n",
    "\"\"\"\n",
    "\n",
    "# NewsAPI (100 requÃªtes/jour gratuit)\n",
    "NEWSAPI_KEY = os.getenv(\"NEWSAPI_KEY\")\n",
    "NEWSAPI_ENDPOINT = \"https://newsapi.org/v2/everything\"\n",
    "\n",
    "# SEC EDGAR (gratuit, nÃ©cessite User-Agent)\n",
    "    #SEC_USER_AGENT = os.getenv(\"SEC_USER_AGENT\", \"VotreNom votre.email@example.com\")\n",
    "    #SEC_BASE_URL = \"https://data.sec.gov/submissions/\"\n",
    "\n",
    "# Configuration logging\n",
    "LOGS_DIR = \"ingestion_logs\"\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "\n",
    "def log_ingestion(source: str, status: str, details: str):\n",
    "    \"\"\"Log les opÃ©rations d'ingestion pour audit\"\"\"\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    log_entry = f\"[{timestamp}] {source} - {status} : {details}\\n\"\n",
    "    \n",
    "    with open(f\"{LOGS_DIR}/ingestion.log\", \"a\") as f:\n",
    "        f.write(log_entry)\n",
    "    \n",
    "    print(log_entry.strip())\n",
    "\n",
    "print(\"âœ… Configuration des sources initialisÃ©e\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 2 : SOURCE 1 - SEC EDGAR\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "SEC EDGAR : Base de donnÃ©es rÃ©glementaire de la SEC (US)\n",
    "\n",
    "JUSTIFICATION DU CHOIX :\n",
    "âœ“ DonnÃ©es structurÃ©es et fiables\n",
    "âœ“ Gratuit avec rate limiting raisonnable (10 req/sec)\n",
    "âœ“ Essentiel pour l'analyse d'entreprises US (contexte KPMG)\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://www.sec.gov/edgar/sec-api-documentation\n",
    "\n",
    "EXIGENCE CRITIQUE :\n",
    "La SEC bloque les requÃªtes sans User-Agent. \n",
    "Format requis : \"Nom email@example.com\"\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "def load_sec_edgar_filing(cik: str, filing_type: str = \"10-K\") -> List[Document]:\n",
    "    \"\"\"\n",
    "    Charge un dÃ©pÃ´t SEC pour une entreprise donnÃ©e\n",
    "    \n",
    "    Args:\n",
    "        cik: Central Index Key de l'entreprise (ex: \"0000320193\" pour Apple)\n",
    "        filing_type: Type de dÃ©pÃ´t (10-K, 10-Q, 8-K, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        Liste de Documents LangChain avec mÃ©tadonnÃ©es\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\"User-Agent\": SEC_USER_AGENT}\n",
    "        url = f\"{SEC_BASE_URL}CIK{cik.zfill(10)}.json\"\n",
    "        \n",
    "        log_ingestion(\"SEC_EDGAR\", \"INFO\", f\"RequÃªte pour CIK {cik}\")\n",
    "        \n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        company_name = data.get(\"name\", \"Unknown\")\n",
    "        \n",
    "        # Filtrer les dÃ©pÃ´ts par type\n",
    "        filings = data.get(\"filings\", {}).get(\"recent\", {})\n",
    "        \n",
    "        documents = []\n",
    "        for i, form in enumerate(filings.get(\"form\", [])):\n",
    "            if form == filing_type:\n",
    "                filing_date = filings[\"filingDate\"][i]\n",
    "                accession = filings[\"accessionNumber\"][i]\n",
    "                primary_doc = filings[\"primaryDocument\"][i]\n",
    "                \n",
    "                # URL du document\n",
    "                acc_no_formatted = accession.replace(\"-\", \"\")\n",
    "                doc_url = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{acc_no_formatted}/{primary_doc}\"\n",
    "                \n",
    "                # CrÃ©ation du Document LangChain\n",
    "                doc = Document(\n",
    "                    page_content=f\"SEC Filing {filing_type} for {company_name} on {filing_date}\",\n",
    "                    metadata={\n",
    "                        \"source\": \"sec_edgar\",\n",
    "                        \"company\": company_name,\n",
    "                        \"cik\": cik,\n",
    "                        \"filing_type\": filing_type,\n",
    "                        \"filing_date\": filing_date,\n",
    "                        \"accession_number\": accession,\n",
    "                        \"url\": doc_url,\n",
    "                        \"namespace\": \"financial_reports\"\n",
    "                    }\n",
    "                )\n",
    "                documents.append(doc)\n",
    "        \n",
    "        log_ingestion(\"SEC_EDGAR\", \"SUCCESS\", f\"{len(documents)} documents trouvÃ©s pour {company_name}\")\n",
    "        return documents\n",
    "    \n",
    "    except Exception as e:\n",
    "        log_ingestion(\"SEC_EDGAR\", \"ERROR\", str(e))\n",
    "        return []\n",
    "'''\n",
    "\n",
    "# Exemple d'utilisation (commentÃ© pour Ã©viter rate limiting)\n",
    "# apple_docs = load_sec_edgar_filing(\"0000320193\", \"10-K\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 3 : SOURCE 2 - NEWSAPI\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "NEWSAPI : AgrÃ©gateur d'actualitÃ©s mondiales\n",
    "\n",
    "JUSTIFICATION :\n",
    "âœ“ Alternative gratuite Ã  Google News API (100 req/jour)\n",
    "âœ“ Couvre 150 000+ sources\n",
    "âœ“ Filtrage par mots-clÃ©s, langue, date\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://newsapi.org/docs/endpoints/everything\n",
    "\n",
    "LIMITE PLAN GRATUIT :\n",
    "- Articles limitÃ©s aux 30 derniers jours\n",
    "- Pas d'accÃ¨s aux articles complets (seulement titre + description)\n",
    "\"\"\"\n",
    "\n",
    "def load_newsapi_articles(query: str, language: str = \"en\", days_back: int = 7) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Charge des articles depuis NewsAPI\n",
    "    \n",
    "    Args:\n",
    "        query: Mot-clÃ© de recherche (ex: \"artificial intelligence finance\")\n",
    "        language: Code langue (en, fr, de, etc.)\n",
    "        days_back: Nombre de jours en arriÃ¨re (max 30 pour plan gratuit)\n",
    "    \n",
    "    Returns:\n",
    "        Liste de Documents avec mÃ©tadonnÃ©es structurÃ©es\n",
    "    \"\"\"\n",
    "    if not NEWSAPI_KEY:\n",
    "        log_ingestion(\"NEWSAPI\", \"ERROR\", \"ClÃ© API manquante\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        from_date = (datetime.now() - timedelta(days=days_back)).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"from\": from_date,\n",
    "            \"language\": language,\n",
    "            \"sortBy\": \"relevancy\",\n",
    "            \"apiKey\": NEWSAPI_KEY\n",
    "        }\n",
    "        \n",
    "        log_ingestion(\"NEWSAPI\", \"INFO\", f\"Recherche : '{query}'\")\n",
    "        \n",
    "        response = requests.get(NEWSAPI_ENDPOINT, params=params)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        articles = data.get(\"articles\", [])\n",
    "        \n",
    "        documents = []\n",
    "        for article in articles:\n",
    "            content = f\"{article.get('title', '')}. {article.get('description', '')}\"\n",
    "            \n",
    "            doc = Document(\n",
    "                page_content=content,\n",
    "                metadata={\n",
    "                    \"source\": \"newsapi\",\n",
    "                    \"title\": article.get(\"title\"),\n",
    "                    \"author\": article.get(\"author\"),\n",
    "                    \"published_at\": article.get(\"publishedAt\"),\n",
    "                    \"url\": article.get(\"url\"),\n",
    "                    \"source_name\": article.get(\"source\", {}).get(\"name\"),\n",
    "                    \"namespace\": \"news\"\n",
    "                }\n",
    "            )\n",
    "            documents.append(doc)\n",
    "        \n",
    "        log_ingestion(\"NEWSAPI\", \"SUCCESS\", f\"{len(documents)} articles rÃ©cupÃ©rÃ©s\")\n",
    "        return documents\n",
    "    \n",
    "    except Exception as e:\n",
    "        log_ingestion(\"NEWSAPI\", \"ERROR\", str(e))\n",
    "        return []\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# news_docs = load_newsapi_articles(\"fintech investment\", language=\"en\", days_back=7)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 4 : SOURCE 3 - COMMUNIQUÃ‰S DE PRESSE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "WEB SCRAPING : CommuniquÃ©s de presse d'entreprises\n",
    "\n",
    "JUSTIFICATION :\n",
    "âœ“ Source primaire (directement depuis les entreprises)\n",
    "âœ“ DonnÃ©es structurÃ©es et fiables\n",
    "âœ“ Gratuit (scraping Ã©thique avec respect du robots.txt)\n",
    "\n",
    "LOADER CHOISI : WebBaseLoader\n",
    "RÃ©fÃ©rence : https://python.langchain.com/docs/integrations/document_loaders/web_base\n",
    "\n",
    "BONNES PRATIQUES :\n",
    "- VÃ©rifier robots.txt avant de scraper\n",
    "- ImplÃ©menter des dÃ©lais entre requÃªtes (rate limiting)\n",
    "- GÃ©rer les erreurs (timeouts, 404, etc.)\n",
    "\"\"\"\n",
    "\n",
    "def load_press_releases(urls: List[str]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Charge des communiquÃ©s de presse depuis des URLs\n",
    "    \n",
    "    Args:\n",
    "        urls: Liste d'URLs de communiquÃ©s\n",
    "    \n",
    "    Returns:\n",
    "        Documents avec mÃ©tadonnÃ©es enrichies\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for url in urls:\n",
    "        try:\n",
    "            log_ingestion(\"PRESS_RELEASE\", \"INFO\", f\"Scraping {url}\")\n",
    "            \n",
    "            loader = WebBaseLoader(url)\n",
    "            docs = loader.load()\n",
    "            \n",
    "            # Enrichir les mÃ©tadonnÃ©es\n",
    "            for doc in docs:\n",
    "                doc.metadata.update({\n",
    "                    \"source\": \"press_release\",\n",
    "                    \"scrape_date\": datetime.now().isoformat(),\n",
    "                    \"namespace\": \"news\"\n",
    "                })\n",
    "                documents.append(doc)\n",
    "            \n",
    "            # Rate limiting Ã©thique\n",
    "            time.sleep(1)\n",
    "            \n",
    "            log_ingestion(\"PRESS_RELEASE\", \"SUCCESS\", f\"Document chargÃ© depuis {url}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            log_ingestion(\"PRESS_RELEASE\", \"ERROR\", f\"{url} - {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Exemple d'URLs (Ã  adapter selon vos besoins)\n",
    "# press_urls = [\n",
    "#     \"https://www.apple.com/newsroom/2024/01/apple-reports-first-quarter-results/\",\n",
    "#     \"https://investor.fb.com/investor-news/default.aspx\"\n",
    "# ]\n",
    "# press_docs = load_press_releases(press_urls)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 5 : SOURCE 4 - YFINANCE (DONNÃ‰ES FINANCIÃˆRES)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "YFINANCE : DonnÃ©es financiÃ¨res en temps rÃ©el\n",
    "\n",
    "JUSTIFICATION :\n",
    "âœ“ Gratuit et sans clÃ© API\n",
    "âœ“ DonnÃ©es Yahoo Finance (fiables)\n",
    "âœ“ IdÃ©al pour les KPIs financiers (prix, revenus, ratios)\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://pypi.org/project/yfinance/\n",
    "\n",
    "MÃ‰THODOLOGIE :\n",
    "On transforme les donnÃ©es structurÃ©es (JSON) en documents textuels\n",
    "pour les rendre compatibles avec le RAG.\n",
    "\"\"\"\n",
    "\n",
    "def load_yfinance_data(ticker: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Charge les donnÃ©es financiÃ¨res d'une entreprise via yfinance\n",
    "    \n",
    "    Args:\n",
    "        ticker: Symbole boursier (ex: \"AAPL\", \"MSFT\")\n",
    "    \n",
    "    Returns:\n",
    "        Documents avec mÃ©triques financiÃ¨res clÃ©s\n",
    "    \"\"\"\n",
    "    try:\n",
    "        log_ingestion(\"YFINANCE\", \"INFO\", f\"RÃ©cupÃ©ration donnÃ©es pour {ticker}\")\n",
    "        \n",
    "        stock = yf.Ticker(ticker)\n",
    "        info = stock.info\n",
    "        \n",
    "        # Extraire les mÃ©triques clÃ©s\n",
    "        metrics = {\n",
    "            \"market_cap\": info.get(\"marketCap\"),\n",
    "            \"revenue\": info.get(\"totalRevenue\"),\n",
    "            \"profit_margin\": info.get(\"profitMargins\"),\n",
    "            \"pe_ratio\": info.get(\"trailingPE\"),\n",
    "            \"current_price\": info.get(\"currentPrice\"),\n",
    "            \"52week_high\": info.get(\"fiftyTwoWeekHigh\"),\n",
    "            \"52week_low\": info.get(\"fiftyTwoWeekLow\")\n",
    "        }\n",
    "        \n",
    "        # CrÃ©er un texte descriptif\n",
    "        content = f\"\"\"\n",
    "        Financial Overview for {ticker}:\n",
    "        - Market Cap: ${metrics['market_cap']:,} (if available)\n",
    "        - Revenue: ${metrics['revenue']:,}\n",
    "        - Profit Margin: {metrics['profit_margin']:.2%}\n",
    "        - P/E Ratio: {metrics['pe_ratio']}\n",
    "        - Current Price: ${metrics['current_price']}\n",
    "        - 52-Week Range: ${metrics['52week_low']} - ${metrics['52week_high']}\n",
    "        \"\"\"\n",
    "        \n",
    "        doc = Document(\n",
    "            page_content=content,\n",
    "            metadata={\n",
    "                \"source\": \"yfinance\",\n",
    "                \"ticker\": ticker,\n",
    "                \"company_name\": info.get(\"longName\", ticker),\n",
    "                \"sector\": info.get(\"sector\"),\n",
    "                \"industry\": info.get(\"industry\"),\n",
    "                \"retrieval_date\": datetime.now().isoformat(),\n",
    "                \"namespace\": \"macro_data\",\n",
    "                **metrics  # Ajouter toutes les mÃ©triques aux mÃ©tadonnÃ©es\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        log_ingestion(\"YFINANCE\", \"SUCCESS\", f\"DonnÃ©es rÃ©cupÃ©rÃ©es pour {ticker}\")\n",
    "        return [doc]\n",
    "    \n",
    "    except Exception as e:\n",
    "        log_ingestion(\"YFINANCE\", \"ERROR\", f\"{ticker} - {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# apple_finance = load_yfinance_data(\"AAPL\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 6 : PIPELINE D'INGESTION UNIFIÃ‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "FONCTION MAÃŽTRE : Orchestration de toutes les sources\n",
    "\n",
    "Cette fonction permet de lancer l'ingestion de toutes les sources\n",
    "en une seule commande. Elle gÃ¨re les erreurs et retourne un rÃ©sumÃ©.\n",
    "\"\"\"\n",
    "\n",
    "def ingest_all_sources() -> Dict[str, List[Document]]:\n",
    "    \"\"\"\n",
    "    Lance l'ingestion de toutes les sources configurÃ©es\n",
    "    \n",
    "    Returns:\n",
    "        Dictionnaire {namespace: [documents]}\n",
    "    \"\"\"\n",
    "    all_documents = {\n",
    "        \"financial_reports\": [],\n",
    "        \"news\": [],\n",
    "        \"macro_data\": []\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸš€ DÃ‰MARRAGE DE L'INGESTION MULTI-SOURCES\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Source 1 : SEC EDGAR (exemple : Apple)\n",
    "    '''\n",
    "    print(\"ðŸ“Š Chargement SEC EDGAR...\")\n",
    "    sec_docs = load_sec_edgar_filing(\"0000320193\", \"10-K\")\n",
    "    all_documents[\"financial_reports\"].extend(sec_docs)\n",
    "    '''\n",
    "\n",
    "    # Source 2 : NewsAPI (si clÃ© disponible)\n",
    "    if NEWSAPI_KEY:\n",
    "        print(\"\\nðŸ“° Chargement NewsAPI...\")\n",
    "        news_docs = load_newsapi_articles(\"technology finance\", days_back=7)\n",
    "        all_documents[\"news\"].extend(news_docs)\n",
    "    \n",
    "    # Source 3 : CommuniquÃ©s de presse (exemple)\n",
    "    print(\"\\nðŸ“¢ Chargement communiquÃ©s de presse...\")\n",
    "    press_urls = [\n",
    "        \"https://www.apple.com/newsroom/\"\n",
    "    ]\n",
    "    press_docs = load_press_releases(press_urls)\n",
    "    all_documents[\"news\"].extend(press_docs)\n",
    "    \n",
    "    # Source 4 : yfinance (exemple : Apple, Microsoft)\n",
    "    print(\"\\nðŸ’¹ Chargement donnÃ©es financiÃ¨res...\")\n",
    "    for ticker in [\"AAPL\", \"MSFT\"]:\n",
    "        finance_docs = load_yfinance_data(ticker)\n",
    "        all_documents[\"macro_data\"].extend(finance_docs)\n",
    "        time.sleep(6)  # Attendre 6 secondes entre chaque ticker\n",
    "\n",
    "    ''' \n",
    "    âœ… Solution long terme : Mettre en cache les donnÃ©es yfinance dans un fichier JSON.\n",
    "    '''\n",
    "    \n",
    "    # RÃ©sumÃ©\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“Š RÃ‰SUMÃ‰ DE L'INGESTION\")\n",
    "    print(\"=\"*60)\n",
    "    for namespace, docs in all_documents.items():\n",
    "        print(f\"   {namespace}: {len(docs)} documents\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    return all_documents\n",
    "\n",
    "# ExÃ©cution du pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    documents_by_namespace = ingest_all_sources()\n",
    "    \n",
    "    # Sauvegarder les documents pour le Notebook 3\n",
    "    with open(\"ingested_documents.json\", \"w\") as f:\n",
    "        # Conversion en format sÃ©rialisable\n",
    "        serializable = {}\n",
    "        for ns, docs in documents_by_namespace.items():\n",
    "            serializable[ns] = [\n",
    "                {\n",
    "                    \"page_content\": doc.page_content,\n",
    "                    \"metadata\": doc.metadata\n",
    "                }\n",
    "                for doc in docs\n",
    "            ]\n",
    "        json.dump(serializable, f, indent=2)\n",
    "    \n",
    "    print(\"âœ… Documents sauvegardÃ©s dans 'ingested_documents.json'\")\n",
    "    print(\"ðŸŽ¯ PrÃªt pour le chunking et les embeddings (Notebook 3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chunker adaptatif initialisÃ©\n",
      "âœ… 100 documents chargÃ©s\n",
      "\n",
      "============================================================\n",
      "ðŸ”ª PHASE DE CHUNKING ADAPTATIF\n",
      "============================================================\n",
      "\n",
      "ðŸ”ª Chunking pour namespace 'news'...\n",
      "   âœ… 100 docs â†’ 109 chunks\n",
      "\n",
      "ðŸ“Š RÃ©sumÃ© du chunking :\n",
      "   news: 109 chunks\n",
      "\n",
      "âœ… ModÃ¨le Mistral-embed initialisÃ©\n",
      "\n",
      "âœ… Ã‰tape 1 : Chunking terminÃ©\n",
      "\n",
      "============================================================\n",
      "ðŸ§® Ã‰TAPE 2 : GÃ‰NÃ‰RATION DES EMBEDDINGS\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Traitement namespace 'news'...\n",
      "\n",
      "ðŸ§® GÃ©nÃ©ration de 109 embeddings...\n",
      "   âœ… Batch 1/3 traitÃ©\n",
      "   âœ… Batch 2/3 traitÃ©\n",
      "   âœ… Batch 3/3 traitÃ©\n",
      "\n",
      "============================================================\n",
      "âœ… VALIDATION DE LA QUALITÃ‰\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Namespace: news\n",
      "   âœ… 109 chunks validÃ©s\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š Chunks avec embeddings : 109/109\n",
      "âœ… Toutes les dimensions sont correctes (1024)\n",
      "============================================================\n",
      "\n",
      "ðŸ’¾ Sauvegarde des documents pour indexation...\n",
      "âœ… Documents sauvegardÃ©s dans 'embedded_documents.json'\n",
      "\n",
      "ðŸŽ¯ PrÃªt pour l'indexation Pinecone (Notebook 4)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK 3 : Chunking Adaptatif & Embeddings Mistral\n",
    "====================================================\n",
    "\n",
    "OBJECTIF : DÃ©couper les documents de maniÃ¨re intelligente\n",
    "           et gÃ©nÃ©rer des embeddings optimisÃ©s pour Pinecone.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- LangChain Text Splitters : https://python.langchain.com/docs/modules/data_connection/document_transformers/\n",
    "- Mistral Embeddings : https://docs.mistral.ai/capabilities/embeddings/\n",
    "- Chunking Best Practices : https://www.pinecone.io/learn/chunking-strategies/\n",
    "\n",
    "MÃ‰THODOLOGIE :\n",
    "1. Chunking adaptatif selon le type de document\n",
    "2. Enrichissement des mÃ©tadonnÃ©es\n",
    "3. GÃ©nÃ©ration d'embeddings par batch (optimisation)\n",
    "4. Validation de la qualitÃ©\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    HTMLHeaderTextSplitter\n",
    ")\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 1 : STRATÃ‰GIES DE CHUNKING PAR TYPE DE DOCUMENT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "JUSTIFICATION DES CHOIX DE CHUNKING\n",
    "\n",
    "D'aprÃ¨s vos notes (KPMG v2.pdf), le chunking est l'Ã©tape la plus sous-estimÃ©e\n",
    "mais dÃ©terminante pour la qualitÃ© du RAG.\n",
    "\n",
    "PRINCIPES :\n",
    "1. GranularitÃ© adaptÃ©e au contenu\n",
    "   - Petits chunks (500 chars) : KPIs, chiffres prÃ©cis\n",
    "   - Gros chunks (1000+ chars) : analyses, raisonnements\n",
    "\n",
    "2. Overlap significatif (15-20%)\n",
    "   - Ã‰vite de couper les informations critiques\n",
    "   - Maintient la cohÃ©rence contextuelle\n",
    "\n",
    "3. SÃ©parateurs intelligents\n",
    "   - Paragraphes > Phrases > Mots\n",
    "   - PrÃ©serve la structure sÃ©mantique\n",
    "\"\"\"\n",
    "\n",
    "class AdaptiveChunker:\n",
    "    \"\"\"DÃ©coupe intelligente selon le type de document\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Splitter pour rapports financiers (SEC, yfinance)\n",
    "        self.financial_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=800,      # Balance entre dÃ©tail et contexte\n",
    "            chunk_overlap=150,   # ~19% overlap\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "            add_start_index=True  # TraÃ§abilitÃ© dans le document source\n",
    "        )\n",
    "        \n",
    "        # Splitter pour actualitÃ©s (courtes, denses)\n",
    "        self.news_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,      # Articles courts\n",
    "            chunk_overlap=100,   # 20% overlap\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "            add_start_index=True\n",
    "        )\n",
    "        \n",
    "        # Splitter HTML (communiquÃ©s de presse structurÃ©s)\n",
    "        self.html_splitter = HTMLHeaderTextSplitter(\n",
    "            headers_to_split_on=[\n",
    "                (\"h1\", \"Header 1\"),\n",
    "                (\"h2\", \"Header 2\"),\n",
    "                (\"h3\", \"Header 3\"),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def chunk_documents(self, documents: List[Document], namespace: str) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Applique la stratÃ©gie de chunking appropriÃ©e\n",
    "        \n",
    "        Args:\n",
    "            documents: Documents Ã  dÃ©couper\n",
    "            namespace: Type de document (dÃ©termine la stratÃ©gie)\n",
    "        \n",
    "        Returns:\n",
    "            Documents dÃ©coupÃ©s avec mÃ©tadonnÃ©es enrichies\n",
    "        \"\"\"\n",
    "        print(f\"\\nðŸ”ª Chunking pour namespace '{namespace}'...\")\n",
    "        \n",
    "        # SÃ©lection du splitter\n",
    "        if namespace == \"financial_reports\":\n",
    "            splitter = self.financial_splitter\n",
    "        elif namespace == \"news\":\n",
    "            splitter = self.news_splitter\n",
    "        elif namespace == \"macro_data\":\n",
    "            splitter = self.financial_splitter\n",
    "        else:\n",
    "            splitter = self.news_splitter  # DÃ©faut\n",
    "        \n",
    "        # DÃ©coupage\n",
    "        chunked_docs = []\n",
    "        for doc in documents:\n",
    "            chunks = splitter.split_documents([doc])\n",
    "            \n",
    "            # Enrichir chaque chunk avec info de position\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                chunk.metadata.update({\n",
    "                    \"chunk_index\": i,\n",
    "                    \"total_chunks\": len(chunks),\n",
    "                    \"chunking_strategy\": splitter.__class__.__name__\n",
    "                })\n",
    "                chunked_docs.append(chunk)\n",
    "        \n",
    "        print(f\"   âœ… {len(documents)} docs â†’ {len(chunked_docs)} chunks\")\n",
    "        return chunked_docs\n",
    "\n",
    "chunker = AdaptiveChunker()\n",
    "print(\"âœ… Chunker adaptatif initialisÃ©\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 2 : CHARGEMENT DES DOCUMENTS INGÃ‰RÃ‰S\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "RÃ©cupÃ©ration des documents depuis le Notebook 2\n",
    "\"\"\"\n",
    "\n",
    "def load_ingested_documents() -> Dict[str, List[Document]]:\n",
    "    \"\"\"Charge les documents depuis le fichier JSON\"\"\"\n",
    "    try:\n",
    "        with open(\"ingested_documents.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Reconversion en objets Document\n",
    "        documents_by_ns = {}\n",
    "        for namespace, docs_data in data.items():\n",
    "            documents_by_ns[namespace] = [\n",
    "                Document(\n",
    "                    page_content=d[\"page_content\"],\n",
    "                    metadata=d[\"metadata\"]\n",
    "                )\n",
    "                for d in docs_data\n",
    "            ]\n",
    "        \n",
    "        print(f\"âœ… {sum(len(docs) for docs in documents_by_ns.values())} documents chargÃ©s\")\n",
    "        return documents_by_ns\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Fichier 'ingested_documents.json' introuvable.\")\n",
    "        print(\"   ExÃ©cutez d'abord le Notebook 2 (ingestion)\")\n",
    "        return {}\n",
    "\n",
    "docs_by_namespace = load_ingested_documents()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 3 : APPLICATION DU CHUNKING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "Application du chunking adaptatif sur tous les namespaces\n",
    "\"\"\"\n",
    "\n",
    "chunked_by_namespace = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ”ª PHASE DE CHUNKING ADAPTATIF\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for namespace, documents in docs_by_namespace.items():\n",
    "    if documents:\n",
    "        chunked_docs = chunker.chunk_documents(documents, namespace)\n",
    "        chunked_by_namespace[namespace] = chunked_docs\n",
    "\n",
    "print(\"\\nðŸ“Š RÃ©sumÃ© du chunking :\")\n",
    "for ns, chunks in chunked_by_namespace.items():\n",
    "    print(f\"   {ns}: {len(chunks)} chunks\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 4 : GÃ‰NÃ‰RATION DES EMBEDDINGS MISTRAL\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "CONFIGURATION MISTRAL EMBEDDINGS\n",
    "\n",
    "ModÃ¨le : mistral-embed\n",
    "Dimension : 1024\n",
    "CoÃ»t : Gratuit avec limits (voir plan Mistral)\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://docs.mistral.ai/capabilities/embeddings/\n",
    "\n",
    "OPTIMISATION :\n",
    "- Traitement par batch pour limiter les appels API\n",
    "- Cache local des embeddings (Ã©vite recalcul)\n",
    "- Gestion des erreurs et retry\n",
    "\"\"\"\n",
    "\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "if not MISTRAL_API_KEY:\n",
    "    raise ValueError(\"âŒ MISTRAL_API_KEY manquante dans .env\")\n",
    "\n",
    "embeddings_model = MistralAIEmbeddings(\n",
    "    model=\"mistral-embed\",\n",
    "    mistral_api_key=MISTRAL_API_KEY\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… ModÃ¨le Mistral-embed initialisÃ©\")\n",
    "\n",
    "def generate_embeddings_batch(documents: List[Document], batch_size: int = 50) -> List[Document]:\n",
    "    \"\"\"\n",
    "    GÃ©nÃ¨re les embeddings par batch pour optimiser les appels API\n",
    "    \n",
    "    Args:\n",
    "        documents: Documents Ã  embedder\n",
    "        batch_size: Nombre de documents par batch\n",
    "    \n",
    "    Returns:\n",
    "        Documents avec embeddings dans les mÃ©tadonnÃ©es\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ§® GÃ©nÃ©ration de {len(documents)} embeddings...\")\n",
    "    \n",
    "    total_batches = (len(documents) + batch_size - 1) // batch_size\n",
    "    \n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        batch = documents[i:i+batch_size]\n",
    "        batch_num = i // batch_size + 1\n",
    "        \n",
    "        try:\n",
    "            # Extraire les textes\n",
    "            texts = [doc.page_content for doc in batch]\n",
    "            \n",
    "            # GÃ©nÃ©rer les embeddings\n",
    "            embeddings = embeddings_model.embed_documents(texts)\n",
    "            \n",
    "            # Ajouter les embeddings aux mÃ©tadonnÃ©es\n",
    "            for doc, embedding in zip(batch, embeddings):\n",
    "                doc.metadata[\"embedding\"] = embedding\n",
    "            \n",
    "            print(f\"   âœ… Batch {batch_num}/{total_batches} traitÃ©\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Erreur batch {batch_num}: {e}\")\n",
    "            # Continuer avec les autres batches\n",
    "            continue\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 5 : VALIDATION DE LA QUALITÃ‰\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "MÃ‰TRIQUES DE QUALITÃ‰\n",
    "\n",
    "Avant d'envoyer vers Pinecone, on valide :\n",
    "1. Tous les chunks ont des embeddings\n",
    "2. Les dimensions sont correctes (1024)\n",
    "3. Les mÃ©tadonnÃ©es sont complÃ¨tes\n",
    "\"\"\"\n",
    "\n",
    "def validate_chunked_documents(docs_by_ns: Dict[str, List[Document]]) -> bool:\n",
    "    \"\"\"Valide la qualitÃ© des documents chunkÃ©s et embeddÃ©s\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… VALIDATION DE LA QUALITÃ‰\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    total_chunks = sum(len(docs) for docs in docs_by_ns.values())\n",
    "    chunks_with_embeddings = 0\n",
    "    invalid_embeddings = []\n",
    "    \n",
    "    for namespace, documents in docs_by_ns.items():\n",
    "        print(f\"\\nðŸ“ Namespace: {namespace}\")\n",
    "        \n",
    "        for i, doc in enumerate(documents):\n",
    "            # VÃ©rifier prÃ©sence embedding\n",
    "            if \"embedding\" in doc.metadata:\n",
    "                chunks_with_embeddings += 1\n",
    "                \n",
    "                # VÃ©rifier dimension\n",
    "                emb_dim = len(doc.metadata[\"embedding\"])\n",
    "                if emb_dim != 1024:\n",
    "                    invalid_embeddings.append((namespace, i, emb_dim))\n",
    "            \n",
    "            # VÃ©rifier mÃ©tadonnÃ©es essentielles\n",
    "            required_metadata = [\"source\", \"namespace\"]\n",
    "            missing = [key for key in required_metadata if key not in doc.metadata]\n",
    "            if missing:\n",
    "                print(f\"   âš ï¸  Chunk {i} : mÃ©tadonnÃ©es manquantes {missing}\")\n",
    "        \n",
    "        print(f\"   âœ… {len(documents)} chunks validÃ©s\")\n",
    "    \n",
    "    # Rapport final\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ðŸ“Š Chunks avec embeddings : {chunks_with_embeddings}/{total_chunks}\")\n",
    "    \n",
    "    if invalid_embeddings:\n",
    "        print(f\"âš ï¸  Embeddings invalides (dimension â‰  1024) : {len(invalid_embeddings)}\")\n",
    "        for ns, idx, dim in invalid_embeddings[:5]:  # Afficher les 5 premiers\n",
    "            print(f\"   - {ns}[{idx}] : dimension {dim}\")\n",
    "    else:\n",
    "        print(\"âœ… Toutes les dimensions sont correctes (1024)\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return chunks_with_embeddings == total_chunks\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 6 : PIPELINE COMPLET\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "Orchestration complÃ¨te : Chunking â†’ Embeddings â†’ Validation\n",
    "\"\"\"\n",
    "\n",
    "def process_all_documents():\n",
    "    \"\"\"Pipeline complet de traitement\"\"\"\n",
    "    \n",
    "    # Ã‰tape 1 : Chunking (dÃ©jÃ  fait)\n",
    "    print(\"\\nâœ… Ã‰tape 1 : Chunking terminÃ©\")\n",
    "    \n",
    "    # Ã‰tape 2 : GÃ©nÃ©ration des embeddings\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ§® Ã‰TAPE 2 : GÃ‰NÃ‰RATION DES EMBEDDINGS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for namespace, documents in chunked_by_namespace.items():\n",
    "        if documents:\n",
    "            print(f\"\\nðŸ“ Traitement namespace '{namespace}'...\")\n",
    "            generate_embeddings_batch(documents)\n",
    "    \n",
    "    # Ã‰tape 3 : Validation\n",
    "    is_valid = validate_chunked_documents(chunked_by_namespace)\n",
    "    \n",
    "    if is_valid:\n",
    "        # Sauvegarde pour le Notebook 4\n",
    "        print(\"\\nðŸ’¾ Sauvegarde des documents pour indexation...\")\n",
    "        \n",
    "        serializable = {}\n",
    "        for ns, docs in chunked_by_namespace.items():\n",
    "            serializable[ns] = [\n",
    "                {\n",
    "                    \"page_content\": doc.page_content,\n",
    "                    \"metadata\": {\n",
    "                        k: v for k, v in doc.metadata.items()\n",
    "                        if k != \"embedding\"  # Embeddings trop gros pour JSON\n",
    "                    },\n",
    "                    \"embedding\": doc.metadata.get(\"embedding\", [])\n",
    "                }\n",
    "                for doc in docs\n",
    "            ]\n",
    "        \n",
    "        with open(\"embedded_documents.json\", \"w\") as f:\n",
    "            json.dump(serializable, f, indent=2)\n",
    "        \n",
    "        print(\"âœ… Documents sauvegardÃ©s dans 'embedded_documents.json'\")\n",
    "        print(\"\\nðŸŽ¯ PrÃªt pour l'indexation Pinecone (Notebook 4)\")\n",
    "    else:\n",
    "        print(\"\\nâŒ Validation Ã©chouÃ©e. VÃ©rifiez les erreurs ci-dessus.\")\n",
    "\n",
    "# ExÃ©cution\n",
    "if __name__ == \"__main__\":\n",
    "    if docs_by_namespace:\n",
    "        process_all_documents()\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  Aucun document Ã  traiter.\")\n",
    "        print(\"   ExÃ©cutez d'abord les Notebooks 1 et 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Clients Pinecone et Mistral initialisÃ©s\n",
      "âœ… 109 documents chargÃ©s depuis embedded_documents.json\n",
      "\n",
      "============================================================\n",
      "ðŸ“¤ INDEXATION PINECONE\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Traitement namespace : news\n",
      "\n",
      "ðŸ“¤ Upsert vers namespace 'news'...\n",
      "   109 vecteurs en 2 batches\n",
      "   âœ… Batch 1/2 envoyÃ©\n",
      "   âœ… Batch 2/2 envoyÃ©\n",
      "\n",
      "============================================================\n",
      "âœ… INDEXATION TERMINÃ‰E\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ðŸ” VALIDATION DE L'INDEXATION\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Statistiques de l'index 'kpmg-veille' :\n",
      "   Total vecteurs : 109\n",
      "\n",
      "ðŸ“ Vecteurs par namespace :\n",
      "   - news: 109 vecteurs\n",
      "\n",
      "ðŸ§ª Test de recherche sur namespace 'news'...\n",
      "   âœ… 3 rÃ©sultats trouvÃ©s\n",
      "\n",
      "   Premier rÃ©sultat :\n",
      "   Source : press_release\n",
      "   Contenu : opens in new window\n",
      "\n",
      "Newsroom\n",
      "\n",
      "\n",
      "Latest News\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Apple Stories\n",
      "\n",
      "                    The creators, developers, and innovators leaving the world better than they found it.\n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "\n",
      "============================================================\n",
      "âœ… VALIDATION TERMINÃ‰E\n",
      "============================================================\n",
      "\n",
      "ðŸŽ¯ SystÃ¨me RAG prÃªt pour les requÃªtes (Notebook 5)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK 4 : Indexation Pinecone avec Namespaces\n",
    "=================================================\n",
    "\n",
    "OBJECTIF : Indexer les documents embeddÃ©s dans Pinecone\n",
    "           en utilisant les namespaces pour l'isolation des sources.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- Pinecone Upsert : https://docs.pinecone.io/docs/upsert-data\n",
    "- LangChain Pinecone : https://python.langchain.com/docs/integrations/vectorstores/pinecone\n",
    "- Namespaces Best Practices : https://docs.pinecone.io/docs/namespaces\n",
    "\n",
    "MÃ‰THODOLOGIE :\n",
    "1. Chargement des documents embeddÃ©s\n",
    "2. Conversion au format Pinecone\n",
    "3. Upsert par batch et namespace\n",
    "4. Validation de l'indexation\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "NOTEBOOK 4 : Indexation Pinecone avec Namespaces\n",
    "=================================================\n",
    "\n",
    "OBJECTIF : Indexer les documents embeddÃ©s dans Pinecone\n",
    "           en utilisant les namespaces pour l'isolation des sources.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- Pinecone Upsert : https://docs.pinecone.io/docs/upsert-data\n",
    "- LangChain Pinecone : https://python.langchain.com/docs/integrations/vectorstores/pinecone\n",
    "- Namespaces Best Practices : https://docs.pinecone.io/docs/namespaces\n",
    "\n",
    "MÃ‰THODOLOGIE :\n",
    "1. Chargement des documents embeddÃ©s\n",
    "2. Conversion au format Pinecone\n",
    "3. Upsert par batch et namespace\n",
    "4. Validation de l'indexation\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Pinecone\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 1 : INITIALISATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "INDEX_NAME = \"kpmg-veille\"\n",
    "\n",
    "if not PINECONE_API_KEY or not MISTRAL_API_KEY:\n",
    "    raise ValueError(\"âŒ ClÃ©s API manquantes dans .env\")\n",
    "\n",
    "# Clients\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "embeddings_model = MistralAIEmbeddings(\n",
    "    model=\"mistral-embed\",\n",
    "    mistral_api_key=MISTRAL_API_KEY\n",
    ")\n",
    "\n",
    "print(\"âœ… Clients Pinecone et Mistral initialisÃ©s\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 2 : CHARGEMENT DES DOCUMENTS EMBEDDÃ‰S\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def load_embedded_documents() -> Dict[str, List[Document]]:\n",
    "    \"\"\"Charge les documents avec leurs embeddings depuis le Notebook 3\"\"\"\n",
    "    try:\n",
    "        with open(\"embedded_documents.json\", \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        docs_by_ns = {}\n",
    "        for namespace, docs_data in data.items():\n",
    "            docs_by_ns[namespace] = [\n",
    "                Document(\n",
    "                    page_content=d[\"page_content\"],\n",
    "                    metadata={\n",
    "                        **d[\"metadata\"],\n",
    "                        \"embedding\": d[\"embedding\"]\n",
    "                    }\n",
    "                )\n",
    "                for d in docs_data\n",
    "            ]\n",
    "        \n",
    "        total = sum(len(docs) for docs in docs_by_ns.values())\n",
    "        print(f\"âœ… {total} documents chargÃ©s depuis embedded_documents.json\")\n",
    "        \n",
    "        return docs_by_ns\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Fichier 'embedded_documents.json' introuvable.\")\n",
    "        print(\"   ExÃ©cutez d'abord le Notebook 3 (chunking & embeddings)\")\n",
    "        return {}\n",
    "\n",
    "docs_by_namespace = load_embedded_documents()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 3 : PRÃ‰PARATION DES VECTEURS POUR PINECONE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "FORMAT PINECONE UPSERT\n",
    "\n",
    "Structure requise :\n",
    "{\n",
    "    \"id\": \"unique_id\",\n",
    "    \"values\": [0.1, 0.2, ...],  # Embedding (liste de 1024 floats)\n",
    "    \"metadata\": {...}            # MÃ©tadonnÃ©es (max 40 KB par vecteur)\n",
    "}\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://docs.pinecone.io/docs/upsert-data\n",
    "\"\"\"\n",
    "\n",
    "def prepare_vectors_for_pinecone(documents: List[Document], namespace: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Convertit les Documents au format Pinecone\n",
    "    \n",
    "    Args:\n",
    "        documents: Documents avec embeddings\n",
    "        namespace: Namespace de destination\n",
    "    \n",
    "    Returns:\n",
    "        Liste de vecteurs au format Pinecone\n",
    "    \"\"\"\n",
    "    vectors = []\n",
    "    \n",
    "    for i, doc in enumerate(documents):\n",
    "        # GÃ©nÃ©rer un ID unique\n",
    "        vector_id = f\"{namespace}_{i}_{int(time.time())}\"\n",
    "        \n",
    "        # Extraire l'embedding\n",
    "        embedding = doc.metadata.pop(\"embedding\", None)\n",
    "        \n",
    "        if not embedding:\n",
    "            print(f\"âš ï¸  Document {i} sans embedding, ignorÃ©\")\n",
    "            continue\n",
    "        \n",
    "        # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "        # â•‘ NETTOYAGE CRITIQUE POUR PINECONE                          â•‘\n",
    "        # â•‘ Pinecone refuse les valeurs None et les types complexes  â•‘\n",
    "        # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        \n",
    "        clean_metadata = {}\n",
    "        for k, v in doc.metadata.items():\n",
    "            # Ignorer l'embedding (dÃ©jÃ  extrait)\n",
    "            if k == \"embedding\":\n",
    "                continue\n",
    "            \n",
    "            # Remplacer None par \"Unknown\"\n",
    "            if v is None:\n",
    "                clean_metadata[k] = \"Unknown\"\n",
    "            \n",
    "            # Garder les types primitifs\n",
    "            elif isinstance(v, (str, int, float, bool)):\n",
    "                # Limiter les strings Ã  500 caractÃ¨res\n",
    "                if isinstance(v, str):\n",
    "                    clean_metadata[k] = v[:500]\n",
    "                else:\n",
    "                    clean_metadata[k] = v\n",
    "            \n",
    "            # Convertir les listes en strings\n",
    "            elif isinstance(v, list):\n",
    "                clean_metadata[k] = [str(x) for x in v if x is not None]\n",
    "            \n",
    "            # Fallback : conversion en string pour les objets complexes\n",
    "            else:\n",
    "                clean_metadata[k] = str(v)[:500]\n",
    "        \n",
    "        # Ajouter le contenu dans les mÃ©tadonnÃ©es\n",
    "        clean_metadata[\"text\"] = doc.page_content[:1000]\n",
    "        \n",
    "        vector = {\n",
    "            \"id\": vector_id,\n",
    "            \"values\": embedding,\n",
    "            \"metadata\": clean_metadata\n",
    "        }\n",
    "        \n",
    "        vectors.append(vector)\n",
    "    \n",
    "    return vectors\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 4 : UPSERT PAR BATCH ET NAMESPACE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "STRATÃ‰GIE D'UPSERT\n",
    "\n",
    "1. Traiter par batch de 100 vecteurs (limite Pinecone)\n",
    "2. Utiliser les namespaces pour isoler les sources\n",
    "3. GÃ©rer les erreurs et retry\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://docs.pinecone.io/docs/upsert-data#batching-upserts\n",
    "\"\"\"\n",
    "\n",
    "def upsert_to_pinecone(vectors: List[Dict], namespace: str, batch_size: int = 100):\n",
    "    \"\"\"\n",
    "    Envoie les vecteurs vers Pinecone par batch\n",
    "    \n",
    "    Args:\n",
    "        vectors: Vecteurs au format Pinecone\n",
    "        namespace: Namespace de destination\n",
    "        batch_size: Taille des batches\n",
    "    \"\"\"\n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    total_batches = (len(vectors) + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"\\nðŸ“¤ Upsert vers namespace '{namespace}'...\")\n",
    "    print(f\"   {len(vectors)} vecteurs en {total_batches} batches\")\n",
    "    \n",
    "    for i in range(0, len(vectors), batch_size):\n",
    "        batch = vectors[i:i+batch_size]\n",
    "        batch_num = i // batch_size + 1\n",
    "        \n",
    "        try:\n",
    "            index.upsert(\n",
    "                vectors=batch,\n",
    "                namespace=namespace\n",
    "            )\n",
    "            print(f\"   âœ… Batch {batch_num}/{total_batches} envoyÃ©\")\n",
    "            \n",
    "            # Rate limiting (10 req/sec max pour Pinecone gratuit)\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Erreur batch {batch_num}: {e}\")\n",
    "            # Retry une fois\n",
    "            try:\n",
    "                time.sleep(1)\n",
    "                index.upsert(vectors=batch, namespace=namespace)\n",
    "                print(f\"   âœ… Retry rÃ©ussi pour batch {batch_num}\")\n",
    "            except Exception as e2:\n",
    "                print(f\"   âŒ Retry Ã©chouÃ© : {e2}\")\n",
    "                continue\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 5 : INDEXATION COMPLÃˆTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def index_all_documents():\n",
    "    \"\"\"Pipeline complet d'indexation\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“¤ INDEXATION PINECONE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not docs_by_namespace:\n",
    "        print(\"âŒ Aucun document Ã  indexer\")\n",
    "        return\n",
    "    \n",
    "    for namespace, documents in docs_by_namespace.items():\n",
    "        if not documents:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nðŸ“ Traitement namespace : {namespace}\")\n",
    "        \n",
    "        # PrÃ©paration des vecteurs\n",
    "        vectors = prepare_vectors_for_pinecone(documents, namespace)\n",
    "        \n",
    "        if vectors:\n",
    "            # Upsert vers Pinecone\n",
    "            upsert_to_pinecone(vectors, namespace)\n",
    "        else:\n",
    "            print(f\"   âš ï¸  Aucun vecteur valide pour {namespace}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… INDEXATION TERMINÃ‰E\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 6 : VALIDATION POST-INDEXATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "VALIDATION :\n",
    "- VÃ©rifier le nombre de vecteurs indexÃ©s\n",
    "- Tester une recherche simple\n",
    "- Confirmer l'isolation des namespaces\n",
    "\"\"\"\n",
    "\n",
    "def validate_indexation():\n",
    "    \"\"\"Valide que l'indexation s'est bien passÃ©e\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ” VALIDATION DE L'INDEXATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    stats = index.describe_index_stats()\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Statistiques de l'index '{INDEX_NAME}' :\")\n",
    "    print(f\"   Total vecteurs : {stats.total_vector_count}\")\n",
    "    print(f\"\\nðŸ“ Vecteurs par namespace :\")\n",
    "    \n",
    "    for namespace, info in stats.namespaces.items():\n",
    "        print(f\"   - {namespace}: {info.vector_count} vecteurs\")\n",
    "    \n",
    "    # Test de recherche\n",
    "    print(\"\\nðŸ§ª Test de recherche sur namespace 'news'...\")\n",
    "    \n",
    "    try:\n",
    "        vectorstore = PineconeVectorStore(\n",
    "            index_name=INDEX_NAME,\n",
    "            embedding=embeddings_model,\n",
    "            namespace=\"news\"\n",
    "        )\n",
    "        \n",
    "        results = vectorstore.similarity_search(\n",
    "            \"latest technology news\",\n",
    "            k=3\n",
    "        )\n",
    "        \n",
    "        print(f\"   âœ… {len(results)} rÃ©sultats trouvÃ©s\")\n",
    "        \n",
    "        if results:\n",
    "            print(f\"\\n   Premier rÃ©sultat :\")\n",
    "            print(f\"   Source : {results[0].metadata.get('source')}\")\n",
    "            print(f\"   Contenu : {results[0].page_content[:200]}...\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Erreur de recherche : {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… VALIDATION TERMINÃ‰E\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 7 : EXÃ‰CUTION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Indexation\n",
    "    index_all_documents()\n",
    "    \n",
    "    # Validation\n",
    "    time.sleep(2)  # Laisser Pinecone finaliser l'indexation\n",
    "    validate_indexation()\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ SystÃ¨me RAG prÃªt pour les requÃªtes (Notebook 5)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faut il Nettoyer les mÃ©tadonnÃ©es avant dâ€™upser ?\n",
    "\n",
    "Pour identifier l'erreur, donner le requirement, l'env et le notebook a claude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ModÃ¨les Mistral initialisÃ©s\n",
      "âœ… Prompt KPMG configurÃ©\n",
      "\n",
      "============================================================\n",
      "ðŸ” ANALYSE EN COURS...\n",
      "============================================================\n",
      "Question : Quelles sont les derniÃ¨res informations sur Apple ?\n",
      "Namespace : Tous (recherche globale)\n",
      "============================================================\n",
      "\n",
      "**Analyse stratÃ©gique des derniÃ¨res Ã©volutions dâ€™Apple (juin 2024)**\n",
      "\n",
      "Apple Inc. (AAPL) traverse une pÃ©riode charniÃ¨re marquÃ©e par des dÃ©fis macroÃ©conomiques, des innovations technologiques et des ajustements stratÃ©giques. Voici une synthÃ¨se des dÃ©veloppements rÃ©cents, structurÃ©e selon les axes financiers, produits, rÃ©glementaires et concurrentiels, avec une attention particuliÃ¨re aux signaux actionnables pour les investisseurs.\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Performance financiÃ¨re et perspectives : un ralentissement contrastÃ©**\n",
      "Les rÃ©sultats du **second trimestre 2024** (clÃ´turÃ© le 30 mars) ont rÃ©vÃ©lÃ© une **baisse de 4,3 % du chiffre dâ€™affaires** en glissement annuel, Ã  **90,8 milliards de dollars**, principalement due au recul des ventes dâ€™iPhone (-10 % Ã  45,9 milliards) et de Mac (-27 % Ã  7,5 milliards) [SEC Filing 10-Q Apple | â­â­â­ | 2024-05-02]. Ce dÃ©clin sâ€™explique par un **cycle de renouvellement des iPhone plus long** (15 % des utilisateurs conservent leur appareil plus de 4 ans, contre 10 % en 2020) [Counterpoint Research | â­â­ | 2024-04-18] et une **demande atone en Chine**, oÃ¹ les ventes ont chutÃ© de **13 %** sur un an [IDC | â­â­ | 2024-05-10]. Ã€ lâ€™inverse, le segment **Services** (Apple TV+, Apple Music, iCloud) a progressÃ© de **14 %** Ã  23,9 milliards, reprÃ©sentant dÃ©sormais **26 % du CA total** â€“ un record historique [SEC Filing 10-Q Apple | â­â­â­ | 2024-05-02].\n",
      "\n",
      "**Perspectives 2024** : Apple anticipe une **reprise modÃ©rÃ©e au T3**, portÃ©e par :\n",
      "- Le lancement attendu de lâ€™**iPhone 16** en septembre, avec des rumeurs persistantes sur une **IA embarquÃ©e** (partenariat avec Google Gemini ou dÃ©veloppement interne) [Bloomberg | â­â­ | 2024-06-05].\n",
      "- Lâ€™**expansion des services financiers**, notamment la carte Apple Card (dÃ©sormais disponible dans 12 pays) et le service \"Buy Now, Pay Later\" (BNPL) [Apple Press Release | â­â­â­ | 2024-05-20].\n",
      "- Une **accÃ©lÃ©ration en Inde**, oÃ¹ Apple a ouvert deux nouveaux magasins (Mumbai et Delhi) et oÃ¹ les ventes ont bondi de **33 %** en 2023 [Counterpoint Research | â­â­ | 2024-01-30].\n",
      "\n",
      "**Risques** : La **guerre commerciale sino-amÃ©ricaine** (restrictions sur les puces TSMC) et la **concurrence agressive de Huawei** en Chine (part de marchÃ© de 17 % au T1 2024, contre 15 % pour Apple) [Canalys | â­â­ | 2024-04-25] pourraient peser sur les marges.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Innovation produit : lâ€™IA et la rÃ©alitÃ© mixte en premiÃ¨re ligne**\n",
      "Apple a officiellement annoncÃ© son entrÃ©e dans lâ€™**Ã¨re de lâ€™IA gÃ©nÃ©rative** lors de la WWDC 2024 (3â€“7 juin), avec :\n",
      "- **\"Apple Intelligence\"** : une couche dâ€™IA intÃ©grÃ©e Ã  iOS 18, macOS 15 et iPadOS 18, incluant des fonctionnalitÃ©s comme la **rÃ©Ã©criture de textes**, la **gÃ©nÃ©ration dâ€™images** (via un partenariat avec Adobe Firefly), et un **assistant vocal amÃ©liorÃ©** (Siri 2.0) [Apple Keynote WWDC 2024 | â­â­â­ | 2024-06-10]. Contrairement Ã  Microsoft (Copilot) ou Google (Gemini), Apple mise sur une **approche \"privacy-first\"**, avec un traitement des donnÃ©es majoritairement en local (via des modÃ¨les lÃ©gers exÃ©cutÃ©s sur les puces M-series).\n",
      "- **Vision Pro** : MalgrÃ© un lancement commercial mitigÃ© (seulement **200 000 unitÃ©s vendues** au T1 2024, selon Ming-Chi Kuo) [Medium (Ming-Chi Kuo) | â­ | 2024-05-15], Apple prÃ©pare une **version 2** pour 2025, avec un design plus lÃ©ger et un prix rÃ©duit (estimÃ© Ã  **2 500 $**, contre 3 500 $ actuellement) [The Information | â­â­ | 2024-06-01].\n",
      "\n",
      "**Analyse** : Ces mouvements confirment la stratÃ©gie dâ€™Apple de **monÃ©tiser lâ€™Ã©cosystÃ¨me** (hardware + services) plutÃ´t que de vendre des licences logicielles. Lâ€™IA pourrait ajouter **5 Ã  10 % de croissance annuelle aux Services** dâ€™ici 2026 [Morgan Stanley Research | â­â­ | 2024-05-22].\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Enjeux rÃ©glementaires : entre pressions antitrust et opportunitÃ©s**\n",
      "Apple fait face Ã  deux dÃ©fis majeurs :\n",
      "- **Loi sur les marchÃ©s numÃ©riques (DMA) en UE** : La Commission europÃ©enne a infligÃ© une **amende de 1,8 milliard dâ€™euros** pour pratiques anticoncurrentielles (restrictions sur les stores alternatifs et les paiements tiers) [European Commission Press Release | â­â­â­ | 2024-03-04]. Apple a annoncÃ© des changements (ouverture partielle du sideloading, rÃ©duction des commissions Ã  17 % pour les petits dÃ©veloppeurs), mais ces mesures sont jugÃ©es **insuffisantes** par les rÃ©gulateurs [Reuters | â­â­ | 2024-06-08].\n",
      "- **ProcÃ¨s Epic Games vs. Apple** : La Cour suprÃªme amÃ©ricaine a refusÃ© dâ€™examiner lâ€™appel dâ€™Apple, confirmant le jugement de 2021 qui lâ€™oblige Ã  autoriser les **liens vers des systÃ¨mes de paiement externes** dans les apps [Supreme Court Order | â­â­â­ | 2024-04-22]. Cela pourrait rÃ©duire les **commissions de lâ€™App Store** (actuellement 15â€“30 %) de **1 Ã  3 points de pourcentage** [Bernstein Research | â­â­ | 2024-05-05].\n",
      "\n",
      "**Impact** : Ces rÃ©glementations pourraient **Ã©roder les marges des Services** (38 % de marge en 2023) [SEC Filing 10-K | â­â­â­ | 2023-11-03], mais Apple compense en dÃ©veloppant des **services premium** (ex : Apple One Premier Ã  32,95 $/mois).\n",
      "\n",
      "---\n",
      "\n",
      "### **4. Dynamique concurrentielle : guerre des Ã©cosystÃ¨mes**\n",
      "- **Vs. Microsoft** : La bataille de lâ€™IA sâ€™intensifie avec lâ€™intÃ©gration de **Copilot+** dans Windows 11 (modÃ¨les locaux via Qualcomm) [Microsoft Build 2024 | â­â­â­ | 2024-05-20]. Apple rÃ©pond avec son **approche \"on-device AI\"**, plus respectueuse de la vie privÃ©e mais techniquement limitÃ©e (modÃ¨les moins puissants que ceux de Microsoft/Google).\n",
      "- **Vs. Google** : Le partenariat avec **Google Gemini** pour lâ€™iPhone 16 (selon des fuites) [The Verge | â­â­ | 2024-06-07] serait un revirement stratÃ©gique, Apple ayant historiquement Ã©vitÃ© les alliances avec les GAFAM. Cela pourrait **accÃ©lÃ©rer lâ€™adoption de lâ€™IA** mais expose Apple Ã  des risques de dÃ©pendance.\n",
      "- **Vs. Huawei/Mate 60 Pro** : En Chine, le **Mate 60 Pro** (avec puce Kirin 9000s, 7 nm) a captÃ© **12 % du marchÃ© premium** au T1 2024, grÃ¢ce Ã  un prix infÃ©rieur de 30 % Ã  lâ€™iPhone 15 Pro [Counterpoint Research | â­â­ | 2024-04-18]. Apple rÃ©pond avec des **subventions aux revendeurs chinois** et des **offres de trade-in agressives**.\n",
      "\n",
      "---\n",
      "### **5. OpportunitÃ©s dâ€™investissement et risques clÃ©s**\n",
      "**Signaux positifs** :\n",
      "- **Dividende et rachats dâ€™actions** : Apple a augmentÃ© son dividende de **4 %** (0,24 $/action) et autorisÃ© **110 milliards de dollars** de rachats supplÃ©mentaires [Apple Press Release | â­â­â­ | 2024-05-02], signalant une confiance dans sa trÃ©sorerie (216 milliards de dollars en cash) [SEC Filing 10-Q | â­â­â­ | 2024-05-02].\n",
      "- **Diversification gÃ©ographique** : Lâ€™Inde pourrait reprÃ©senter **15 % de la production dâ€™iPhone dâ€™ici 2025** (contre 7 % aujourdâ€™hui) [JP Morgan | â­â­ | 2024-03-10], rÃ©duisant la dÃ©pendance Ã  la Chine.\n",
      "\n",
      "**Risques** :\n",
      "- **Saturation du marchÃ© des smartphones** : Le taux de pÃ©nÃ©tration des iPhone atteint **85 % aux Ã‰tats-Unis** [Consumer Intelligence Research Partners | â­â­ | 2024-04-01], limitant la croissance organique.\n",
      "- **DÃ©pendance Ã  la Chine** : 19 % du CA dâ€™Apple provient de Chine [SEC Filing 10-K | â­â­â­ | 2023-11-03], exposÃ©e aux tensions gÃ©opolitiques et Ã  la concurrence locale.\n",
      "\n",
      "---\n",
      "### **Recommandations stratÃ©giques**\n",
      "1. **Surveiller lâ€™adoption de lâ€™IA** : Le succÃ¨s dâ€™**Apple Intelligence** (disponible en bÃªta en juin 2024) sera un catalyseur clÃ© pour les Services. Un taux de pÃ©nÃ©tration > 20 % dâ€™ici fin 2024 serait un signal fort.\n",
      "2. **Ã‰valuer lâ€™impact du DMA** : Les changements dans lâ€™App Store pourraient rÃ©duire les revenus des Services de **2 Ã  5 %** [Goldman Sachs | â­â­ | 2024-05-15]. Ã€ suivre : lâ€™Ã©volution des commissions en 2025.\n",
      "3. **Anticiper le cycle iPhone 16** : Si les rumeurs dâ€™IA embarquÃ©e se confirment, un **supercycle de renouvellement** (comme en 2020 avec la 5G) pourrait booster les ventes de **10 Ã  15 %** [Wedbush Securities | â­â­ | 2024-06-03].\n",
      "4. **Diversification sectorielle** : Apple accÃ©lÃ¨re dans la **santÃ©** (Apple Watch avec capteurs de glycÃ©mie) et la **finance** (comptes dâ€™Ã©pargne Apple Card Ã  4,5 % APY). Ces segments pourraient reprÃ©senter **10 % du CA dâ€™ici 2030** [KPMG Analysis | â­â­ | 2024-06-10].\n",
      "\n",
      "---\n",
      "**Sources complÃ©mentaires disponibles sur demande** (rapports payants : Gartner, IDC, Bernstein). Souhaitez-vous une analyse approfondie sur un axe spÃ©cifique (ex : supply chain, R&D, ESG) ?\n",
      "\n",
      "âœ… SystÃ¨me RAG KPMG opÃ©rationnel\n",
      "ðŸŽ¯ PrÃªt pour l'interface Gradio (optionnel)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK 5 : RAG Query & Prompt Engineering pour Veille KPMG\n",
    "============================================================\n",
    "\n",
    "OBJECTIF : CrÃ©er un systÃ¨me de requÃªtes RAG optimisÃ© pour la veille stratÃ©gique\n",
    "           avec prompting avancÃ© et citations obligatoires.\n",
    "\n",
    "RÃ‰FÃ‰RENCES :\n",
    "- Mistral Prompting : https://docs.mistral.ai/guides/prompting_capabilities/\n",
    "- LangChain RAG : https://python.langchain.com/docs/use_cases/question_answering/\n",
    "- KPMG Requirements : hackathon KPMG (1).pdf\n",
    "\n",
    "EXIGENCES CRITIQUES :\n",
    "âœ“ Citations systÃ©matiques des sources\n",
    "âœ“ Indication de fiabilitÃ© et date\n",
    "âœ“ RÃ©ponses structurÃ©es (pas de bullet points sauf demande explicite)\n",
    "âœ“ IA explicable (chaÃ®ne de raisonnement)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 1 : INITIALISATION DES COMPOSANTS RAG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "INDEX_NAME = \"kpmg-veille\"\n",
    "\n",
    "# ModÃ¨le d'embeddings\n",
    "embeddings = MistralAIEmbeddings(\n",
    "    model=\"mistral-embed\",\n",
    "    mistral_api_key=MISTRAL_API_KEY\n",
    ")\n",
    "\n",
    "# ModÃ¨le LLM (Mistral Medium pour raisonnement)\n",
    "llm = ChatMistralAI(\n",
    "    model=\"mistral-medium\",\n",
    "    temperature=0,  # DÃ©terministe pour analyses factuelles\n",
    "    mistral_api_key=MISTRAL_API_KEY\n",
    ")\n",
    "\n",
    "print(\"âœ… ModÃ¨les Mistral initialisÃ©s\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 2 : RETRIEVERS PAR NAMESPACE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "STRATÃ‰GIE DE RETRIEVAL\n",
    "\n",
    "On crÃ©e un retriever par namespace pour permettre des requÃªtes ciblÃ©es.\n",
    "L'utilisateur peut spÃ©cifier le namespace ou interroger tous les namespaces.\n",
    "\n",
    "PARAMÃˆTRES :\n",
    "- k=5 : Top 5 documents les plus pertinents\n",
    "- score_threshold : Filtrage par similaritÃ© (optionnel)\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://python.langchain.com/docs/modules/data_connection/retrievers/\n",
    "\"\"\"\n",
    "\n",
    "NAMESPACES = [\n",
    "    \"financial_reports\",\n",
    "    \"news\",\n",
    "    \"macro_data\"\n",
    "]\n",
    "\n",
    "def get_retriever(namespace: Optional[str] = None, k: int = 5):\n",
    "    \"\"\"\n",
    "    CrÃ©e un retriever pour un namespace spÃ©cifique ou global\n",
    "    \n",
    "    Args:\n",
    "        namespace: Namespace ciblÃ© (None = tous les namespaces)\n",
    "        k: Nombre de documents Ã  rÃ©cupÃ©rer\n",
    "    \n",
    "    Returns:\n",
    "        Retriever configurÃ©\n",
    "    \"\"\"\n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=embeddings,\n",
    "        namespace=namespace  # None = recherche sur tous les namespaces\n",
    "    )\n",
    "    \n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": k}\n",
    "    )\n",
    "    \n",
    "    return retriever\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 3 : PROMPT ENGINEERING KPMG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "PROMPT STRUCTURÃ‰ SELON LES EXIGENCES KPMG\n",
    "\n",
    "InspirÃ© de vos notes (hackathon KPMG.pdf) :\n",
    "âœ“ Assistant Intelligent de Veille StratÃ©gique\n",
    "âœ“ Citations OBLIGATOIRES avec source, date, fiabilitÃ©\n",
    "âœ“ RÃ©ponse en prose (pas de bullet points par dÃ©faut)\n",
    "âœ“ Indication si donnÃ©es manquantes ou payantes\n",
    "âœ“ CapacitÃ© Ã  demander des prÃ©cisions\n",
    "\n",
    "STRUCTURE :\n",
    "1. RÃ´le et expertise\n",
    "2. Instructions de citation\n",
    "3. Format de rÃ©ponse\n",
    "4. Gestion des cas limites\n",
    "\"\"\"\n",
    "\n",
    "KPMG_PROMPT_TEMPLATE = \"\"\"Vous Ãªtes l'Assistant Intelligent de Veille StratÃ©gique de KPMG Global Strategy Group.\n",
    "\n",
    "Votre mission : Fournir des analyses de marchÃ© prÃ©cises, sourcÃ©es et actionnables pour aider nos clients Ã  prendre des dÃ©cisions d'investissement Ã©clairÃ©es.\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "RÃˆGLES DE CITATION (OBLIGATOIRES)\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "Pour CHAQUE information factuelle (chiffres, dates, faits) vous DEVEZ :\n",
    "1. Citer la source exacte (ex: \"SEC Filing 10-K d'Apple - 2024-01-15\")\n",
    "2. Indiquer le niveau de fiabilitÃ© :\n",
    "   - â­â­â­ : Source primaire (SEC, rapport officiel, yfinance)\n",
    "   - â­â­ : Source secondaire fiable (NewsAPI, presse reconnue)\n",
    "   - â­ : Source tertiaire (blogs, rÃ©seaux sociaux)\n",
    "3. PrÃ©ciser la date de l'information si critique\n",
    "\n",
    "Format de citation : [Source | FiabilitÃ© | Date]\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "CONTEXTE DISPONIBLE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "{context}\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "QUESTION DU CLIENT\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "{question}\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "INSTRUCTIONS DE RÃ‰PONSE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "1. STRUCTURE :\n",
    "   - RÃ©pondez en prose fluide (paragraphes, pas de bullet points)\n",
    "   - Organisez votre rÃ©ponse de faÃ§on logique et narrative\n",
    "   - Utilisez des transitions naturelles entre les idÃ©es\n",
    "\n",
    "2. CONTENU :\n",
    "   - Citez systÃ©matiquement vos sources (format ci-dessus)\n",
    "   - Si une donnÃ©e est manquante : indiquez-le explicitement\n",
    "   - Si une information nÃ©cessite un accÃ¨s payant : prÃ©cisez-le\n",
    "   - Si le contexte est ambigu : demandez des prÃ©cisions au client\n",
    "\n",
    "3. TONE :\n",
    "   - Professionnel mais accessible\n",
    "   - Factuel et analytique\n",
    "   - Confiant sur les donnÃ©es sourcÃ©es, prudent sur les spÃ©culations\n",
    "\n",
    "4. CAS LIMITES :\n",
    "   - Si vous ne trouvez pas l'information : \"Les donnÃ©es disponibles ne permettent pas de rÃ©pondre Ã  cette question. Sources consultÃ©es : [liste]. Je recommande [action].\"\n",
    "   - Si deux sources se contredisent : Mentionnez les deux et expliquez pourquoi\n",
    "   - Si une entreprise est ambiguÃ« : \"J'ai identifiÃ© plusieurs entreprises nommÃ©es [X]. Pouvez-vous prÃ©ciser : secteur, gÃ©ographie, ou autre contexte ?\"\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "RÃ‰PONSE ANALYTIQUE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(KPMG_PROMPT_TEMPLATE)\n",
    "\n",
    "print(\"âœ… Prompt KPMG configurÃ©\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 4 : FORMATAGE DU CONTEXTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "FORMATAGE DES DOCUMENTS RÃ‰CUPÃ‰RÃ‰S\n",
    "\n",
    "On enrichit le contexte avec :\n",
    "- Source et type de document\n",
    "- Date de publication/scraping\n",
    "- Namespace d'origine\n",
    "- Score de pertinence (si disponible)\n",
    "\"\"\"\n",
    "\n",
    "def format_docs(docs) -> str:\n",
    "    \"\"\"\n",
    "    Formate les documents rÃ©cupÃ©rÃ©s pour le prompt\n",
    "    \n",
    "    Args:\n",
    "        docs: Documents LangChain\n",
    "    \n",
    "    Returns:\n",
    "        String formatÃ© avec mÃ©tadonnÃ©es enrichies\n",
    "    \"\"\"\n",
    "    formatted = []\n",
    "    \n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        metadata = doc.metadata\n",
    "        \n",
    "        # Construction de l'entrÃ©e\n",
    "        entry = f\"â”â”â” DOCUMENT {i} â”â”â”\\n\"\n",
    "        entry += f\"Source : {metadata.get('source', 'Unknown')}\\n\"\n",
    "        entry += f\"Type : {metadata.get('namespace', 'Unknown')}\\n\"\n",
    "        \n",
    "        # Date si disponible\n",
    "        date_fields = ['filing_date', 'published_at', 'scrape_date', 'retrieval_date']\n",
    "        for field in date_fields:\n",
    "            if field in metadata:\n",
    "                entry += f\"Date : {metadata[field]}\\n\"\n",
    "                break\n",
    "        \n",
    "        # URL si disponible\n",
    "        if 'url' in metadata:\n",
    "            entry += f\"URL : {metadata['url']}\\n\"\n",
    "        \n",
    "        # Contenu\n",
    "        entry += f\"\\nContenu :\\n{doc.page_content}\\n\"\n",
    "        \n",
    "        formatted.append(entry)\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 5 : CHAÃŽNE RAG COMPLÃˆTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "ARCHITECTURE LCEL (LangChain Expression Language)\n",
    "\n",
    "Pipeline : Retriever â†’ Format Context â†’ Prompt â†’ LLM â†’ Parse\n",
    "\n",
    "RÃ‰FÃ‰RENCE :\n",
    "https://python.langchain.com/docs/expression_language/\n",
    "\"\"\"\n",
    "\n",
    "def create_rag_chain(namespace: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    CrÃ©e une chaÃ®ne RAG complÃ¨te\n",
    "    \n",
    "    Args:\n",
    "        namespace: Namespace ciblÃ© (None = tous)\n",
    "    \n",
    "    Returns:\n",
    "        ChaÃ®ne RAG exÃ©cutable\n",
    "    \"\"\"\n",
    "    retriever = get_retriever(namespace=namespace, k=5)\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\n",
    "            \"context\": retriever | format_docs,\n",
    "            \"question\": RunnablePassthrough()\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    return rag_chain\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 6 : INTERFACE DE REQUÃŠTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "FONCTIONS D'INTERFACE UTILISATEUR\n",
    "\n",
    "Permettent d'interroger le systÃ¨me de diffÃ©rentes maniÃ¨res :\n",
    "- RequÃªte simple (tous namespaces)\n",
    "- RequÃªte ciblÃ©e (namespace spÃ©cifique)\n",
    "- RequÃªte multi-namespaces (comparaison)\n",
    "\"\"\"\n",
    "\n",
    "def query_veille(question: str, namespace: Optional[str] = None) -> str:\n",
    "    \"\"\"\n",
    "    Interface principale de requÃªte\n",
    "    \n",
    "    Args:\n",
    "        question: Question de l'utilisateur\n",
    "        namespace: Namespace ciblÃ© (optionnel)\n",
    "    \n",
    "    Returns:\n",
    "        RÃ©ponse formatÃ©e avec citations\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ” ANALYSE EN COURS...\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Question : {question}\")\n",
    "    \n",
    "    if namespace:\n",
    "        print(f\"Namespace : {namespace}\")\n",
    "    else:\n",
    "        print(\"Namespace : Tous (recherche globale)\")\n",
    "    \n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    try:\n",
    "        chain = create_rag_chain(namespace)\n",
    "        response = chain.invoke(question)\n",
    "        return response\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"âŒ Erreur lors de la requÃªte : {e}\"\n",
    "\n",
    "def compare_namespaces(question: str, namespaces: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Compare les rÃ©ponses de plusieurs namespaces\n",
    "    \n",
    "    Args:\n",
    "        question: Question\n",
    "        namespaces: Liste de namespaces Ã  comparer\n",
    "    \n",
    "    Returns:\n",
    "        Dictionnaire {namespace: rÃ©ponse}\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for ns in namespaces:\n",
    "        print(f\"\\nðŸ“ Interrogation de '{ns}'...\")\n",
    "        results[ns] = query_veille(question, namespace=ns)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 7 : EXEMPLES D'UTILISATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "\"\"\"\n",
    "SCÃ‰NARIOS DE DÃ‰MONSTRATION KPMG\n",
    "\n",
    "Ces exemples illustrent les capacitÃ©s du systÃ¨me :\n",
    "1. Analyse de marchÃ©\n",
    "2. Due diligence d'entreprise\n",
    "3. DÃ©tection de tendances\n",
    "4. Analyse concurrentielle\n",
    "\"\"\"\n",
    "\n",
    "def demo_scenarios():\n",
    "    \"\"\"DÃ©montre les capacitÃ©s du systÃ¨me avec des cas rÃ©els\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"ðŸŽ¯ \"*20)\n",
    "    print(\" DÃ‰MONSTRATION RAG VEILLE KPMG\")\n",
    "    print(\"ðŸŽ¯ \"*20 + \"\\n\")\n",
    "    \n",
    "    scenarios = [\n",
    "        {\n",
    "            \"titre\": \"1. ANALYSE FINANCIÃˆRE D'ENTREPRISE\",\n",
    "            \"question\": \"Quelle est la capitalisation boursiÃ¨re actuelle d'Apple et son Ã©volution ?\",\n",
    "            \"namespace\": \"macro_data\"\n",
    "        },\n",
    "        {\n",
    "            \"titre\": \"2. VEILLE ACTUALITÃ‰S SECTEUR TECH\",\n",
    "            \"question\": \"Quelles sont les derniÃ¨res actualitÃ©s concernant l'intelligence artificielle et la finance ?\",\n",
    "            \"namespace\": \"news\"\n",
    "        },\n",
    "        {\n",
    "            \"titre\": \"3. RECHERCHE GLOBALE (TOUS NAMESPACES)\",\n",
    "            \"question\": \"Quels sont les principaux risques et opportunitÃ©s pour les entreprises tech en 2024 ?\",\n",
    "            \"namespace\": None\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        print(\"\\n\" + \"â”€\"*60)\n",
    "        print(f\"ðŸ“Š {scenario['titre']}\")\n",
    "        print(\"â”€\"*60)\n",
    "        \n",
    "        response = query_veille(\n",
    "            question=scenario['question'],\n",
    "            namespace=scenario['namespace']\n",
    "        )\n",
    "        \n",
    "        print(\"\\nðŸ’¡ RÃ‰PONSE :\\n\")\n",
    "        print(response)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# SECTION 8 : EXÃ‰CUTION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Exemple simple\n",
    "    question = \"Quelles sont les derniÃ¨res informations sur Apple ?\"\n",
    "    response = query_veille(question)\n",
    "    print(response)\n",
    "    \n",
    "    # DÃ©commenter pour la dÃ©mo complÃ¨te\n",
    "    # demo_scenarios()\n",
    "    \n",
    "    print(\"\\nâœ… SystÃ¨me RAG KPMG opÃ©rationnel\")\n",
    "    print(\"ðŸŽ¯ PrÃªt pour l'interface Gradio (optionnel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hobby/Desktop/Python/ML_projects/langchain_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Initialisation de l'interface KPMG (mistral-small)...\n",
      "âœ… Variables d'environnement chargÃ©es\n",
      "âœ… Embeddings initialisÃ©s\n",
      "âœ… Retriever configurÃ©\n",
      "âœ… LLM Mistral Small initialisÃ©\n",
      "âœ… Prompt configurÃ©\n",
      "âœ… ChaÃ®ne RAG construite\n",
      "\n",
      "============================================================\n",
      "ðŸš€ LANCEMENT DE L'INTERFACE GRADIO\n",
      "============================================================\n",
      "\n",
      "ðŸ“Œ ModÃ¨le utilisÃ© : mistral-small (gratuit)\n",
      "ðŸ“Š Index Pinecone : 118 vecteurs disponibles\n",
      "âœ… SystÃ¨me prÃªt pour la dÃ©mo\n",
      "\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "IMPORTANT: You are using gradio version 4.0.0, however version 4.44.1 is available, please upgrade.\n",
      "--------\n",
      "\n",
      "âœ… Interface lancÃ©e avec succÃ¨s !\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GRADIO INTERFACE - VERSION AVEC MISTRAL-SMALL (GRATUIT)\n",
    "========================================================\n",
    "\n",
    "Cette version utilise mistral-small au lieu de mistral-medium.\n",
    "Performance lÃ©gÃ¨rement infÃ©rieure mais GRATUIT et SUFFISANT pour votre dÃ©mo.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_mistralai import ChatMistralAI, MistralAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# INITIALISATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"ðŸ”§ Initialisation de l'interface KPMG (mistral-small)...\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "INDEX_NAME = \"kpmg-veille\"\n",
    "\n",
    "if not MISTRAL_API_KEY or not PINECONE_API_KEY:\n",
    "    raise ValueError(\"âŒ ClÃ©s API manquantes dans .env\")\n",
    "\n",
    "print(\"âœ… Variables d'environnement chargÃ©es\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# COMPOSANTS RAG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "try:\n",
    "    # Embeddings\n",
    "    embeddings = MistralAIEmbeddings(\n",
    "        model=\"mistral-embed\",\n",
    "        mistral_api_key=MISTRAL_API_KEY\n",
    "    )\n",
    "    print(\"âœ… Embeddings initialisÃ©s\")\n",
    "    \n",
    "    # Vector Store\n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=INDEX_NAME,\n",
    "        embedding=embeddings,\n",
    "        namespace=\"news\"\n",
    "    )\n",
    "    \n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 3}\n",
    "    )\n",
    "    print(\"âœ… Retriever configurÃ©\")\n",
    "    \n",
    "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "    # â•‘ CHANGEMENT CRITIQUE : mistral-medium â†’ mistral-small    â•‘\n",
    "    # â•‘                                                           â•‘\n",
    "    # â•‘ Mistral-small est GRATUIT et suffisant pour du RAG      â•‘\n",
    "    # â•‘ Performance : 85% de mistral-medium Ã  coÃ»t zÃ©ro         â•‘\n",
    "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    \n",
    "    llm = ChatMistralAI(\n",
    "        model=\"mistral-small\",  # âœ… MODÃˆLE GRATUIT\n",
    "        temperature=0,\n",
    "        mistral_api_key=MISTRAL_API_KEY\n",
    "    )\n",
    "    print(\"âœ… LLM Mistral Small initialisÃ©\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur lors de l'initialisation : {e}\")\n",
    "    raise\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PROMPT KPMG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "KPMG_PROMPT_TEMPLATE = \"\"\"Vous Ãªtes l'Assistant Intelligent de Veille StratÃ©gique de KPMG Global Strategy Group.\n",
    "\n",
    "Votre mission : Fournir des analyses de marchÃ© prÃ©cises, sourcÃ©es et actionnables pour aider nos clients Ã  prendre des dÃ©cisions d'investissement Ã©clairÃ©es.\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "RÃˆGLES DE CITATION (OBLIGATOIRES)\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "Pour CHAQUE information factuelle (chiffres, dates, faits) vous DEVEZ :\n",
    "1. Citer la source exacte (ex: \"https://www.apple.com - 2024-01-15\")\n",
    "2. Indiquer le niveau de fiabilitÃ© :\n",
    "   - *** : Source primaire (SEC, rapport officiel, yfinance)\n",
    "   - ** : Source secondaire fiable (NewsAPI, presse reconnue)\n",
    "   - * : Source tertiaire (blogs, rÃ©seaux sociaux)\n",
    "3. PrÃ©ciser la date de l'information si critique\n",
    "\n",
    "Format de citation : [Source au format URL | FiabilitÃ© | Date]\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "CONTEXTE DISPONIBLE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "{context}\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "QUESTION DU CLIENT\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "{question}\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "INSTRUCTIONS DE RÃ‰PONSE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\n",
    "1. STRUCTURE :\n",
    "   - RÃ©pondez en prose fluide (paragraphes, pas de bullet points)\n",
    "   - Organisez votre rÃ©ponse de faÃ§on logique et narrative\n",
    "   - Utilisez des transitions naturelles entre les idÃ©es\n",
    "\n",
    "2. CONTENU :\n",
    "   - Citez systÃ©matiquement vos sources (format ci-dessus)\n",
    "   - Si une donnÃ©e est manquante : indiquez-le explicitement\n",
    "   - Si une information nÃ©cessite un accÃ¨s payant : prÃ©cisez-le\n",
    "   - Si le contexte est ambigu : demandez des prÃ©cisions au client\n",
    "\n",
    "3. TONE :\n",
    "   - Professionnel mais accessible\n",
    "   - Factuel et analytique\n",
    "   - Confiant sur les donnÃ©es sourcÃ©es, prudent sur les spÃ©culations\n",
    "\n",
    "4. CAS LIMITES :\n",
    "   - Si vous ne trouvez pas l'information : \"Les donnÃ©es disponibles ne permettent pas de rÃ©pondre Ã  cette question. Sources consultÃ©es : [liste]. Je recommande [action].\"\n",
    "   - Si deux sources se contredisent : Mentionnez les deux et expliquez pourquoi\n",
    "   - Si une entreprise est ambiguÃ« : \"J'ai identifiÃ© plusieurs entreprises nommÃ©es [X]. Pouvez-vous prÃ©ciser : secteur, gÃ©ographie, ou autre contexte ?\"\n",
    "\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "RÃ‰PONSE ANALYTIQUE\n",
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(KPMG_PROMPT_TEMPLATE )\n",
    "print(\"âœ… Prompt configurÃ©\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CHAÃŽNE RAG\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"Formate les documents rÃ©cupÃ©rÃ©s\"\"\"\n",
    "    if not docs:\n",
    "        return \"Aucun document pertinent trouvÃ©.\"\n",
    "    \n",
    "    formatted = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        date = doc.metadata.get('published_at', doc.metadata.get('scrape_date', 'N/A'))\n",
    "        content = doc.page_content[:500]\n",
    "        \n",
    "        formatted.append(f\"[Document {i} - Source: {source} - Date: {date}]\\n{content}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"âœ… ChaÃ®ne RAG construite\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FONCTION STREAMING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def stream_kpmg_response(message, history):\n",
    "    \"\"\"GÃ©nÃ¨re la rÃ©ponse de maniÃ¨re progressive\"\"\"\n",
    "    try:\n",
    "        partial_message = \"\"\n",
    "        \n",
    "        for chunk in rag_chain.stream(message):\n",
    "            partial_message += chunk\n",
    "            yield partial_message\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = f\"\"\"âŒ Erreur lors de la recherche :\n",
    "        \n",
    "DÃ©tails : {str(e)}\n",
    "\n",
    "Suggestions :\n",
    "1. VÃ©rifiez que l'index Pinecone contient des donnÃ©es (âœ… Vous avez 118 vecteurs)\n",
    "2. Testez avec une question plus simple\n",
    "3. VÃ©rifiez les crÃ©dits Mistral sur console.mistral.ai\"\"\"\n",
    "        \n",
    "        yield error_msg\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# INTERFACE GRADIO â€“ STYLE TERMINAL RÃ‰TRO\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "theme = gr.themes.Base().set(\n",
    "    body_background_fill=\"#0f0f0f\",\n",
    "    body_text_color=\"#c6f6d5\",\n",
    "    button_primary_background_fill=\"#0f0f0f\",\n",
    "    button_primary_text_color=\"#c6f6d5\",\n",
    "    input_background_fill=\"#0f0f0f\",\n",
    "    input_border_color=\"#c6f6d5\"\n",
    ")\n",
    "\n",
    "\n",
    "custom_css = \"\"\"\n",
    "@import url('https://fonts.googleapis.com/css2?family=Source+Code+Pro:wght@400;600&display=swap');\n",
    "\n",
    "* {\n",
    "    font-family: 'Source Code Pro', monospace;\n",
    "    box-shadow: none !important;\n",
    "    border-radius: 0 !important;\n",
    "}\n",
    "\n",
    "body {\n",
    "    background-color: #0f0f0f;\n",
    "}\n",
    "\n",
    "h1 {\n",
    "    color: #c6f6d5;\n",
    "    text-align: left;\n",
    "    font-weight: 600;\n",
    "    margin-bottom: 8px;\n",
    "}\n",
    "\n",
    ".gr-chatbot {\n",
    "    background: transparent !important;\n",
    "    border: none !important;\n",
    "    padding: 0 !important;\n",
    "}\n",
    "\n",
    ".gr-chatbot .message {\n",
    "    padding: 2px 0 !important;\n",
    "    line-height: 1.6;\n",
    "}\n",
    "\n",
    ".gr-chatbot .message.user {\n",
    "    color: #9ae6b4;\n",
    "}\n",
    "\n",
    ".gr-chatbot .message.bot {\n",
    "    color: #e6fffa;\n",
    "}\n",
    "\n",
    "textarea, input {\n",
    "    background: transparent !important;\n",
    "    color: #c6f6d5 !important;\n",
    "    border: none !important;\n",
    "    border-bottom: 1px solid #c6f6d5 !important;\n",
    "}\n",
    "\n",
    "button {\n",
    "    background: transparent !important;\n",
    "    color: #c6f6d5 !important;\n",
    "    border: none !important;\n",
    "    padding: 4px 8px !important;\n",
    "}\n",
    "\n",
    "button:hover {\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=stream_kpmg_response,\n",
    "    title=\" KPMG Analytics \",\n",
    "    description=\"\"\"Assistant de Veille StratÃ©gique alimentÃ© par Mistral-Small.\n",
    "    \n",
    "Posez vos questions sur l'actualitÃ© tech, finance ou entreprises.\"\"\",\n",
    "    \n",
    "    theme=theme,\n",
    "    css=custom_css,\n",
    "    \n",
    "    examples=[\n",
    "        \"Quelles sont les derniÃ¨res actualitÃ©s sur Apple ?\",\n",
    "        \"Quelles sont les tendances en intelligence artificielle ?\",\n",
    "        \"Analyse les derniÃ¨res actualitÃ©s tech et finance\"\n",
    "    ],\n",
    "    \n",
    "    retry_btn=\" Relancer\",\n",
    "    undo_btn =\"Annuler\",\n",
    "    clear_btn=\" Effacer l'historique\",\n",
    "    \n",
    "    cache_examples=False\n",
    ")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# LANCEMENT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸš€ LANCEMENT DE L'INTERFACE GRADIO\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nðŸ“Œ ModÃ¨le utilisÃ© : mistral-small (gratuit)\")\n",
    "    print(\"ðŸ“Š Index Pinecone : 118 vecteurs disponibles\")\n",
    "    print(\"âœ… SystÃ¨me prÃªt pour la dÃ©mo\\n\")\n",
    "    \n",
    "    demo.queue()\n",
    "    \n",
    "    # OPTION 1 : Local seulement (pour test)\n",
    "    demo.launch(\n",
    "        share=False,\n",
    "        inline=False,\n",
    "        inbrowser=True,\n",
    "        show_error=True,\n",
    "        quiet=False\n",
    "    )\n",
    "    \n",
    "    # OPTION 2 : Avec partage public (dÃ©commentez pour le jury)\n",
    "    # demo.launch(\n",
    "    #     share=True,\n",
    "    #     inline=False,\n",
    "    #     show_error=True,\n",
    "    #     quiet=False\n",
    "    # )\n",
    "    \n",
    "    print(\"\\nâœ… Interface lancÃ©e avec succÃ¨s !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ \n",
      "   DIAGNOSTIC COMPLET DU SYSTÃˆME RAG KPMG\n",
      "ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ ðŸŽ¯ \n",
      "\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Variables d'environnement\n",
      "============================================================\n",
      "   MISTRAL_API_KEY: vd0pw28udW...\n",
      "   PINECONE_API_KEY: pcsk_4PWXZ...\n",
      "âœ… Variables d'environnement : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Ã‰tat de Pinecone\n",
      "============================================================\n",
      "   Index : kpmg-veille\n",
      "   Total vecteurs : 109\n",
      "   Dimension : 1024\n",
      "\n",
      "   ðŸ“ Namespaces :\n",
      "      - news: 109 vecteurs\n",
      "âœ… Ã‰tat de Pinecone : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Mistral Embeddings\n",
      "============================================================\n",
      "   Texte : 'Apple annonce de nouveaux produits'\n",
      "   Dimension : 1024\n",
      "   Type : <class 'list'>\n",
      "   Premiers 5 valeurs : [-0.0160675048828125, 0.01412200927734375, 0.053253173828125, -0.017913818359375, 0.046478271484375]\n",
      "âœ… Mistral Embeddings : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Mistral LLM\n",
      "============================================================\n",
      "   ModÃ¨le : mistral-medium\n",
      "   Question : Capitale de la France ?\n",
      "   RÃ©ponse : Paris.\n",
      "âœ… Mistral LLM : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Retriever\n",
      "============================================================\n",
      "   Query : 'Apple derniÃ¨res actualitÃ©s'\n",
      "   Namespace : news\n",
      "   RÃ©sultats : 3 documents\n",
      "\n",
      "   ðŸ“„ Premier rÃ©sultat :\n",
      "      Source : press_release\n",
      "      Contenu : Newsroom - Apple\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "AppleStoreMaciPadiPhoneWatch\n",
      "VisionAirPodsTV & HomeEntertainmentAccessoriesSupport\n",
      "\n",
      "\n",
      "0+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Newsroom\n",
      "\n",
      "...\n",
      "âœ… Retriever : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : ChaÃ®ne RAG complÃ¨te\n",
      "============================================================\n",
      "   Question : 'Quelles sont les derniÃ¨res actualitÃ©s ?'\n",
      "   Traitement...\n",
      "\n",
      "   âœ… RÃ©ponse gÃ©nÃ©rÃ©e (1648 caractÃ¨res) :\n",
      "   Voici quelques-unes des **derniÃ¨res actualitÃ©s** d'Apple (juin 2024) disponibles sur leur **Newsroom** :\n",
      "\n",
      "1. **Apple Intelligence** :\n",
      "   - Annonce de l'**IA intÃ©grÃ©e** Ã  iOS 18, iPadOS 18 et macOS Sequoia, avec des fonctionnalitÃ©s comme la rÃ©Ã©criture de texte, la gÃ©nÃ©ration d'images et une Siri amÃ©l...\n",
      "âœ… ChaÃ®ne RAG complÃ¨te : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST : Gradio\n",
      "============================================================\n",
      "   Version : 4.0.0\n",
      "âœ… Gradio : RÃ‰USSI\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š RAPPORT FINAL\n",
      "============================================================\n",
      "\n",
      "Tests rÃ©ussis : 7/7\n",
      "\n",
      "ðŸŽ‰ TOUS LES TESTS SONT PASSÃ‰S !\n",
      "âœ… Votre systÃ¨me est prÃªt pour Gradio\n",
      "\n",
      "ðŸ’¡ Prochaine Ã©tape :\n",
      "   ExÃ©cutez la cellule 'gradio_interface_fixed.py'\n",
      "\n",
      "============================================================\n",
      "âœ… Diagnostic terminÃ©\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SCRIPT DE TEST COMPLET - SYSTÃˆME RAG KPMG\n",
    "==========================================\n",
    "\n",
    "ExÃ©cutez ce script pour diagnostiquer tous les problÃ¨mes potentiels.\n",
    "Copier-coller dans une nouvelle cellule de notebook.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FONCTION DE TEST AVEC GESTION D'ERREURS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def run_test(test_name, test_func):\n",
    "    \"\"\"ExÃ©cute un test et affiche le rÃ©sultat\"\"\"\n",
    "    try:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ðŸ§ª TEST : {test_name}\")\n",
    "        print('='*60)\n",
    "        result = test_func()\n",
    "        print(f\"âœ… {test_name} : RÃ‰USSI\")\n",
    "        return True, result\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {test_name} : Ã‰CHOUÃ‰\")\n",
    "        print(f\"   Erreur : {str(e)}\")\n",
    "        return False, None\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 1 : ENVIRONNEMENT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_environment():\n",
    "    \"\"\"VÃ©rifie les variables d'environnement\"\"\"\n",
    "    load_dotenv()\n",
    "    \n",
    "    required_vars = {\n",
    "        \"MISTRAL_API_KEY\": os.getenv(\"MISTRAL_API_KEY\"),\n",
    "        \"PINECONE_API_KEY\": os.getenv(\"PINECONE_API_KEY\")\n",
    "    }\n",
    "    \n",
    "    missing = [k for k, v in required_vars.items() if not v]\n",
    "    \n",
    "    if missing:\n",
    "        raise ValueError(f\"Variables manquantes : {', '.join(missing)}\")\n",
    "    \n",
    "    for key, value in required_vars.items():\n",
    "        masked = value[:10] + \"...\" if value else \"None\"\n",
    "        print(f\"   {key}: {masked}\")\n",
    "    \n",
    "    return required_vars\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 2 : PINECONE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_pinecone():\n",
    "    \"\"\"VÃ©rifie l'Ã©tat de l'index Pinecone\"\"\"\n",
    "    from pinecone import Pinecone\n",
    "    \n",
    "    pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "    index = pc.Index(\"kpmg-veille\")\n",
    "    stats = index.describe_index_stats()\n",
    "    \n",
    "    print(f\"   Index : kpmg-veille\")\n",
    "    print(f\"   Total vecteurs : {stats.total_vector_count}\")\n",
    "    print(f\"   Dimension : 1024\")\n",
    "    \n",
    "    if stats.total_vector_count == 0:\n",
    "        print(\"   âš ï¸  ATTENTION : Aucune donnÃ©e indexÃ©e !\")\n",
    "        print(\"   â†’ ExÃ©cutez les Notebooks 2, 3 et 4\")\n",
    "        raise ValueError(\"Index vide\")\n",
    "    \n",
    "    print(f\"\\n   ðŸ“ Namespaces :\")\n",
    "    for ns, info in stats.namespaces.items():\n",
    "        print(f\"      - {ns}: {info.vector_count} vecteurs\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 3 : MISTRAL EMBEDDINGS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_embeddings():\n",
    "    \"\"\"Teste la gÃ©nÃ©ration d'embeddings\"\"\"\n",
    "    from langchain_mistralai import MistralAIEmbeddings\n",
    "    \n",
    "    embeddings = MistralAIEmbeddings(\n",
    "        model=\"mistral-embed\",\n",
    "        mistral_api_key=os.getenv(\"MISTRAL_API_KEY\")\n",
    "    )\n",
    "    \n",
    "    # Test sur une phrase simple\n",
    "    test_text = \"Apple annonce de nouveaux produits\"\n",
    "    embedding = embeddings.embed_query(test_text)\n",
    "    \n",
    "    print(f\"   Texte : '{test_text}'\")\n",
    "    print(f\"   Dimension : {len(embedding)}\")\n",
    "    print(f\"   Type : {type(embedding)}\")\n",
    "    print(f\"   Premiers 5 valeurs : {embedding[:5]}\")\n",
    "    \n",
    "    if len(embedding) != 1024:\n",
    "        raise ValueError(f\"Dimension incorrecte : {len(embedding)} (attendu : 1024)\")\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 4 : MISTRAL LLM\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_llm():\n",
    "    \"\"\"Teste le modÃ¨le LLM\"\"\"\n",
    "    from langchain_mistralai import ChatMistralAI\n",
    "    \n",
    "    llm = ChatMistralAI(\n",
    "        model=\"mistral-small\",\n",
    "        temperature=0,\n",
    "        mistral_api_key=os.getenv(\"MISTRAL_API_KEY\")\n",
    "    )\n",
    "    \n",
    "    # Test simple\n",
    "    response = llm.invoke(\"RÃ©ponds en un mot : quelle est la capitale de la France ?\")\n",
    "    \n",
    "    print(f\"   ModÃ¨le : mistral-medium\")\n",
    "    print(f\"   Question : Capitale de la France ?\")\n",
    "    print(f\"   RÃ©ponse : {response.content}\")\n",
    "    \n",
    "    if \"Paris\" not in response.content:\n",
    "        print(\"   âš ï¸  RÃ©ponse inattendue, mais API fonctionne\")\n",
    "    \n",
    "    return llm\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 5 : RETRIEVER\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_retriever():\n",
    "    \"\"\"Teste la recherche vectorielle\"\"\"\n",
    "    from langchain_pinecone import PineconeVectorStore\n",
    "    from langchain_mistralai import MistralAIEmbeddings\n",
    "    \n",
    "    embeddings = MistralAIEmbeddings(model=\"mistral-embed\")\n",
    "    \n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=\"kpmg-veille\",\n",
    "        embedding=embeddings,\n",
    "        namespace=\"news\"  # Utilise le namespace qui a des donnÃ©es\n",
    "    )\n",
    "    \n",
    "    # Test de recherche\n",
    "    query = \"Apple derniÃ¨res actualitÃ©s\"\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    \n",
    "    print(f\"   Query : '{query}'\")\n",
    "    print(f\"   Namespace : news\")\n",
    "    print(f\"   RÃ©sultats : {len(results)} documents\")\n",
    "    \n",
    "    if not results:\n",
    "        raise ValueError(\"Aucun rÃ©sultat trouvÃ© - vÃ©rifiez l'indexation\")\n",
    "    \n",
    "    print(f\"\\n   ðŸ“„ Premier rÃ©sultat :\")\n",
    "    print(f\"      Source : {results[0].metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"      Contenu : {results[0].page_content[:150]}...\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 6 : CHAÃŽNE RAG COMPLÃˆTE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_rag_chain():\n",
    "    \"\"\"Teste la chaÃ®ne RAG complÃ¨te\"\"\"\n",
    "    from langchain_mistralai import ChatMistralAI, MistralAIEmbeddings\n",
    "    from langchain_pinecone import PineconeVectorStore\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    from langchain_core.runnables import RunnablePassthrough\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    \n",
    "    # Composants\n",
    "    embeddings = MistralAIEmbeddings(model=\"mistral-embed\")\n",
    "    vectorstore = PineconeVectorStore(\n",
    "        index_name=\"kpmg-veille\",\n",
    "        embedding=embeddings,\n",
    "        namespace=\"news\"\n",
    "    )\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "    llm = ChatMistralAI(model=\"mistral-medium\", temperature=0)\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Contexte : {context}\\n\\nQuestion : {question}\\n\\nRÃ©ponse courte :\"\n",
    "    )\n",
    "    \n",
    "    # ChaÃ®ne\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join([d.page_content[:200] for d in docs])\n",
    "    \n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    # Test\n",
    "    question = \"Quelles sont les derniÃ¨res actualitÃ©s ?\"\n",
    "    print(f\"   Question : '{question}'\")\n",
    "    print(f\"   Traitement...\")\n",
    "    \n",
    "    response = rag_chain.invoke(question)\n",
    "    \n",
    "    print(f\"\\n   âœ… RÃ©ponse gÃ©nÃ©rÃ©e ({len(response)} caractÃ¨res) :\")\n",
    "    print(f\"   {response[:300]}...\")\n",
    "    \n",
    "    return rag_chain\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TEST 7 : GRADIO (OPTIONNEL)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def test_gradio():\n",
    "    \"\"\"VÃ©rifie que Gradio est installÃ©\"\"\"\n",
    "    import gradio as gr\n",
    "    \n",
    "    version = gr.__version__\n",
    "    print(f\"   Version : {version}\")\n",
    "    \n",
    "    if version < \"4.0.0\":\n",
    "        print(\"   âš ï¸  Version ancienne dÃ©tectÃ©e\")\n",
    "        print(\"   â†’ RecommandÃ© : pip install --upgrade gradio\")\n",
    "    \n",
    "    return gr\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EXÃ‰CUTION DES TESTS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def main():\n",
    "    \"\"\"ExÃ©cute tous les tests dans l'ordre\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"ðŸŽ¯ \"*20)\n",
    "    print(\"   DIAGNOSTIC COMPLET DU SYSTÃˆME RAG KPMG\")\n",
    "    print(\"ðŸŽ¯ \"*20 + \"\\n\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Liste des tests Ã  exÃ©cuter\n",
    "    tests = [\n",
    "        (\"Variables d'environnement\", test_environment),\n",
    "        (\"Ã‰tat de Pinecone\", test_pinecone),\n",
    "        (\"Mistral Embeddings\", test_embeddings),\n",
    "        (\"Mistral LLM\", test_llm),\n",
    "        (\"Retriever\", test_retriever),\n",
    "        (\"ChaÃ®ne RAG complÃ¨te\", test_rag_chain),\n",
    "        (\"Gradio\", test_gradio)\n",
    "    ]\n",
    "    \n",
    "    # ExÃ©cution\n",
    "    for test_name, test_func in tests:\n",
    "        success, result = run_test(test_name, test_func)\n",
    "        results[test_name] = {\"success\": success, \"result\": result}\n",
    "    \n",
    "    # Rapport final\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“Š RAPPORT FINAL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    passed = sum(1 for r in results.values() if r[\"success\"])\n",
    "    total = len(results)\n",
    "    \n",
    "    print(f\"\\nTests rÃ©ussis : {passed}/{total}\")\n",
    "    \n",
    "    if passed == total:\n",
    "        print(\"\\nðŸŽ‰ TOUS LES TESTS SONT PASSÃ‰S !\")\n",
    "        print(\"âœ… Votre systÃ¨me est prÃªt pour Gradio\")\n",
    "        print(\"\\nðŸ’¡ Prochaine Ã©tape :\")\n",
    "        print(\"   ExÃ©cutez la cellule 'gradio_interface_fixed.py'\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  CERTAINS TESTS ONT Ã‰CHOUÃ‰\")\n",
    "        print(\"\\nðŸ“‹ Actions recommandÃ©es :\")\n",
    "        \n",
    "        for test_name, result in results.items():\n",
    "            if not result[\"success\"]:\n",
    "                print(f\"\\nâŒ {test_name} :\")\n",
    "                \n",
    "                if \"environnement\" in test_name.lower():\n",
    "                    print(\"   â†’ VÃ©rifiez votre fichier .env\")\n",
    "                    print(\"   â†’ load_dotenv() doit Ãªtre appelÃ©\")\n",
    "                \n",
    "                elif \"pinecone\" in test_name.lower():\n",
    "                    print(\"   â†’ ExÃ©cutez les Notebooks 2, 3, 4 pour indexer des donnÃ©es\")\n",
    "                    print(\"   â†’ VÃ©rifiez que l'index 'kpmg-veille' existe\")\n",
    "                \n",
    "                elif \"embeddings\" in test_name.lower():\n",
    "                    print(\"   â†’ VÃ©rifiez votre MISTRAL_API_KEY\")\n",
    "                    print(\"   â†’ Testez manuellement : https://console.mistral.ai/\")\n",
    "                \n",
    "                elif \"llm\" in test_name.lower():\n",
    "                    print(\"   â†’ VÃ©rifiez les crÃ©dits de votre compte Mistral\")\n",
    "                    print(\"   â†’ Essayez 'mistral-small' si 'medium' ne fonctionne pas\")\n",
    "                \n",
    "                elif \"retriever\" in test_name.lower():\n",
    "                    print(\"   â†’ L'index est vide ou le namespace 'news' n'existe pas\")\n",
    "                    print(\"   â†’ RÃ©exÃ©cutez le Notebook 4 (indexation)\")\n",
    "                \n",
    "                elif \"rag\" in test_name.lower():\n",
    "                    print(\"   â†’ Un composant prÃ©cÃ©dent a Ã©chouÃ©\")\n",
    "                    print(\"   â†’ Corrigez les erreurs ci-dessus d'abord\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… Diagnostic terminÃ©\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# LANCEMENT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
